%%% lecture 1

\section{Introduction}
\subsection{Introduction example} 
\label{sub:introduction_example}
We have
\[
	\begin{cases}
		f''+f =g, &\text{ in }I = [0,1]\\
		f(0)=1, \,f'(0)=1
	\end{cases}
\]
where $g$ is a known continous function on $I$. We will now consider different cases:

\begin{enumerate}[1.]
	\item $g=0$
	\[
		\Rightarrow \,f(x) = A \cos(x) + B \sin(x), x \in I
	\]
	where $A,B \in \mathbb{R}$.
	\item $g$ arbitrary. We will now introduce the Method of variation of constants. Set
	\[
		f(x)=A(x) \cos(x)+ B(x) \sin(x)
	\]
	Differentiate
	\[
		f'(x) = A'(x) \cos(x) + B'(x) \sin(x) - A(x) \sin(x) + B(x) \cos(x)
	\]
	Aussume (This is part of the method)
	\[
		A'(x)\cos(x) + B'(x) \sin(x) = 0, \qquad x \in I
	\]
	Differentiate $f'(x)$ and get
	\[
		f''(x)=\underset{= -f(x)}{\underbrace{-A(x) \cos(x) - B(x) \sin(x)}} - A'(x) \sin(x) + B'(x) \cos(x)
	\]
	We get
	\[
		g(x) = f''(x)+f(x) = -A'(x) \sin(x) + B'(x) \cos(x).
	\]
	Now:
	\[
		\begin{cases}
			A'(x)\cos(x) + B'(x) \sin(x) = 0, & x \in I\\
			- A'(x) \sin(x)+ B'(x) \cos(x) = g(x), & x \in I \\
			A(0)=1, \qquad B(0)=0 &
		\end{cases}
	\]
	We get
	\begin{align*}
		A'(x) &= - g(x)\sin(x) \\
		A(0) &= 1 \\
		B'(x) &= g(x) \cos(x) \\
		B(0) &=0
	\end{align*}
	This implies
	\begin{align*}
		A(x) &= A(0) + \int_{0}^{x} A'(t) \,\mathrm{d}t = 1 - \int_{0}^{x} g(t) \sin(t) \,\mathrm{d}t \\
		B(x) &= B(0) + \int_{0}^{x}B'(t) \,\mathrm{d}t = 0 + \int_{0}^{x}g(t)\cos(t) \,\mathrm{d}t
	\end{align*}
	Hence
	\begin{align*}
		f(x) &= \cos(x) - \int_{0}^{x} g(t) \sin(t) \,\mathrm{d}t \cos(x) + \int_{0}^{x} g(t) \cos(t) \,\mathrm{d}t \sin(x) \\
		&= \cos(x) + \int_{0}^{x} (\underset{=\sin(x-t)}{\underbrace{\sin(x)\cos(t)- \sin(t)\cos(x)}})g(t) \,\mathrm{d}t \\
		&= \cos(x) + \int_{0}^{x}\sin(x-t)g(t) \,\mathrm{d}t \qquad (*)
	\end{align*}
	Check that $f(x)$ in $(*)$ satisfies the PDE.
	\minisec{special case:}
	Assume for $x \in I$
	\[
		g(x) = k(x)f(x)
	\]
	Here $k$ is a known continous function on $I$. Insert this in $(*)$. We obtain
	\[
		f(x) = \cos(x) + \int_{0}^{x} \sin(x-t)k(t)f(t) \,\mathrm{d}t, \qquad x \in I \qquad (**)
	\]
	Observe that $f$ appears both in LHS and RHS. $(**)$ is a reformulation of the PDE with $g=kf$. Pick a $\underset{\in C(I)}{\underbrace{\text{continous function in $I$}}}$. call it $f_0$. Set
	\begin{align*}
		f_1(x) &= \cos(x) + \int_{0}^{x}\sin(x-t)k(t)f_0(t) \,\mathrm{d}t \\
		f_2(x) &= \cos(x) + \int_{0}^{x}\sin(x-t)k(t)f_1(t) \,\mathrm{d}t \\
		\vdots &\qquad \qquad  \vdots \\
		f_{n+1}(x) &= \cos(x) + \int_{0}^{x}\sin(x-t)k(t)f_n(t) \,\mathrm{d}t, \qquad n=1,2,3, \dots \\
	\end{align*}
	\minisec{Hope:} $f_n$ tends to some continous function $f$ on $I$, denoted $f_n \to f$. 'Tends to' has to be more precis! 
	\begin{align*}
		f_{n+1}(x) &= \cos(x) + \int_{0}^{x} \sin(x-t)k(t)f_n(t) \,\mathrm{d}t \\
		\downarrow & \qquad \qquad \downarrow \\
		f(x) &= \cos(x) + \int_{0}^{x} \sin(x-t)k(t)f(t) \,\mathrm{d}t
	\end{align*}
	for $x \in I$. Simplify notation set for $v \in C(I)$
	\[
		\begin{cases}
			u(x)&=\cos(x)\\
			kv(x)&= \int_{0}^{x} \sin(x-t)k(t)v(t) \,\mathrm{d}t
		\end{cases}
	\]
	We have $f_0 \in C(I)$, $f_{n+1}=u + k f_n$ for $n=0,1,2, \dots$ (!) \\
	Facts from previous calculus classes:
	\begin{definition*}[Sequenze of continous functions]
		\[
			v_n \in C(I), \qquad n=1,2,\dots
		\]
		We say that $(v_n)_{n=1}^{\infty}$ converges uniformly in $I$ if
		\[
			\max_{x \in I} \abs{v_n(x)-v_m(x)} \to 0 , \qquad n,m \to \infty
		\]
		i.e.
		\[
			\forall\, \varepsilon >0 \exists\, N: \forall\, n,m \geq N: \, \max_{x \in I}\abs{v_n(x)-v_m(x)}< \varepsilon
		\]
	\end{definition*}
	\begin{lemma*}
		Suppose that $(v_n)_{n=1}^{\infty}$ converges uniformly on $I$. then there exists $v \in C(I)$ such that
		\[
			 \max_{x \in I}\abs{v_m(x)-v(x)} \to 0 \qquad \text{as }m \to \infty
		\]
	\end{lemma*}
	Back to (!): \\
	\minisec{More Notation:}
	\[
		k(kv) = k^2 v, \qquad v \in C(I)
	\]
	and
	\[
		k^{n+1}v = k(k^nv), \qquad n=1,2,\dots
	\]
	We have 
	\begin{align*}
		f_0 & \in C(I) \\ f_1 &=u+kf_0 \\ \text{ and }  
				f_2 &= u + kf_1 = u + k(u+kf_0)
	\end{align*}
	and so on. Note that
	\[
		k(v+w)=kv+kw
	\]
	Then 
	\begin{align*}
		f_2 &= u +k (u+kf_0) = k + ku + k(kf_0) = u + ku +k^2f_0 \\
		f_3 &= u + kf_2 = u + ku + k^2u + k^3f_0
	\end{align*}
	and in general for $n=1,2,\dots$
	\[
		f_n = ku + \dots + k^{n-1}u + k^n f_0, \qquad n=1,2,\dots
	\]
	Assume $n>m$ then
	\[
		f_n-f_m = k^mu + \dots + k^{n-1}u + k^nf_0 - k^mf_0
	\]
	Set for $v \in C(I)$
	\[
		\norm{v} = \max_{x \in I}\abs{v(x)}
	\]
	Note
	\[
		\norm{v+w} \leq \norm{v} + \norm{w} \qquad \text{for }v,w \in C(I)
	\]
	and
	\[
		\norm{-v}=\norm{v}.
	\]
	We have
	\begin{align*}
		\norm{f_n-f_m} &= \norm{k^mu + \dots + k^{n-1}u + k^nf_0 - k^m f_0} \\
		&\leq \norm{k^mu} + \dots + \norm{ k^{n-1}u} + \norm{k^nf_0} + \norm{- k^mf_0}.
	\end{align*}
	Assumption:
	\[
		\sum_{l=1}^{\infty} \norm{k^lv} < \infty \qquad \text{for all }v \in C(I) \qquad (***).
	\]
	Under this assumption
	\[
		\norm{f_n-f_m} \to 0 \qquad \text{as }n,m \to \infty
	\]
	since
	\begin{align*}
		\sum_{l=1}^{\infty}\norm{k^lu} &< \infty \qquad \qquad (u(x)=\cos(x)) \\
		\sum_{l=1}^{\infty}\norm{k^lf_0} &< \infty \qquad \qquad (f_0 \in C(I))
	\end{align*}
	conclusion: $(f_n)_{n=1}^{\infty}$ converges uniformly on $I$. By lemma above there exists $f \in C(I)$ such that
	\[
		\max_{x \in I}\abs{f_n(x)-f(x)} \to 0, \qquad n \to \infty
	\]
	i.e.
	\[
		\norm{f_n -f} \to 0, \qquad n \to \infty
	\]
	'Back hope':
	$f_n$ tends to $f$, denoted $f_n \to f$ shall be interpretated as
	\[
		\norm{f_n -f} \to 0, \qquad n \to \infty
	\]
	Remember
	\[
		f_{n+1}(x) = u(x) + k f_n(x) \to ?
	\]
	For $x \in I$ there is
	\begin{align*}
		\abs{k f_n(x)- kf(x)} &= \abs{ \int_{0}^{x} \sin(x-t)k(t)f_n(t) \,\mathrm{d}t- \int_{0}^{x}\sin(x-t)k(t)f(t) \,\mathrm{d}t} \\
		&\leq \int_{0}^{x}\abs{\sin(x-t)k(t)}\underset{\leq \norm{f_n-f}}{\underbrace{\abs{f_n(t)-f(t)}}} \,\mathrm{d}t \\
		&\leq \int_{0}^{x}\abs{\sin(x-t)k(t)} \,\mathrm{d}t \norm{f_n-f}
	\end{align*}
	In particular
	\begin{align*}
		\norm{k f_n- kf} &\leq \max_{x \in I}\int_{0}^{x} \underset{\leq 1}{\underbrace{\abs{\sin(x-t)}}} \underset{\max_{t \in I}\abs{k(t)}< \infty}{\underbrace{\abs{k(t)}}} \,\mathrm{d}t \norm{f_n -f} \\
		&\leq \norm{k} \norm{f_n-f}
	\end{align*}
	We have, provided $(***)$ holds, shown
	\begin{align*}
		f_{n+1} &= u + k f_n \\
		\downarrow & \\
		f &= u + kf
	\end{align*}
	Let us try to prove $(***)$. For $v \in C(I)$ arbitrary and for $x \in I$
	\begin{align*}
		\norm{kv(x)} &= \abs{\int_{0}^{x}\sin(x-t)k(t)v(t) \,\mathrm{d}t} \\
		&\leq \int_{0}^{x}\underset{\leq 1}{\underbrace{\abs{\sin(x-t)}}}\underset{\leq \norm{k}}{\underbrace{\abs{k(t)}}}\abs{v(t)} \,\mathrm{d}t \\
		&\leq \int_{0}^{x}\underset{\leq \norm{v}}{\underbrace{\abs{v(t)}}} \,\mathrm{d}t \norm{k} \\
		&\leq \norm{k} \norm{v}x
	\end{align*}
	In particular
	\[
		\norm{kv} \leq \norm{k}\norm{v}
	\]
	and
	\begin{align*}
		\abs{k^2v(x)} &\leq \int_{0}^{x} \abs{kv(t)} \,\mathrm{d}t \norm{k} \\
		&\leq \int_{0}^{x}\norm{k}\norm{v}t \,\mathrm{d}t \cdot \norm{k} \\
		&= \norm{k}^2 \norm{v} \frac{x^2}{2}
	\end{align*}
	In particular
	\[
		\norm{k^2v} \leq \norm{k}^2 \norm{v} \frac{1}{2}
	\]
	By induction we get
	\begin{align*}
		\abs{k^n v(x)} &\leq \norm{k}^n \norm{v} \frac{x^m}{m!} \qquad x \in I \\
		\norm{k^n v} &\leq  \norm{k}^n \norm{v} \frac{1}{n!}
	\end{align*}
	So 
	\begin{align*}
		\sum_{l=1}^{\infty}\norm{k^lv} &\leq \sum_{l=1}^{\infty}\norm{k}^l \norm{v} \frac{1}{l!} \\
		&= \norm{v} \sum_{l=1}^{\infty} \frac{\norm{k}^l}{l!} \\
		&\leq \norm{v} e^{\norm{k}} < \infty
	\end{align*}
	consider Taylor expansion.
	$\Rightarrow $ $(***)$ holds true. \\
	We have now shown that $f = u+kf$ where $u(x) = \cos(x)$ and
	\[
		kv = \int_{0}^{x}\sin(x-t)k(t)v(t) \,\mathrm{d}t
	\]
	$x \in I$ for $v \in C(I)$, has a solution $f \in C(I)$. \\
	\minisec{Question:} Is the solution unique? \\
	Assume $f,\tilde f \in C(I)$ such that $f = u + k f$ and $\tilde f = u+ k \tilde f$. Set 
	\[
		v = f- \tilde f \in C(I)
	\]
	\begin{align*}
		\Rightarrow v &= (u+kf) - (u+ k \tilde f) \\ &= kf - k \tilde f \\ &= k(f- \tilde f) \\ &= kv
	\end{align*}
	We have $v = kv$, implies that $kv = k(kv) = k^2v$. So for $n=1,2,\dots$
	\[
		v = kv = k^2v = \dots = k^nv.
	\]
	We know 
	\[
		\sum_{n=1}^{\infty}\norm{k^n \hat{v}} < \infty \qquad \text{for all }\hat{v} \in C(I).
	\]
	Apply this to $\hat{v}=v$:
	\[
		\sum_{n=1}^{\infty}\underset{=\norm{v}}{\underbrace{\norm{k^nv}}} < \infty .
	\]
	So $\norm{v}=0$ with implies $v(x)=0$ for all $x \in I$.
	So we have $f(x)=\tilde f(x)$ for $x \in I$. \\
	$\Rightarrow $ Answer to the question above: YES ! 
\end{enumerate}
We have more or less proved the following theorem:
\begin{theorem}
	Set $I=[0,1]$. Suppose $u \in C(I)$ and $k \in C(I \times I)$. Consider 
	\[
		f(x) = u(x)+ \int_{0}^{x} k(x,t) f(t) \,\mathrm{d}t, \qquad x \in I \qquad \qquad (1)
	\]
	Then $(1)$ has a unique solution $f \in C(I)$
\end{theorem}
With the same technology we can prove:
\begin{theorem}
	Set $I = [0,1]$. Suppose $u \in C(I)$, $k \in C(I \times I)$ and $\max\limits_{(x,t) \in I \times I} \abs{k(x,t)} <1$. Consider \[
		f(x) = u(x) + \int_{0}^{1}k(x,t)f(t) \,\mathrm{d}t, \qquad x \in I \qquad \qquad (2).
	\]
	Then $(2)$ has a unique solution $f \in C(I)$.
\end{theorem}
Different notions: see introductional example.
\begin{definition*}[vector space]
	$C(I)$ with the operations for $x \in I$
	\begin{description}
		\item[addition] $v,w \in C(I)$: $\qquad (v+w)(x) = v(x)+ w(x)$ 
		\item[mult. by scalar] $v \in C(I)$, $ \lambda \in \mathbb{R}$: $\qquad (\lambda v)(x) = \lambda v(x)$ 
	\end{description}
	Note that $v+w, \lambda v \in C(I)$.
\end{definition*}
\begin{definition*}[norm]
	norm on $C(I)$ for instance 
	\[
		\norm{v} = \max_{x \in I} \abs{v(x)}
	\]
	with norm given we can talk about convergence and continuity.
\end{definition*}
\begin{definition*}[Cauchy sequence]
	In our example a sequence $(f_n)_{n=1}^{\infty}$ is called Cauchy sequence if $\norm{f_n-f_m} \to 0$ for $n,m \to \infty$.
\end{definition*}
\begin{definition*}
	$C(I)$ with the max-norm. Lemma above says that every Cauchy sequence converges i.e.
	\[
		\norm{v_n-v_m} \to 0, \qquad n,m \to \infty
	\]
	This applies
	\[
		\exists\, v \in C(I): \norm{v_n-v} \to 0, \qquad n \to \infty
	\]
	This is the defining property of a Banach space. \\
	$K$ linear mapping $C(I) \to C(I)$ with
	\begin{align*}
		K(v+w) &= K(v) + K(w) \\
		K(\lambda v) &= \lambda K(v)
	\end{align*}
	for $v,w \in  C(I)$, $\lambda \in \mathbb{R}$. \\
	$K$ bounded linear:
	\[
		\norm{Kv} \leq M \norm{v} \qquad \forall\, v \in C(I)
	\]
	where $M >0$ independent of $v$.	
\end{definition*}
\begin{definition*}[operator norm]
	Define
	\[
		\norm{K}:= \inf \set[M>0]{\norm{Kv} \leq M \norm{v} \text{ for all }v \in C(I)}.
	\]
\end{definition*}
\minisec{fixed point results:}
Our example: $f=u+kf =: T(f)$ and $f_0 \in C(I)$ fixed. \\
Form sequence of iterants $(f_n)_{n=1}^{\infty}$, $f_n = T(f_{n-1})$, $n=1,2,\dots$ if
\[
	\norm{T(v)-T(w)} \leq c \norm{v-w}
\]
for all $v,w \in C(I)$ for some $c<1$. Then there is a unique $v \in C(I)$ such that $v = T(v)$. \\
This is \underline{Banach's fixed point theorem}.
\begin{definition*}[Green's function]
	Our example: 
	\[
		L = \left( \diffd{}{x} \right)^2 + 1 
	\]
	differential operator. Boundary conditions 
	\[
		f(0) = f'(0) = 0.
	\]
	Then 
	\[
		f(x) = \int_{0}^{1} g(x,t)h(t) \,\mathrm{d}t 
	\]
	is a solution to
	\[
		\begin{cases}
			f''+f &= h, \\
			f(0) = f'(0)& = 0	
		\end{cases}
	\]
\end{definition*}
\begin{definition*}[real vector space]
	We say that $E$ is a real vector space  if it is a non-empty set with the operations 
	\begin{description}
		\item[addition] $E \times E \to E$, $\qquad (x,y) \mapsto x+y$
		\item[mult. with scalar] $\mathbb{R} \times E \to E$, $ \qquad (\lambda,x) \mapsto \lambda x$ 
	\end{description}
	satisfying the axioms:
	\begin{enumerate}[(1)]
		\item $x+y = y+x, \qquad$ for all $x,y \in E$
		\item $x+(y+z)= (x+y)+z, \qquad $ for all $x,y,z \in E$
		\item For all $x,y \in E$ there exists $z \in E$ such that $x+z = y$
		\item $\alpha (\beta x) = (\alpha \cdot \beta)x, \qquad $ for all $\alpha,\beta \in \mathbb{R}, x \in E$
		\item $\alpha(x+y) = \alpha x+ \alpha y, \qquad $ for all $\alpha \in \mathbb{R}, x,y \in E$
		\item $(\alpha + \beta) x = \alpha x + \beta x, \qquad $ for all $\alpha, \beta \in \mathbb{R}, x \in E$
		\item $1 \cdot x = x, \qquad $ for all $x \in E$.  
	\end{enumerate}
\end{definition*}
\begin{bemerkung}
	$E$ is a complex vector space if all $\mathbb{R}$ in the definition above are replaced by $\mathbb{C}$.
\end{bemerkung}
\begin{bemerkung}
	\begin{enumerate}[(1)]
		\item \[
			\exists\,! 0 \in E: \qquad x + 0 = x \qquad \text{for all }x \in E.
		\]
		since: Fix $x \in E$, by $(3)$, $\exists\, 0_x$ such that $0_x + x =x$. \\
		Fix $y \in E$. We want to show that $y + 0_y = y$. By $(3)$, there exists $z \in E$ such that $x+z = y$. So
		\begin{align*}
			y + 0_x & \stackrel{\hphantom{(1)}}{=} (x+z)+ 0_x \\
			&\stackrel{(1)}{=} (z+x)+ 0_x \\
			&\stackrel{(2)}{=} z + (x + 0_x) \\
			&\stackrel{\hphantom{(1)}}{=} z+x \\
			&\stackrel{(1)}{=}x+z \\
			&\stackrel{\hphantom{(1)}}{=} y.
		\end{align*}
		Assume $x+ 0_1 = x$, $x+ 0_2 =x$ for all $x \in E$. We want to show $0_1 = 0_2$:
		\[
			0_1 = 0_1 + 0_2 = 0_2 + 0_1 = 0_2
		\]
		\item 
		\[
			\forall\, x \in E: \, \exists\,! \,-x \in E: \,x+(-x)=0
		\]
		proof: exercise.
		\item \begin{align*}
			0x &=0 \qquad \text{for all }x \in E \\
			(-1)x &= -x \qquad \text{for all }x \in E
		\end{align*}
	\end{enumerate}
\end{bemerkung}
\begin{beispiele}[Examples of real vector spaces]
	\begin{enumerate}[1)]
		\item $\mathbb{R}$ with standard addition and mult. by scalar.
		\item $\mathbb{R}^n$, $n=2,3, \dots$
		\begin{description}
			\item[addition] $(x_1,x_2,\dots) + (y_1,y_2, \dots) = (x_1+y_1,x_2+y_2, \dots)$ 
			\item[mult.] $ \lambda (x_1,x_2,\dots) = (\lambda x_1, \lambda x_2, \dots)$
		\end{description} 
		\item $\mathbb{R}^{\infty} = \set[(x_1,\dots,x_n,\dots)]{x_n \in \mathbb{R}, n=1,2,\dots}$
		\item $1 \leq p < \infty$, 
		\[
			l^p = \set[(x_1,\dots,x_n, \dots) \in \mathbb{R}^{\infty}]{\left( \sum_{n=1}^{\infty} \abs{x_n}^p \right)^{\frac{1}{p}} < \infty}
		\]
		with the same addition and mult. by scalar as in $\mathbb{R}^{\infty}$. We have to check:
		\begin{enumerate}[(1)]
			\item $x,y \in l^p \qquad \Rightarrow \qquad x+y \in l^p$
			\item $x \in l^p, \lambda \in \mathbb{R} \qquad \Rightarrow \qquad \lambda x \in l^p$ 
		\end{enumerate}
		For $(1)$ we assume $x = (x_1, \dots, x_n, \dots)$ and $y = (y_1, \dots, y_n, \dots)$.
		\begin{align*}
			x \in l^p \qquad &\Rightarrow \qquad \sum_{n=1}^{\infty}\abs{x_n}^p < \infty \\
			y \in l^p \qquad &\Rightarrow \qquad \sum_{n=1}^{\infty}\abs{y_n}^p < \infty
		\end{align*}
		\[
			\Rightarrow \qquad  x+y = (x_1+y_1, \dots) \stackrel{?}{\in } l^p?
		\]
		\begin{align*}
			\Rightarrow \sum_{n=1}^{\infty}\abs{x_n+y_n}^p & \leq \set{\abs{x_n+y_n} \leq \abs{x_n}+ \abs{y_n} \leq 2 \max \set{\abs{x_n},\abs{y_n}}} \\
			& \,\set{\abs{x_n+y_n}^p \leq 2^p \left( \abs{x_n}^p + \abs{y_n}^p \right)} \\
			&\leq \sum_{n=1}^{\infty}2^p (\abs{x_n}^p + \abs{y_n}^p) \\
			&= 2^p \underset{< \infty}{\underbrace{\sum_{}^{}\abs{x_n}^p}}+ 2^p \underset{< \infty}{\underbrace{\sum_{}^{}\abs{y_n}^p}} < \infty
		\end{align*}
		and \[
			\sum_{n=1}^{\infty} \abs{\lambda x_n}^p = \sum_{n=1}^{\infty} \abs{\lambda}^p \cdot \abs{x_n}^p = \abs{\lambda}^p \sum_{n=1}^{\infty}\abs{x_n}^p < \infty
		\]
		\item function spaces, say real-valued functions on $I$.
		\begin{description}
			\item[addition:] $(f+g)(x) = f(x)+ g(x), \qquad x \in I$
			\item[mult. by scalar:] $(\lambda f)(x)= \lambda f(x) \qquad $ for functions $f$ and $g$ 
		\end{description}
		\item $C(I):$ addition and mult. by scalar as in $(5)$. \\ $f,g$ continuous in $I$ implies that $f+g$ is continuous in $I$. \\
		Also if $f$ is continuous and $\lambda \in \mathbb{R}$ then $(\lambda f)$ is continuous in $I$.
		\item $P(I)= \,$ polynomials in $I$.
		\item $P_k(I)= \,$ polynomials of degree at most $k$ in $I$.
	\end{enumerate}
\end{beispiele}
