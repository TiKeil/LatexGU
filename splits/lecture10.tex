%%%lecture 10

\begin{beispiel}
	$E = L^2([0,1])$ and $f,g \in E$ with
	\[
		\skal{f}{g}_{L^2} = \int_{0}^{1} f(x) \overline{g(x)} \,\mathrm{d}x, \qquad \norm{f}_{L^2} = \left( \int_{0}^{1} \abs{f(x)}^2 \,\mathrm{d}x \right)^{\frac{1}{2}}.
	\]
	Set $h \in C([0,1] \times [0,1])$ and for $f \in L^2([0,1])$
	\[
		A(f)(x) = \int_{0}^{1} h(x,y)f(y) \,\mathrm{d}y, \qquad x \in [0,1].
	\]
	Then
	\[
		\norm{A} \leq \left( \int_{0}^{1} \left( \int_{0}^{1} \abs{h(x,y)}^2 \,\mathrm{d}y \right) \,\mathrm{d}x \right)^{\frac{1}{2}} < \infty.
	\]
\end{beispiel}
\begin{beispiel}
	Let $(E, \norm{.})$ be a normed space. Then there are no $A,B \in B(E,E)$ such that
	\[
		AB - BA = I
	\]
	where $I$ is the identity ($I(x)=x$ for $x \in E$).
	\begin{bemerkung}
		Consider $ f \in E = C^{\infty}([0,1])$ and 
		\[
			A = \diffd{}{x}, \qquad B=x.
		\]Then
		\[
			(AB - BA)(f)(x) = \diffd{}{x}(x(f(x))) - x \diffd{}{x}f(x) = f(x).
		\]
	\end{bemerkung}
	Argue by contradiction. \\
	Assume $A,B \in B(E,E)$ with $AB-BA = I$. \\
	Hint: Consider $A^nB-BA^n$ for $n = 1,2,\dots$. For $n =2$ we have
	\begin{align*}
		A^2B-BA^2 &= A^2B-ABA + ABA - BA^2 \\
		&= A(AB-BA) + (AB-BA)A \\
		&= 2A.
	\end{align*}
	For $n=3$ we have
	\begin{align*}
		A^3B-BA^3 &= A^3B-A^2BA + A^2BA - BA^3 \\
		&=A^2(AB-BA) + (A^2B-BA^2)A \\
		&= 3A^2.
	\end{align*}
	In general 
	\[
		A^nB-BA^n = nA^{n-1}, \qquad n=2,3,4,\dots \qquad (*)
	\]
	Check using an induction argument. We obtain
	\[
		n \norm{A^{n-1}} = \norm{A^nB-BA^n} \leq \norm{A^nB} + \norm{BA^n} \leq  2 \norm{A^{n-1}} \norm{A} \norm{B}
	\]
	Hence \[
		(2 \norm{A} \norm{B} -n) \norm{A^{n-1}} \geq 0, \qquad  \forall\,  n = 2,3,\dots.
	\]
	We conclude that $\norm{A^{n-1}}= 0$ for $n$ large enough. Clearly the same for $\norm{A^n}$. This yields $A^n=0$ for $n$ large enough. Repeated use of $(*)$ gives $A=0$. This contradicts $AB-BA= I$ so the implication in the example is proven.
\end{beispiel}

Recall a important theorem:

\begin{theorem}[Riesz representation theorem]
	$(E, \skal{.}{.})$ Hilbert space $f \in B(E,\mathbb{C})$. $f$ is bounded linear functional on $E$. This yields
	\[
		\exists\,! x_f \in E: \qquad f(x) = \skal{x}{x_f}, \qquad \forall\, x \in E.
	\]
	Also it holds
	\[
		\underset{\substack{\text{operator norm} \\ \text{of $f$}}}{\underbrace{\norm{f}}} = \underset{\substack{norm of} \\ \text{$x_f$ in $E$}}{\underbrace{\norm{x_f}}}.
	\]
\end{theorem}

\begin{definition}
	$\varphi: E \times E \to \mathbb{C}$ is called:
	\begin{itemize}
		\item Bilinear, if for scalars $\alpha$ and $\beta$ it holds
		\begin{align*}
			\varphi( \alpha x+ \beta y,z) &= \alpha \varphi(x,z)+ \beta \varphi(y,z) \qquad \forall\, x,y,z \in E \\
			\varphi(x,\alpha y + \beta z) &= \bar{\alpha} \varphi(x,z) + \overline{\beta} \varphi(y,z) \qquad \forall\, x,y,z \in E.
		\end{align*}
		\item Bounded, if there exists $M>0$ such that
		\[
			\abs{\varphi(x,y)} \leq M \norm{x}\norm{y}, \qquad \forall\, x,y \in E.
		\]
		\item Coercive, if there exists $K>0$ such that
		\[
			\varphi(x,x) \geq K \norm{x}^2, \qquad \forall\, x \in E.
		\]
	\end{itemize}
\end{definition}
Clearly $\skal{.}{.}$ in $E$ is a bilinear, bounded and coercive functional in $E$ (with $M=K=1$). \\
We will now introduce a Generalization of the Riesz representation theorem.

\begin{theorem}[Lax-Milgram]
	$(E, \skal{.}{.})$ Hilbert space. Let $\varphi: E \times E \to \mathbb{C}$ be a bilinear, bounded and coercive functional. $f: E \to \mathbb{C}$ bounded linear functional in $E$. Then there exists an unique $x_f \in E$ such that
	\[
		f(x) = \varphi(x,x_f), \qquad  \forall\, x \in E.
	\]
\end{theorem}

\begin{beweis}
	\begin{enumerate}[Step 1:]
		\item $\exists\,!$ $A \in B(E,E)$ with
		\[
			\varphi(x,y)= \skal{x}{A(y)}, \qquad \forall\, x,y \in E.
		\]
		\item $A$ is injective and surjective.
		\item Apply RRT with $ \tilde x_f = A^{-1}(x_f)$
		\begin{align*}
			f(x) &= \skal{x}{x_f} \\ &= \skal{x}{A(A^{-1}(x_f))} \\ &= \varphi(x, \tilde x_f), \qquad \forall\, x \in E.
		\end{align*}
	\end{enumerate}
	\begin{description}
		\item[Step 1:] Fix $y \in E$ and consider for $x \in E$
		\[
			x \stackrel{f_y}{\mapsto } \varphi(x,y) \in \mathbb{C}.
		\] 
		\textbf{Claim:} \text{    }$f_y: E \to \mathbb{C}$ is a bounded linear functional. \\
		For $x,y,z \in E$ and $\alpha,\beta$ scalars we have
		\begin{align*}
			f_y(\alpha x+ \beta z) &= \varphi(\alpha x + \beta z,y) \\
			&= \alpha \varphi(x,y) + \beta \varphi(z,y) \\
			&= \alpha f_y(x) + \beta f_y(z).
		\end{align*}
		Hence $f_y$ is linear. It is bounded because of
		\[
			\abs{f_y(x)} = \abs{\varphi(x,y)} \leq (M \norm{y})\norm{x}, \qquad \forall\, x \in E.
		\]
		So $f_y$ is bounded. \\
		RRT implies $f_y(x) = \skal{x}{A(y)}$ for all $x \in E$ for some $A(y) \in E$. \\ Now we have $A : E \to E$.
		\textbf{Claim:} \text{    }$A \in B(E,E)$. \\
		For $x,y,z \in E$ and scalars $\alpha, \beta$ we have
		\begin{align*}
			\skal{x}{A( \alpha y + \beta z)} &= \varphi(x, \alpha y + \beta z) \\
			&= \bar{\alpha} \varphi(x,y)+ \bar{\beta} \varphi(x,z) \\
			&= \bar{\alpha} \skal{x}{A(y)} + \bar{\beta} \skal{x}{A(z)} \\
			&= \skal{x}{\alpha A(y)}+ \skal{x}{\beta A(z)}. \\
		\end{align*}
		This is equivalent to
		\[
			\skal{x}{A(\alpha y + \beta z)- \alpha A(y) - \beta A(z)} = 0, \qquad  x \in E.
		\]
		This implies 
		\[
			\norm{A(\alpha y + \beta z) - \alpha A(y) - \beta A(z)} = 0.
		\]
		So \[
			A( \alpha y+ \beta z) = \alpha A(y) + \beta A(z) \qquad \forall\, y,z \in E \text{ and scalars }\beta,\alpha.
		\]
		Hence, $A$ is linear. We will now show that $A$ is bounded: \\
		We know because $\varphi$ is continuous that for all $x,y \in E$
		\[
			\abs{\skal{x}{A(y)}} = \abs{\varphi(x,y)} \leq M \norm{x} \norm{y}.
		\]
		Take $x = A(y)$ and get
		\[
			\norm{A(y)}^2 \leq  M \norm{A(y)} \norm{y} \qquad \forall\, y \in E
		\]
		which implies
		\[
			\norm{A(y)} \leq M \norm{y} \qquad \forall\, y \in E.
		\]
		Hence $\norm{A} \leq M < \infty$.
		\item[Step 2:] Note $\varphi(x,y) = \skal{x}{A(y)}$ for alle $x,y \in E$. \\
		\textbf{Claim:} \text{    }$A$ is injective, i.e.
		\[
			A(x_1) = A(x_2) \qquad \Rightarrow \qquad x_1 = x_2.
 		\]
		$\varphi$ is coercive so
		\[
			\norm{x}^2 \leq \frac{\varphi(x,x)}{K} = \frac{1}{K} \underset{>0}{\underbrace{\abs{\skal{x}{A(x)}}}} \leq \frac{1}{K} \norm{x} \norm{A(x)} \qquad \forall\,  x \in E.
		\]
		Hence \[
			\norm{x} \leq  \frac{1}{K} \norm{A(x)}, \qquad \forall\, x \in E.
		\]
		If $A(x_1) = A(x_2)$ we have $A(x_1-x_2) = 0 \in E$ then
		\[
			\norm{x_1 - x_2} \leq \frac{1}{K} \norm{A(x_1 -x_2)} = 0.
		\]
		We get $x_1 = x_2$. \\
		\textbf{Claim:} \text{    }$A$ is surjective, i.e. the image of $A$ is $E$: \[
			\mathcal{R}(A) = \set[A(x)]{x \in E} = E.
		\] 
		We first show that $\mathcal{R}(A)$ is a closed subspace of $E$. 
		\begin{itemize}
			\item $\mathcal{R}(A)$ is a subspace in $E$ since $A$ is linear.
			\item $\mathcal{R}(A)$ is closed since
			\[
				y_n \to y \qquad \text{in }(E, \norm{.}) \qquad \Rightarrow y \in \mathcal{R}(A).
			\]			
		\end{itemize}
		$\mathcal{R}(A)$ is linear. Take $y_1,y_2 \in \mathcal{R}(A)$ with preimages $x_1,x_2$ and yield
		\[
			\alpha_1 y_1 + \alpha_2 y_2 = \alpha_1 A(x_1) + \alpha_2 A(x_2) = A(\alpha_1 x_1 + \alpha_2 x_2).
		\]
		So \[
			\alpha_1 y_1 + \alpha_2 y_2 \in \mathcal{R}(A).
		\]
		Assume \[
			y_n \to y \qquad \text{in }(E, \norm{.}).
		\]
		For $n=1,2,\dots$ there are $x_1,x_2,\dots$ such that $y_n= A(x_n)$ for $n=1,2,\dots$. \\
		\textbf{Claim:} \text{    }$(x_n)_{n \in \mathbb{N}}$ is a Cauchy sequence in $E$ since
		\begin{align*}
			\norm{x_n-x_m} &\leq \frac{1}{K} \norm{A(x_n-x_m)} \\
			&= \frac{1}{K} \norm{A(x_n)- A(x_m)} \\
			&= \frac{1}{K} \norm{y_n -y_m} \to 0, \qquad n,m \to \infty
		\end{align*}
		since $(y_n)_{n \in \mathbb{N}}$ converges. \\
		Since $(E, \norm{.})$ is a Banach space $(x_n)_{n \in \mathbb{N}}$ converges in $(E, \norm{.})$. Call the limit $x \in E$. Hence
		\[
			A(x_n) \to y
		\]
		since $A$ is bounded, continuos and linear. So $y = A(x)$ and we get $y \in \mathcal{R}(A)$. \\
		Secondly $A$ is surjective, i.e. $\mathcal{R}(A)=E$. \\
		Assume that this is not true. The Orthogonal decomposition theorem gives
		\[
			E = \mathcal{R}(A) \oplus \mathcal{R}(A)^{\perp}.
		\]
		The first one is a closed subspace in $E$ and the second one is not empty by assumption. Fix $z \in \mathcal{R}(A)^{\perp} \setminus \set{0}$. Note 
		\[
			\varphi(x,y) = \skal{x}{A(y)} \qquad x,y \in E
		\]
		With $x = y = z$ we get
		\[
			\varphi(z,z) = \skal{z}{A(z)} = 0
		\]
		and 
		\[
			\varphi(z,z) \geq K \norm{z}^2 \geq 0 \qquad \Rightarrow  \,z=0.
		\]
		This is a contradiction. \\
		The Conclusion is 
		\[
			\mathcal{R}(A)^{\perp} = \set{0} \qquad \Rightarrow \qquad \mathcal{R}(A) = E.
		\]
		We have $\varphi(x,y) = \skal{x}{A(y)}$ for all $x,y \in E$ and $A \in B(E,E)$ surjective.
		\item[Step 3:] see above.
	\end{description}
\end{beweis}

\subsection{Adjoint operator} 
\label{sub:adjoint_operator}

$(E,\skal{.}{.})$ Hilbert space and $A \in B(E,E)$ with adjoint $A^{*}$, i.e.
\[
	\skal{A(x)}{y} = \skal{x}{A^*(y)} , \qquad \forall\, x,y \in E.
\]
Fix $y \in E$ and consider
\[
	x \stackrel{f_y}{\mapsto } \skal{A(x)}{y} \in \mathbb{C}. 
\]
\textbf{Claim:} \text{    }$f_y$ is a bounded linear functional on $E$
\begin{itemize}
	\item linear since $A$ is linear.
	\item bounded since $A$ is bounded with
	\[
		\abs{f_y(x)} \leq (\norm{A}\norm{y})\norm{x}, \qquad x \in E.
	\]
\end{itemize}
	RRT implies
	\[
		f_y(x) = \skal{x}{A^*(y)}, \qquad x \in E.
	\]
	We have $A^*: E \to E$ such that
	\[
		\skal{A(x)}{y} = \skal{x}{A^*(y)} , \qquad \forall\, x,y \in E.
	\]
\begin{proposition}
	$A \in B(E,E)$. Then $A^* \in B(E,E) $ and $\norm{A^*} = \norm{A}$.
\end{proposition}
\begin{beweis}
	$A^*$ linear:
	\[
		\skal{x}{A^* ( \alpha y + \beta z)} = \skal{x}{\alpha A^*(y) + \beta A^*(z)} \qquad \forall\, x,y \in E.
	\]
	$A^*$ bounded: \\ Take $x= A^*(y)$ and get
	\begin{align*}
		\norm{A^*(y)}^2 &= \abs{\skal{A(A^*(y))}{y}} \\
		&\leq \norm{A(A^*(y))} \norm{y} \\
		&\leq \norm{A} \norm{A^*(y)} \norm{y}, \qquad y \in E.
	\end{align*}
	We get
	\[
		\norm{A^*(y)} \leq \norm{A} \norm{y}, \qquad y \in E.
	\]
	Conclucion: $A^* \in B(E,E)$. We also get 
	\[
		\norm{A^*} \leq \norm{A}.
	\]
	But we also know that $A^{**} = A$ since
	\begin{align*}
		\skal{x}{A^{**}(y)} &= \skal{A^*(x)}{y} \\
		&= \overline{\skal{y}{A^*(x)}} \\
		&= \overline{\skal{A(y)}{x}} \\
		&= \skal{x}{A(y)}, \qquad x,y \in E.
	\end{align*}
	So \[
		\norm{A} = \norm{A^{**}} \leq \norm{A^*}
	\]
	which impllies
	\[
		\norm{A} = \norm{A^*}.
	\]
\end{beweis}
\begin{bemerkung}
	$A,B \in B(E,E)$ then
	\begin{align*}
		(A+B)^* &= A^* + B^* \\
		(AB)^* &= B^* A^* \\
		(\alpha A)^* &= \bar{\alpha}A^* \\
		A^{**} &= A \\
		I^* &= I.
	\end{align*}
\end{bemerkung}
\begin{beispiel}
	Continuity of the example above: For $f \in L^2([0,1])$ consider
	\[
		A(f)(x) = \int_{0}^{1}h(x,y)f(y) \,\mathrm{d}y, \qquad x \in [0,1].
	\]
	For $g \in L^2([0,1])$ it holds
	\begin{align*}
		\skal{A(f)}{g}_{L^2} &= \int_{0}^{1} A(f)(x)\overline{g(x)} \,\mathrm{d}x \\
		&= \int_{0}^{1}\int_{0}^{1} h(x,y)f(y) \,\mathrm{d}x \overline{g(x)} \,\mathrm{d}x \\
		&= \int_{0}^{1}f(y) \cdot \int_{0}^{1}h(x,y) \overline{g(x)} \,\mathrm{d}x \,\mathrm{d}y \\
		&= \int_{0}^{1} f(y) \cdot \overline{\int_{0}^{1} \overline{h(x,y)} g(x) \,\mathrm{d}x} \,\mathrm{d}y \\
		&= \skal{f}{A^*(g)}_{L^2}.
	\end{align*}
	This gives us 
	\[
		A^*(f)(x) = \int_{0}^{1} \overline{h(y,x)}f(y) \,\mathrm{d}y, \qquad x \in [0,1].
	\]
\end{beispiel}

\begin{beispiel}
	$A \in B(E,E)$. It follows
	\[
		\mathcal{R}(A)^{\perp} = N(A^*) = \set[x \in E]{A^*(x) = 0}
	\]
	since $x \in \mathcal{R}(A)^{\perp}$. It is equivalent that
	\[
		\skal{x}{A(y)} = 0, \qquad \forall\, y \in E
	\] 
	\[
		\Leftrightarrow \qquad \skal{A^*(x)}{y} = 0, \qquad \forall\, y \in E
	\]
	\[
		\Rightarrow \qquad A^*(x) = 0 \qquad \Leftrightarrow \qquad x \in N(A^*).
	\]
	We get
	\[
		N(A^*)^{\perp} = \overline{\mathcal{R}(A)}
	\]
	since
	\[
		N(A^*)^{\perp} = \left( R(A)^{\perp} \right)^{\perp} = \overline{\spn(\mathcal{R}(A))} = \overline{\mathcal{R}(A)}.
	\]
\end{beispiel}
\begin{bemerkung}
	$A \in B(E,E)$ is called self adjoint if $A^* = A$.
\end{bemerkung}
For $A \in B(E,E)$ we have
\[
	\norm{A} =\sup\limits_{\substack{\norm{x} = 1  \\ \norm{y}=1}} \abs{\skal{A(x)}{y}}
\]
since
\[
	\norm{\skal{A(x)}{y}} \leq \underset{\leq \norm{A}\norm{x}}{\underbrace{\norm{A(x)}}} \leq \norm{A}, \qquad \text{for }\norm{x}=\norm{y}=1.
\]
If $A(x) = 0$ for all $x \in E$ then $\norm{A}=0$ and also
\[
	\sup\limits_{\substack{\norm{x} = 1  \\ \norm{y}=1}} \abs{\skal{A(x)}{y}} = 0.
\]
For $x$ with $A(x) \neq 0$ then it is
\[
	A \left( \frac{1}{\norm{x}}x \right) \neq 0.
\]
For such an $x$ with $\norm{x}=1$ we have
\[
	\abs{\skal{A(x)}{\frac{1}{\norm{A(x)}}A(x)}} = \frac{1}{\norm{A(x)}} \norm{A(x)}^2 = \norm{A(x)}
\]
and
\[
	\norm{A} \leq \sup_{\norm{x}=1} \norm{A(x)} \leq \sup\limits_{\substack{\norm{x} = 1  \\ \norm{y}=1}} \abs{\skal{A(x)}{y}} \leq \norm{A}.
\]
\begin{proposition}
	Let $A \in B(E,E)$ be self-adjoint. Then
	\[
		\norm{A} = \sup_{\norm{x}=1} \abs{\skal{A(x)}{x}}.
	\]
\end{proposition}
\begin{beweis}
	Set 
	\[
		M = \sup_{\norm{x}=1} \abs{\skal{A(x)}{x}}.
	\]
	For $\norm{x}=1$ we have
	\[
		\abs{\skal{A(x)}{x}} \leq \norm{A(x)} \norm{x} \leq \norm{A}.
	\]
	Furthermore
	\[
		M \leq \norm{A}.
	\]
	It remains to prove: $\norm{A} \leq M$. \\
	For $x,z \in E$ consider:
	\begin{align*}
		\skal{A(x+z)}{x+z} - \skal{A(x-z)}{x-z} &= 2 \skal{A(x)}{z} + 2 \skal{A(z)}{x} \\
		&= 2 \left( \skal{A(x)}{z} + \skal{z}{A^*(x)} \right) \\
		&= 2 (\skal{A(x)}{z} + \skal{z}{A(x)}) \\
		&= 4 \re( \skal{A(x)}{z}).
	\end{align*}
	Assume now $A(x) \neq 0$ and set
	\[
		z = \frac{1}{\norm{A(x)}} A(x).
	\]
	Hence
	\[
		\norm{A(x)} = \frac{1}{4} \left( \skal{A(x+\frac{1}{\norm{A(x)}} A(x))}{x + \frac{1}{\norm{A(x)}} A(x)} 
		- \skal{A(x-\frac{1}{\norm{A(x)}} A(x))}{x- \frac{1}{\norm{A(x)}} A(x)} \right).
	\]
	Note \[
		\abs{\skal{A(y)}{y}} = \norm{y}^2 \abs{\skal{A(\frac{1}{\norm{y}}y)}{ \frac{1}{\norm{y}}y}} \leq M \norm{y}^2.
	\]
	We now obtain
	\begin{align*}
		\norm{A(x)} &\leq \frac{1}{4} \left( M \norm{x+\frac{1}{\norm{A(x)}} A(x)}^2 + M \norm{x - \frac{1}{\norm{A(x)}} A(x)}^2 \right) \\
		&= \frac{M}{4} 2 \left( \norm{x}^2 + \norm{\frac{1}{\norm{A(x)}} A(x)}^2 \right) \\
		&= \frac{M}{2} (\norm{x}^2 +1).
	\end{align*}
	So
	\[
		\norm{A} = \sup_{\norm{x}=1} \norm{A(x)} \leq M
	\]
	and this yields
	\[
		\norm{A}= M.
	\]
\end{beweis}