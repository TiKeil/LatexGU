%!TEX TS-program = xelatex

\newcommand{\Semester}{WiSe 2016/2017, Term 1}
\newcommand{\fach}{Applied Functionalanalysis}
\newcommand{\prof}{Prof.\ Peter Kumlin}

\input{!config/VorlagenTim/preambel.tex}

\numberwithin{equation}{section}
\numberwithin{figure}{section}

\begin{document}

\maketitle
\cleardoubleoddemptypage

\pagenumbering{Alph}
\section*{foreword --- cooperation}
This document is a transcript of the lecture \enquote{\fach, \Semester}, by \prof.
It mainly contains the written content of the lecture. I will not assume any responsibility for the correctness of the content! For questions, remarks and mistakes please write an email to \href{mailto:keil.menden@web.de}{\nolinkurl{keil.menden@web.de}}. I'm grateful for every email. 
\newpage

\newpage

\tableofcontents
\cleardoubleoddemptypage
\pagenumbering{arabic}
\setcounter{page}{1}

\section{Introduction}
\subsection{Introduction example} 
\label{sub:introduction_example}
We have
\[
	\begin{cases}
		f''+f =g, &\text{ in }I = [0,1]\\
		f(0)=1, \,f'(0)=1
	\end{cases}
\]
where $g$ is a known continous function in $I$. We will now consider different cases:

\begin{enumerate}[1.]
	\item $g=0$
	\[
		\Rightarrow \,f(x) = A \cos(x) + B \sin(x), x \in I
	\]
	where $A,B \in \mathbb{R}$.
	\item $g$ arbitrary. We will now introduce the Method of variation of constants. Set
	\[
		f(x)=A(x) \cos(x)+ B(x) \sin(x)
	\]
	Differentiate
	\[
		f'(x) = A'(x) \cos(x) + B'(x) \sin(x) - A(x) \sin(x) + B(x) \cos(x)
	\]
	Aussume (This is part of the method)
	\[
		A'(x)\cos(x) + B'(x) \sin(x) = 0, \qquad x \in I
	\]
	Differentiate $f'(x)$ and get
	\[
		f''(x)=\underset{= -f(x)}{\underbrace{-A(x) \cos(x) - B(x) \sin(x)}} - A'(x) \sin(x) + B'(x) \cos(x)
	\]
	We get
	\[
		g(x) = f''(x)+f(x) = -A'(x) \sin(x) + B'(x) \cos(x).
	\]
	Now:
	\[
		\begin{cases}
			A'(x)\cos(x) + B'(x) \sin(x) = 0, & x \in I\\
			- A'(x) \sin(x)+ B'(x) \cos(x) = g(x), & x \in I \\
			A(0)=1, \qquad B(0)=0 &
		\end{cases}
	\]
	We get
	\begin{align*}
		A'(x) &= - g(x)\sin(x) \\
		A(0) &= 1 \\
		B'(x) &= g(x) \cos(x) \\
		B(0) &=0
	\end{align*}
	This implies
	\begin{align*}
		A(x) &= A(0) + \int_{0}^{x} A'(t) \,\mathrm{d}t = 1 - \int_{0}^{x} g(t) \sin(t) \,\mathrm{d}t \\
		B(x) &= B(0) + \int_{0}^{x}B'(t) \,\mathrm{d}t = 0 + \int_{0}^{x}g(t)\cos(t) \,\mathrm{d}t
	\end{align*}
	Hence
	\begin{align*}
		f(x) &= \cos(x) - \int_{0}^{x} g(t) \sin(t) \,\mathrm{d}t \cos(x) + \int_{0}^{x} g(t) \cos(t) \,\mathrm{d}t \sin(x) \\
		&= \cos(x) + \int_{0}^{x} (\underset{=\sin(x-t)}{\underbrace{\sin(x)\cos(t)- \sin(t)\cos(x)}})g(t) \,\mathrm{d}t \\
		&= \cos(x) + \int_{0}^{x}\sin(x-t)g(t) \,\mathrm{d}t \qquad (*)
	\end{align*}
	Check that $f(x)$ in $(*)$ satisfies the PDE.
	\minisec{special case:}
	Assume for $x \in I$
	\[
		g(x) = k(x)f(x)
	\]
	Here $k$ is a known continous function in $I$. Insert this in $(*)$. We obtain
	\[
		f(x) = \cos(x) + \int_{0}^{x} \sin(x-t)k(t)f(t) \,\mathrm{d}t, \qquad x \in I \qquad (**)
	\]
	Observe that $f$ appears both in LHS and RHS. $(**)$ is a reformulation of the PDE with $g=kf$. Pick a $\underset{\in C(I)}{\underbrace{\text{continous function in $I$}}}$. call it $f_0$. Set
	\begin{align*}
		f_1(x) &= \cos(x) + \int_{0}^{x}\sin(x-t)k(t)f_0(t) \,\mathrm{d}t \\
		f_2(x) &= \cos(x) + \int_{0}^{x}\sin(x-t)k(t)f_1(t) \,\mathrm{d}t \\
		\vdots &\qquad \qquad  \vdots \\
		f_{n+1}(x) &= \cos(x) + \int_{0}^{x}\sin(x-t)k(t)f_n(t) \,\mathrm{d}t, \qquad n=1,2,3, \dots \\
	\end{align*}
	\minisec{Hope:} $f_n$ tends to some continous function $f$ on $I$, denoted $f_n \to f$. 'Tends to' has to be more precis! 
	\begin{align*}
		f_{n+1}(x) &= \cos(x) + \int_{0}^{x} \sin(x-t)k(t)f_n(t) \,\mathrm{d}t \\
		\downarrow & \qquad \qquad \downarrow \\
		f(x) &= \cos(x) + \int_{0}^{x} \sin(x-t)k(t)f(t) \,\mathrm{d}t
	\end{align*}
	for $x \in I$. Simplify notation set for $v \in C(I)$
	\[
		\begin{cases}
			u(x)&=\cos(x)\\
			kv(x)&= \int_{0}^{x} \sin(x-t)k(t)v(t) \,\mathrm{d}t
		\end{cases}
	\]
	We have $f_0 \in C(I)$, $f_{n+1}=u + k f_n$ for $n=0,1,2, \dots$ (!) \\
	Facts from previous calculus classes:
	\begin{definition*}[Sequenze of continous functions]
		\[
			v_n \in C(I), \qquad n=1,2,\dots
		\]
		We say that $(v_n)_{n=1}^{\infty}$ converges uniformly in $I$ if
		\[
			\max_{x \in I} \abs{v_n(x)-v_m(x)} \to 0 , \qquad n,m \to \infty
		\]
		i.e.
		\[
			\forall\, \varepsilon >0 \exists\, N: \forall\, n,m \geq N: \, \max_{x \in I}\abs{v_n(x)-v_m(x)}< \varepsilon
		\]
	\end{definition*}
	\begin{lemma*}
		Suppose that $(v_n)_{n=1}^{\infty}$ converges uniformly on $I$. then there exists $v \in C(I)$ such that
		\[
			 \max_{x \in I}\abs{v_m(x)-v(x)} \to 0 \qquad \text{as }m \to \infty
		\]
	\end{lemma*}
	Back to (!): \\
	More Notation:
	\[
		k(kv) = k^2 v, \qquad v \in C(I)
	\]
	and
	\[
		k^{n+1}v = k(k^nv), \qquad n=1,2,\dots
	\]
	We have $f_0 \in C(I)$, $f_1=u+kf_0$ and 
	\[
		f_2 = u + kf_1 = u + k(u+kf_0)
	\]
	and so on. Note that
	\[
		k(v+w)=kv+kw
	\]
	Then 
	\begin{align*}
		f_2 &= u +k (u+kf_0) = k + ku + k(kf_0) = u + ku +k^2f_0 \\
		f_3 &= u + kf_2 = u + ku + k^2u + k^3f_0
	\end{align*}
	and in general for $n=1,2,\dots$
	\[
		f_n = ku + \dots + k^{n-1}u + k^n f_0, \qquad n=1,2,\dots
	\]
	Assume $n>m$ then
	\[
		f_n-f_m = k^mu + \dots + k^{n-1}u + k^nf_0 - k^mf_0
	\]
	Set for $v \in C(I)$
	\[
		\norm{v} = \max_{x \in I}\abs{v(x)}
	\]
	Note
	\[
		\norm{v+w} \leq \norm{v} + \norm{w} \qquad \text{for }v,w \in C(I)
	\]
	and
	\[
		\norm{-v}=\norm{v}.
	\]
	We have
	\begin{align*}
		\norm{f_n-f_m} &= \norm{k^mu + \dots + k^{n-1}u + k^nf_0 - k^m f_0} \\
		&\leq \norm{k^mu} + \dots + \norm{ k^{n-1}u} + \norm{k^nf_0} + \norm{- k^mf_0}.
	\end{align*}
	Assumption
	\[
		\sum_{l=1}^{\infty} \norm{k^lv} < \infty \qquad \text{for all }v \in C(I) \qquad (***)
	\]
	Under this assumption
	\[
		\norm{f_n-f_m} \to 0 \qquad \text{as }n,m \to \infty
	\]
	since
	\begin{align*}
		\sum_{l=1}^{\infty}\norm{k^lu} &< \infty \qquad \qquad (u(x)=\cos(x)) \\
		\sum_{l=1}^{\infty}\norm{k^lf_0} &< \infty \qquad \qquad (f_0 \in C(I))
	\end{align*}
	conclusion: $(f_n)_{n=1}^{\infty}$ converges uniformly on $I$. By lemma above there exists $f \in C(I)$ such that
	\[
		\max_{x \in I}\abs{f_n(x)-f(x)} \to 0, \qquad n \to \infty
	\]
	i.e.
	\[
		\norm{f_n -f} \to 0, \qquad n \to \infty
	\]
	'Back hope':
	$f_n$ tends to $f$, denoted $f_n \to f$ shall be interpretated as
	\[
		\norm{f_n -f} \to 0, \qquad n \to \infty
	\]
	Remember
	\[
		f_{n+1}(x) = u(x) + k f_n(x) \to ?
	\]
	For $x \in I$ there is
	\begin{align*}
		\abs{k f_n(x)- kf(x)} &= \abs{ \int_{0}^{x} \sin(x-t)k(t)f_n(t) \,\mathrm{d}t- \int_{0}^{x}\sin(x-t)k(t)f(t) \,\mathrm{d}t} \\
		&\leq \int_{0}^{x}\abs{\sin(x-t)k(t)}\underset{\leq \norm{f_n-f}}{\underbrace{\abs{f_n(t)-f(t)}}} \,\mathrm{d}t \\
		&\leq \int_{0}^{x}\abs{\sin(x-t)k(t)} \,\mathrm{d}t \norm{f_n-f}
	\end{align*}
	In particular
	\begin{align*}
		\norm{k f_n- kf} &\leq \max_{x \in I}\int_{0}^{x} \underset{\leq 1}{\underbrace{\abs{\sin(x-t)}}} \underset{\max_{t \in I}\abs{k(t)}< \infty}{\underbrace{\abs{k(t)}}} \,\mathrm{d}t \norm{f_n -f} \\
		&\leq \norm{k} \norm{f_n-f}
	\end{align*}
	We have, provided $(***)$ holds, shown
	\begin{align*}
		f_{n+1} &= u + k f_n \\
		\downarrow & \\
		f &= u + kf
	\end{align*}
	Let us try to prove $(***)$. For $v \in C(I)$ arbitrary and for $x \in I$
	\begin{align*}
		\norm{kv(x)} &= \abs{\int_{0}^{x}\sin(x-t)k(t)v(t) \,\mathrm{d}t} \\
		&\leq \int_{0}^{x}\underset{\leq 1}{\underbrace{\abs{\sin(x-t)}}}\underset{\leq \norm{k}}{\underbrace{\abs{k(t)}}}\abs{v(t)} \,\mathrm{d}t \\
		&\leq \int_{0}^{x}\underset{\leq \norm{v}}{\underbrace{\abs{v(t)}}} \,\mathrm{d}t \norm{k} \\
		&\leq \norm{k} \norm{v}x
	\end{align*}
	In particular
	\[
		\norm{kv} \leq \norm{k}\norm{v}
	\]
	and
	\begin{align*}
		\abs{k^2v(x)} &\leq \int_{0}^{x} \abs{kv(t)} \,\mathrm{d}t \norm{k} \\
		&\leq \int_{0}^{x}\norm{k}\norm{v}t \,\mathrm{d}t \cdot \norm{k} \\
		&= \norm{k}^2 \norm{v} \frac{x^2}{2}
	\end{align*}
	In particular
	\[
		\norm{k^2v} \leq \norm{k}^2 \norm{v} \frac{1}{2}
	\]
	By induction we get
	\begin{align*}
		\abs{k^n v(x)} &\leq \norm{k}^n \norm{v} \frac{x^m}{m!} \qquad x \in I \\
		\norm{k^n v} &\leq  \norm{k}^n \norm{v} \frac{1}{n!}
	\end{align*}
	So 
	\begin{align*}
		\sum_{l=1}^{\infty}\norm{k^lv} &\leq \sum_{l=1}^{\infty}\norm{k}^l \norm{v} \frac{1}{l!} \\
		&= \norm{v} \sum_{l=1}^{\infty} \frac{\norm{k}^l}{l!} \\
		&\leq \norm{v} e^{\norm{k}} < \infty
	\end{align*}
	consider Taylor expansion.
	$\Rightarrow $ $(***)$ holds true. \\
	We have now shown that $f = u+kf$ where $u(x) = \cos(x)$ and
	\[
		kv = \int_{0}^{x}\sin(x-t)k(t)v(t) \,\mathrm{d}t
	\]
	$x \in I$ for $v \in C(I)$, has a solution $f \in C(I)$. \\
	Question: Is the solution unique? \\
	Assume $f,\tilde f \in C(I)$ such that $f = u + k f$ and $\tilde f = u+ k \tilde f$. Set 
	\[
		v = f- \tilde f \in C(I)
	\]
	\begin{align*}
		\Rightarrow v &= (u+kf) - (u+ k \tilde f) \\ &= kf - k \tilde f \\ &= k(f- \tilde f) \\ &= kv
	\end{align*}
	We have $v = kv$, implies that $kv = k(kv) = k^2v$. So for $n=1,2,\dots$
	\[
		v = kv = k^2v = \dots = k^nv
	\]
	We know 
	\[
		\sum_{n=1}^{\infty}\norm{k^n \hat{v}} < \infty \qquad \text{for all }\hat{v} \in C(I).
	\]
	Apply this to $\hat{v}=v$:
	\[
		\sum_{n=1}^{\infty}\underset{=\norm{v}}{\underbrace{\norm{k^nv}}} < \infty 
	\]
	So $\norm{v}=0$ with implies $v(x)=0$ for all $x \in I$.
	So we have $f(x)=\tilde f(x)$ for $x \in I$. \\
	$\Rightarrow $ Answer to the question above: YES ! 
\end{enumerate}
We have more or less proved the following theorem:
\begin{theorem}
	Set $I=[0,1]$. Suppose $u \in C(I)$ and $k \in C(I \times I)$. Consider 
	\[
		f(x) = u(x)+ \int_{0}^{x} k(x,t) f(t) \,\mathrm{d}t, \qquad x \in I \qquad \qquad (1)
	\]
	Then $(1)$ has a unique solution $f \in C(I)$
\end{theorem}
With the same technology we can prove:
\begin{theorem}
	Set $I = [0,1]$. Suppose $u \in C(I)$, $k \in C(I \times I)$ and $\max\limits_{(x,t) \in I \times I} \abs{k(x,t)} <1$. Consider \[
		f(x) = u(x) + \int_{0}^{1}k(x,t)f(t) \,\mathrm{d}t, \qquad x \in I \qquad \qquad (2).
	\]
	Then $(2)$ has a unique solution $f \in C(I)$.
\end{theorem}
Different notions: see intoductory example.
\begin{definition*}[vector space]
	$C(I)$ with the operations for $x \in I$
	\begin{description}
		\item[addition] $v,w \in C(I)$: $\qquad (v+w)(x) = v(x)+ w(x)$ 
		\item[mult. by scalar] $v \in C(I)$, $ \lambda \in \mathbb{R}$: $\qquad (\lambda v)(x) = \lambda v(x)$ 
	\end{description}
	Note that $v+w, \lambda v \in C(I)$.
\end{definition*}
\begin{definition*}[norm]
	norm on $C(I)$ for instance 
	\[
		\norm{v} = \max_{x \in I} \abs{v(x)}
	\]
	with norm given we can talk about convergence and confirmity
\end{definition*}
\begin{definition*}[Cauchy sequence]
	In our example a sequence $(f_n)_{n=1}^{\infty}$ is called Cauchy sequence if $\norm{f_n-f_m} \to 0$ for $n,m \to \infty$.
\end{definition*}
\begin{definition*}
	$C(I)$ with the max-norm. Lemma above says that every Cauchy sequence converges i.e.
	\[
		\norm{v_n-v_m} \to 0, \qquad n,m \to \infty
	\]
	This applies
	\[
		\exists\, v \in C(I): \norm{v_n-v} \to 0, \qquad n \to \infty
	\]
	This is the defining property of a Banach space. \\
	$K$ linear mapping $C(I) \to C(I)$ with
	\begin{align*}
		K(v+w) &= K(v) + K(w) \\
		K(\lambda v) &= \lambda K(v)
	\end{align*}
	for $v,w \in  C(I)$, $\lambda \in \mathbb{R}$. \\
	$K$ bounded linear:
	\[
		\norm{Kv} \leq M \norm{v} \qquad \forall\, v \in C(I)
	\]
	where $M >0$ independent of $v$.	
\end{definition*}
\begin{definition*}[operator norm]
	Define
	\[
		\norm{K}= \inf \set[M>0]{\norm{Kv} \leq M \norm{v} \text{ for all }v \in C(I)}.
	\]
\end{definition*}
\minisec{fixed point results:}
Our example: $f=u+kf =: T(f)$ and $f_0 \in C(I)$ fixed. \\
Form sequence of iterants $(f_n)_{n=1}^{\infty}$, $f_n = T(f_{n-1})$, $n=1,2,\dots$ if
\[
	\norm{T(v)-T(w)} \leq c \norm{v-w}
\]
for all $v,w \in C(I)$ for some $c<1$. Then there is a unique $v \in C(I)$ such that $v = T(v)$. \\
This is \underline{Banach's fixed point theorem}.
\begin{definition*}[Green's function]
	Our example: 
	\[
		L = \left( \diffd{}{x} \right)^2 + 1 
	\]
	differential operator. Boundary conditions 
	\[
		f(0) = f'(0) = 0.
	\]
	Then 
	\[
		f(x) = \int_{0}^{1} g(x,t)h(t) \,\mathrm{d}t 
	\]
	is a solution to
	\[
		\begin{cases}
			f''+f &= h, \\
			f(0) = f'(0)& = 0	
		\end{cases}
	\]
\end{definition*}
\begin{definition*}[real vector space]
	We say that $E$ is a real vector space  if it is a non-empty set with the operations 
	\begin{description}
		\item[addition] $E \times E \to E$, $\qquad (x,y) \mapsto x+y$
		\item[mult. with scalar] $\mathbb{R} \times E \to E$, $ \qquad (\lambda,x) \mapsto \lambda x$ 
	\end{description}
	satisfying the axioms:
	\begin{enumerate}[(1)]
		\item $x+y = y+x, \qquad$ for all $x,y \in E$
		\item $x+(y+z)= (x+y)+z, \qquad $ for all $x,y,z \in E$
		\item For all $x,y \in E$ there exists $z \in E$ such that $x+z = y$
		\item $\alpha (\beta x) = (\alpha \cdot \beta)x, \qquad $ for all $\alpha,\beta \in \mathbb{R}, x \in E$
		\item $\alpha(x+y) = \alpha x+ \alpha y, \qquad $ for all $\alpha \in \mathbb{R}, x,y \in E$
		\item $(\alpha + \beta) x = \alpha x + \beta x, \qquad $ for all $\alpha, \beta \in \mathbb{R}, x \in E$
		\item $1 \cdot x = x, \qquad $ for all $x \in E$.  
	\end{enumerate}
\end{definition*}
\begin{bemerkung}
	$E$ is a complec vector space if all $\mathbb{R}$ in the definition above are replaced by $\mathbb{C}$.
\end{bemerkung}
\begin{bemerkung}
	\begin{enumerate}[(1)]
		\item \[
			\exists\,! 0 \in E: \qquad x + 0 = x \qquad \text{for all }x \in E.
		\]
		since: Fix $x \in E$, by $(3)$, $\exists\, 0_x$ such that $0_x + x =x$. \\
		Fix $y \in E$. We want to show that $y + 0_y = y$. By $(3)$, there exists $z \in E$ such that $x+z = y$. So
		\begin{align*}
			y + 0_x & \stackrel{\hphantom{(1)}}{=} (x+z)+ 0_x \\
			&\stackrel{(1)}{=} (z+x)+ 0_x \\
			&\stackrel{(2)}{=} z + (x + 0_x) \\
			&\stackrel{\hphantom{(1)}}{=} z+x \\
			&\stackrel{(1)}{=}x+z \\
			&\stackrel{\hphantom{(1)}}{=} y.
		\end{align*}
		Assume $x+ 0_1 = x$, $x+ 0_2 =x$ for all $x \in E$. We want to show $0_1 = 0_2$:
		\[
			0_1 = 0_1 + 0_2 = 0_2 + 0_1 = 0_2
		\]
		\item 
		\[
			\forall\, x \in E: \, \exists\,! \,-x \in E: \,x+(-x)=0
		\]
		proof: exercise.
		\item \begin{align*}
			0x &=0 \qquad \text{for all }x \in E \\
			(-1)x &= -x \qquad \text{for all }x \in E
		\end{align*}
	\end{enumerate}
\end{bemerkung}
\begin{beispiele}[Examples of real vector spaces]
	\begin{enumerate}[1)]
		\item $\mathbb{R}$ with standard addition and mult. by scalar.
		\item $\mathbb{R}^n$, $n=2,3, \dots$
		\begin{description}
			\item[addition] $(x_1,x_2,\dots) + (y_1,y_2, \dots) = (x_1+y_1,x_2+y_2, \dots)$ 
			\item[mult.] $ \lambda (x_1,x_2,\dots) = (\lambda x_1, \lambda x_2, \dots)$
		\end{description} 
		\item $\mathbb{R}^{\infty} = \set[(x_1,\dots,x_n,\dots)]{x_n \in \mathbb{R}, n=1,2,\dots}$
		\item $1 \leq p < \infty$, 
		\[
			l^p = \set[(x_1,\dots,x_n, \dots) \in \mathbb{R}^{\infty}]{\left( \sum_{n=1}^{\infty} \abs{x_n}^p \right)^{\frac{1}{p}} < \infty}
		\]
		with the same addition and mult. by scalar as in $\mathbb{R}^{\infty}$. We have to check:
		\begin{enumerate}[(1)]
			\item $x,y \in l^p \qquad \Rightarrow \qquad x+y \in l^p$
			\item $x \in l^p, \lambda \in \mathbb{R} \qquad \Rightarrow \qquad \lambda x \in l^p$ 
		\end{enumerate}
		For $(1)$ we assume $x = (x_1, \dots, x_n, \dots)$ and $y = (y_1, \dots, y_n, \dots)$.
		\begin{align*}
			x \in l^p \qquad &\Rightarrow \qquad \sum_{n=1}^{\infty}\abs{x_n}^p < \infty \\
			y \in l^p \qquad &\Rightarrow \qquad \sum_{n=1}^{\infty}\abs{y_n}^p < \infty
		\end{align*}
		\[
			\Rightarrow \qquad  x+y = (x_1+y_1, \dots) \stackrel{?}{\in } l^p?
		\]
		\begin{align*}
			\Rightarrow \sum_{n=1}^{\infty}\abs{x_n+y_n}^p & \leq \set{\abs{x_n+y_n} \leq \abs{x_n}+ \abs{y_n} \leq 2 \max \set{\abs{x_n},\abs{y_n}}} \\
			& \,\set{\abs{x_n+y_n}^p \leq 2^p \left( \abs{x_n}^p + \abs{y_n}^p \right)} \\
			&\leq \sum_{n=1}^{\infty}2^p (\abs{x_n}^p + \abs{y_n}^p) \\
			&= 2^p \underset{< \infty}{\underbrace{\sum_{}^{}\abs{x_n}^p}}+ 2^p \underset{< \infty}{\underbrace{\sum_{}^{}\abs{y_n}^p}} < \infty
		\end{align*}
		and \[
			\sum_{n=1}^{\infty} \abs{\lambda x_n}^p = \sum_{n=1}^{\infty} \abs{\lambda}^p \cdot \abs{x_n}^p = \abs{\lambda}^p \sum_{n=1}^{\infty}\abs{x_n}^p < \infty
		\]
		\item function spaces, say real-valued functions on $I$.
		\begin{description}
			\item[addition:] $(f+g)(x) = f(x)+ g(x), \qquad x \in I$
			\item[mult. by scalar:] $(\lambda f)(x)= \lambda f(x) \qquad $ for functions $f$ and $g$ 
		\end{description}
		\item $C(I):$ addition and mult. by scalar as in $(5)$. \\ $f,g$ continuous in $I$ implies that $f+g$ is continuous in $I$. \\
		Also if $f$ is continuous and $\lambda \in \mathbb{R}$ then $(\lambda f)$ is continuous in $I$.
		\item $P(I)= \,$ polynomials in $I$.
		\item $P_k(I)= \,$ polynomials of degree at most $k$ in $I$.
	\end{enumerate}
\end{beispiele}

%01.09.2016
\begin{theorem}[Hölder's inequality]
	Assume $1<p<\infty$ and $\frac{1}{p}+ \frac{1}{q}=1$. Let $(x_1, \dots, x_n, \dots)$ and $(y_1,y_2, \dots, y_n, \dots)$ be sequences of complex numbers. Then
	\[
		\sum_{n=1}^{\infty}\abs{x_ny_n} 
		\leq \left( \sum_{n=1}^{\infty}\abs{x_n}^p \right)^{\frac{1}{p}} \cdot \left( \sum_{n=1}^{\infty}\abs{y_n}^q \right)^{\frac{1}{q}}
	\]
	Remark there the LHS can be infinity, but the RHS can also be infinity.
\end{theorem}
\begin{beweis}
	\begin{description}
		\item[Step 1] We're going to proof 
		\[
			ab \leq \frac{a^p}{p}+ \frac{b^q}{q}, \qquad \text{for all }a,b >0
		\] 
		\[
			\int_{0}^{a} x^{p-1} \,\mathrm{d}x = \frac{a^p}{p}
		\]
		Note $y = x^{p-1}$ gives \[
			x  = y ^{\frac{1}{p-1}} = y^{\frac{1}{\frac{1}{1-\frac{1}{q}}-1}}= y ^{\frac{1}{\frac{q}{q-1}-1}} = y^{q-1}
		\] 
		so
		\[
			\int_{0}^{b}y^{q-1} \,\mathrm{d}y = \frac{b^q}{q}
		\]
		We get
		\[
			ab \leq \frac{a^p}{p}+ \frac{b^q}{q}
		\]
		(You also get condition for $=$)
		\item[Step 2] It is enough to consider the cases LHS $>0$ and RHS $< \infty$. There consists integer $N$ such that
		\[
			0 < \sum_{n=1}^{N}\abs{x_n}^p, \, \sum_{n=1}^{N}\abs{y_n}^q < \infty
		\]
		Set 
		\begin{align*}
			a &= \frac{\abs{x_k}}{\left( \sum_{n=1}^{N}\abs{x_n}^p \right)^{\frac{1}{p}}}, \qquad k = 1,2, \dots,N, \\
			b &= \frac{\abs{y_k}}{\left( \sum_{n=1}^{N}\abs{y_n}^q \right)^{\frac{1}{q}}}, \qquad k = 1,2, \dots,N.
		\end{align*}
		Insert into
		\[
			ab \leq \frac{a^p}{p}+ \frac{b^q}{q}.
		\]
		\[
			\frac{\abs{x_ky_k}}{\left( \sum_{n=1}^{N}\abs{x_n}^p \right)^{\frac{1}{p}}\left( \sum_{n=1}^{N}\abs{y_n}^q \right)^{\frac{1}{q}}} 
			\leq \frac{\abs{x_k}^p}{p \sum_{n=1}^{N}\abs{x_n}^p} + \frac{\abs{y_k}^q}{q \sum_{n=1}^{N}\abs{y_n}^q}, \qquad k = 1,2, \dots, N.
		\]
		We sum over $k$ from $1$ to $N$.
		\[
			\sum_{k=1}^{N}\abs{x_ky_k} \leq  \left( \sum_{n=1}^{N}\abs{x_n}^p \right)^{\frac{1}{p}} \cdot \left( \sum_{n=1}^{N}\abs{y_n}^q \right)^{\frac{1}{q}}
		\]
		Let $N \to \infty$. First in RHS and then in LHS. 
	\end{description}
\end{beweis}
\begin{theorem}[Minkowski's inequality]
	Assume $1 \leq p < \infty$. and $X,Y \in l^p$. Then
	\[
		\norm{X+Y}_{l^p} \leq \norm{X}_{l^p} + \norm{Y}_{l^p}
	\]
\end{theorem}
\begin{beweis}
	\begin{description}
		\item[$p=1$] 
		\begin{align*}
			\norm{X+Y}_{l^1} &= \norm{(x_1,x_2, \dots,x_n, \dots)+ (y_1,y_2, \dots,y_n, \dots)}_{l^1} \\
			&= \norm{(x_1+y_1, \dots,x_n + y_n, \dots)}_{l^1} \\
			&= \sum_{n=1}^{\infty} \abs{x_n+y_n} \\
			&\leq \sum_{n=1}^{\infty} (\abs{x_n}+\abs{y_n}) \\
			&= \sum_{n=1}^{\infty}\abs{x_n}+ \sum_{n=1}^{\infty}\abs{y_n} \\
			&= \norm{X}_{l^1}+ \norm{Y}_{l^1}
		\end{align*} 
		\item[$1 < p < \infty$] 
		\begin{align*}
					\norm{X+Y}_{l^p}^p &= \sum_{n=1}^{\infty}\abs{x_n+y_n}^p \\
					&= \sum_{n=1}^{\infty}\abs{x_n+y_n}\abs{x_n+y_n}^{p-1} \\
					&\leq \sum_{n=1}^{\infty}\abs{x_n}\abs{x_n+y_n}^{p-1} + \sum_{n=1}^{\infty}\abs{y_n}\abs{x_n+y_n}^{p-1}.
		\end{align*}
		Use Hölder to get
		\begin{align*}
			\sum_{n=1}^{\infty}\abs{x_n}\abs{x_n+y_n}^{p-1} &\leq
			 \underset{=\norm{X}_{l^p}}{\underbrace{\left( \sum_{n=1}^{\infty}\abs{x_n}^p \right)^{\frac{1}{p}}}} \cdot \left( \sum_{n=1}^{\infty}\abs{x_n+y_n}^{(p-1)q} \right)^{\frac{1}{q}} \\
			 &= \set{(p-1)q = (p-1)\frac{1}{1-\frac{1}{p}}=p} \\
			 &= \norm{X}_{l^p}  \left( \sum_{n=1}^{\infty}\abs{x_n+y_n}^p \right)^{\frac{1}{q}}.
		\end{align*}
		We have
		\[
			\norm{X+Y}_{l^p}^p \leq \left( \norm{X}_{l^p} + \norm{Y}_{l^p} \right) \norm{X+Y}_{l^p}^{\frac{p}{q}}
		\]
		If $\norm{X+Y}_{l^p} \neq 0$ then
		\[
			\norm{X+Y}_{l^p}^{p-\frac{p}{q}} \leq \norm{X}_{l^p} + \norm{Y}_{l^p}
		\]
		there
		\[
			p- \frac{p}{q} = p (1- \frac{1}{q}) = p \frac{1}{p} = 1.
		\]
	\end{description}
\end{beweis}
\begin{bemerkung}
	$f \in C([0,1])$ then for $1 \leq p < \infty$
	\[
		\norm{f}_{L^p} = \left( \int_{0}^{1} \abs{f(t)}^p \,\mathrm{d}t \right)^{\frac{1}{p}}.
	\]
	Claim:
	\begin{align*}
		\norm{fq}_{L^1} = \int_{0}^{1} \abs{f(t)\cdot g(t)} \,\mathrm{d}t \leq \norm{f}_{L^p} \cdot \norm{g}_{L^q}
	\end{align*}
	where $\frac{1}{p}+ \frac{1}{q}= 1$. Also we have
	\[
		\norm{f+q}_{L^p} \leq \norm{f}_{L^p}+ \norm{g}_{L^p}
	\]
	This is proven with the same technique as we used for $l^p$. $\sum_{n=1}^{\infty}$ is replaced by $\int_{0}^{1} \,\mathrm{d}t$. \\
	$E$ real/complex vector space. $x_1, \dots,x_n \in E$, $\lambda_1, \dots, \lambda_n$ scalar. We say that 
	\[
		\lambda_1 x_1, \dots, \lambda_n x_n
	\]
	is a linear combination of $x_1,\dots,x_n$. We say that $x_1,\dots,x_n$ are linear independent if 
	\[
		\alpha_1 x_1 + \dots + \alpha_n x_n = 0 \qquad \Rightarrow \qquad \alpha_1 = \dots = \alpha_n = 0.
	\]
	If $A \subset E$, we say that $A$ is linear independant if every linear combination of vectors in $A$ is linear independant.
\end{bemerkung}
	\begin{beispiele}
		\begin{enumerate}[(1)]
			\item 
		Set $E = P([0,1])$ and $A = \set[p_k]{p_k(x) = x^k, x \in [0,1], k= 0,1, \dots}$. A is linear independant since: \\ consider
		\[
			\alpha_0 p_0 + \alpha_1 p_1 + \dots + \alpha_np_n = 0
		\]
		i.e. 
		\[
			\alpha_0 p_0(x) + \alpha_1 p_1(x) + \dots + \alpha_n p_n(x) = 0(x), \qquad x \in [0,1] 
		\]
		i.e.
		\[
			\alpha_0 + \alpha_1 x + \dots + \alpha_n x^n = 0, \qquad x \in [0,1]
		\]
		If $x = 0$ then $\alpha_0 = 0$
		\[
			\alpha_1 x + \dots + \alpha_n x^n = 0, \qquad x \in [0,1].
		\]
		Differentiate
		\[
			\alpha_1 + 2 \alpha_2 x + \dots + n \alpha_n x^{n-1} = 0
		\]
		gives $\alpha_1 = 0$. Continue and get
		\[
			\alpha_0 = \alpha_1 = \dots = \alpha_n = 0.
		\]
		Set $B \subset E$ where
		\begin{align*}
			\text{span } B &= \set{\text{set of all linear combinations of elements in B}} \\
			&= \set[\sum_{k=1}^{n}\lambda_k x_k]{x_k \in B, \lambda_k \in \mathbb{R}, k=1,2,\dots,n \text{ where n is a positive integer}}
		\end{align*}
		\begin{bemerkung}
			\[
				\sum_{k=1}^{n}\lambda_k x_k \in E
			\]
			\[
				\sum_{k=1}^{\infty} \lambda_k x_k \text{    has no meaning}
			\]
		\end{bemerkung}
		$C \subset E$ is called a basis for E if
		\begin{enumerate}[1)]
			\item $C$ linear independant.
			\item $ \text{span } C = E$
		\end{enumerate}
		continue of the example above: \\
		\minisec{Claim:}$A$ is a basis for E.
		\item Set $E = l^2$ and
		\[
			A = \set[X_k]{k =1,2,\dots}
		\]
		\[
			X_k = (0,0,\dots,0,1,0,0,\dots)
		\]
		\minisec{Claim:}A is linear independant since
		\[
			\alpha_1 X_1 + \alpha_2 X_2 + \dots + \alpha_n X_n = 0
		\]
		Here 
		\[
			\alpha_1 X_1 = (\alpha_1,0,0,\dots), \qquad etc
		\]
		and
		\[
			0 = (0,0, \dots)
		\]
		So
		\[
			(\alpha_1,\alpha_2, \dots, \alpha_n,0, \dots) = (0,0,\dots)
		\]
		So $\alpha_1= \alpha_2 = \dots = \alpha_n = 0$. \\
		Question: Is $A$ a basis for $l^2$? \\
		We note: If $X \in \text{span }A$ then
		\[
			X = (x_1,x_2, \dots,x_n,0,0,\dots)
		\]
		for some positive integer $n$, i.e. $X$ has only finitely many nonzero positions. \\
		Cosider:
		\[
			X := (1, \frac{1}{2}, \dots, \frac{1}{n}, \dots)
		\]
		\[
			\norm{X}_{l^2} = \left( \sum_{n=1}^{\infty} \frac{1}{n^2} \right)^{\frac{1}{2}} < \infty
		\]
		So $X \in l^2 \setminus \text{span }A$.
		\end{enumerate}
		\begin{bemerkung}
			Every vector space has a basis (if we are allowed to use Axiom of Choice/ zorns lemma). \\ Basis = vector space basis = Hamel basis
		\end{bemerkung}
		Assume $x_1, \dots,x_n$ is a basis for $E$. Then every basis for $E$ must contain $n$ different elements. 
		\[
			n = \dim E
		\]
		is well-defined. (System of linear equations, homogeneous with more unknowns than equations. Then there exists a nontrivial solution.)
	\end{beispiele}
\begin{definition*}[norm]
	$E$ vector space. We say that $\norm{.}: E \to [0,\infty)$ is a norm on $E$ if
	\begin{enumerate}[1)]
		\item $\norm{x}=0 \qquad \Rightarrow x =0$
		\item $\norm{\lambda x} = \abs{\lambda} \norm{x} \qquad $ for all $x \in E, \lambda \in \mathbb{R}$
		\item $\norm{x+y} \leq \norm{x} + \norm{y} \qquad $ for all $x,y \in E$
	\end{enumerate}
	
\end{definition*}
\begin{bemerkung}
	\[
		\norm{0} = \norm{0 \cdot 0} = \underset{=0}{\underbrace{\abs{0}}} \norm{0} = 0
	\]
\end{bemerkung}
\begin{beispiele}
	\begin{enumerate}[(1)]
		\item $1 < p < \infty$ and 
	\[
		\norm{X}_{l^p} = \left( \sum_{n=1}^{\infty} \abs{x_n}^p \right)^{\frac{1}{p}}
	\]
	is a norm on $l^p$. Check $1)$,$2)$ and $3)$ above:
	\begin{enumerate}[1)]
		\item \phantom{1} \[
			0 = \norm{X}_{l^p} = \left( \sum_{n=1}^{\infty} \abs{x_n}^p \right)^{\frac{1}{p}} 
		\]
		It follows
		\[
			x_n=0, \qquad n=1,2,\dots
		\]
		\[
			\Rightarrow \qquad X = (x_1,x_2, \dots) = (0,0,\dots) = 0
		\]
		\item \phantom{1}\[
			\norm{\lambda X}_{l^p} = \left( \sum_{n=1}^{\infty} \abs{\lambda x_n}^p \right)^{\frac{1}{p}} 
			= \left( \abs{\lambda}^p \sum_{n=1}^{\infty} \abs{x_n}^p \right)^{\frac{1}{p}} = \abs{\lambda} \norm{X}_{l^p}
		\]
		\item \phantom{1}\[
			\norm{X+Y}_{l^p} \leq \set{\text{Minkowski's inequality}} \leq \norm{X}_{l^p} + \norm{Y}_{l^p}
		\]
	\end{enumerate}
	\item $E = C([0,1])$ and $f \in E$
	\[
		\norm{f} = \max\limits_{t \in [0,1]} \abs{f(t)} \in [0,\infty)
	\]
	Check the axioms above
	\begin{enumerate}[1)]
		\item If $\norm{f} = 0$ it follows
		\[
			\abs{f(t)} = 0 \,\text{ for all }t \in [0,1], \qquad \Rightarrow \qquad f=0
		\]
		\item \[
			\norm{\lambda f} = \max\limits_{t \in [0,1]} \underset{\abs{\lambda}\abs{f(t)}}{\underbrace{\abs{\underset{\lambda f(t)}{\underbrace{(\lambda f)(t)}}}}}
			= \abs{\lambda} \max\limits_{t \in [0,1]} \abs{f(t)} = \abs{\lambda} \norm{f}
		\]
		\item 
		\[
			\norm{f+g} = \max\limits_{t \in [0,1]} \abs{\underset{f(t)+g(t)}{\underbrace{(f+g)(t)}}} = \max\limits_{t \in [0,1]}  \left( \abs{f(t)} + \abs{g(t)} \right)
			\leq \max\limits_{t \in [0,1]} \abs{f(t)} + \max\limits_{t \in [0,1]} \abs{g(t)} = \norm{f} + \norm{g}
		\]
	\end{enumerate}
	\item $E = C([0,1])$ and $f \in E$.
	\[
		\norm{f}_{L^1} = \int_{0}^{1} \abs{f(t)} \,\mathrm{d}t 
	\]
	defines also a norm on $E$.
	\begin{description}
		\item[3)]
		\begin{align*}
			\norm{f+g}_{L^1} &= \int_{0}^{1} \abs{\underset{f(t)+g(t)}{\underbrace{(f+g)(t)}}} \,\mathrm{d}t \\
			&\leq \int_{0}^{1}(\abs{f(t)}+ \abs{g(t)}) \,\mathrm{d}t \\
			&= \int_{0}^{1}\abs{f(t)} \,\mathrm{d}t + \int_{0}^{1}\abs{g(t)} \,\mathrm{d}t \\
			&= \norm{f}_{L^1} + \norm{g}_{L^1}
		\end{align*}
		\item[2)] \[
			\norm{\lambda f} = \int_{0}^{1} \underset{= \abs{\lambda}\abs{f(t)}}{\underbrace{\abs{(\lambda f)(t)}}} \,\mathrm{d}t = \abs{\lambda} \norm{f}_{L^1}
		\]
		\item[1)] \[
			0 = \norm{f}_{L^1} = \int_{0}^{1}\abs{f(t)} \,\mathrm{d}t
		\]
		This implies $f(t)=0$ for $t \in [0,1]$ since f is continuous! i.e. $f=0$
	\end{description}
	\end{enumerate}
\end{beispiele}
\begin{theorem}[equivalent norm]
	$E$ vector space with norms $\norm{.}$ and $\norm{.}_{*}$. We say that $\norm{.}$ and $\norm{.}_{*}$ are equivalent if there exists $\alpha, \beta >0$ such that
	\[
		\alpha \norm{x}_{*} \leq \norm{x} \leq \beta \norm{x}_{*} \qquad \text{for all }x \in E.
	\]
\end{theorem}
\begin{beispiel}
		\item $E = C([0,1])$. Choose $y = f(t)$ and $y = \abs{f(t)}$
		\[
			\norm{f} = \max\limits_{t \in [0,1]} \abs{f(t)}, \qquad \norm{f}_{*} = \norm{f}_{L^1} = \text{area}.
		\]
		Question: Are these norms equivalent? \\
		Claim $f \in C([0,1])$ 
		\[
			\norm{f}_{*} = \int_{0}^{1} \underset{\leq \norm{f}}{\underbrace{\abs{f(t)}}} \,\mathrm{d}t \leq \norm{f}
		\]
		Choose $f_n(t)$ such that
		\[
			\norm{f_n} = 1, \qquad \norm{f_n}_{*} = \frac{1}{2n}
		\]
		So 
		\[
			\frac{\norm{f_n}_{*}}{\norm{f_n}} = \frac{1}{2n} \to 0 \qquad n \to \infty
		\]
		The norms are not equivalent! Answer: NO ! 
	\end{beispiel}
\begin{theorem}
	$E$ vector space with $\dim E < \infty$.  \\
	$\Rightarrow $ All norms on $E$ are equivalent.
\end{theorem}
\begin{beweis}
	Assume $n = \dim E$ with a positive integer $n$. Let $x_1,x_2, \dots , x_n$ be a basis for $E$. For every $x \in E$
	\[
		x = \alpha_1(x)x_1 + \dots + \alpha_n(x)x_n
	\]
	where $\alpha_1(x), \dots, \alpha_n(x)$ unique. Set 
	\[
		\norm{x}_{*} = \abs{\alpha_1(x)}+ \dots + \abs{\alpha_n(x)}, \qquad x \in E
	\]
	\minisec{Claim:}$\norm{.}_{*}$ defines a norm on $E$ (easy proof) \\
	Fix an arbitrary norm $\norm{.}$ on $E$. \\
	\minisec{Claim:}$\norm{.}_{*}$ and $\norm{.}$ are equivalent. \\
	Note for $x \in E$
	\begin{align*}
		\norm{x} &= \norm{\alpha_1(x)x_1 + \dots + \alpha_n(x)x_n}  \\
		&\leq \abs{\alpha_1(x)}\norm{x_1} + \dots + \abs{\alpha_n(x)} \norm{x_n} \\
		&\leq \max\limits_{k=1,2,\dots,n} \norm{x_k} ( \underset{= \norm{x}_{*}}{\underbrace{\abs{\alpha_1(x)}+ \dots + \abs{\alpha_n(x)}}}) 
	\end{align*}
	Set $\beta = \max\limits_{k=1,2,\dots,n} \norm{x_k}$.
	Then
	\[
		\norm{x} \leq \beta \norm{x}_{*} \qquad \text{for all }x \in E.
	\]
	Remains to prove: There exists $\alpha >0$ such that
	\[
		\alpha \norm{x}_{*} \leq \norm{x} \qquad \text{for all } x \in E \qquad (*)
	\]
	Let $E$ be a vector space with norm $\norm{.}$ and $(v_m)_{m=1}^{\infty}$ a sequence in $E$. We say that $(v_m)_{m=1}^{\infty}$ converges in $(E,\norm{.})$ if there exists $v \in E$ such that $\norm{v_m-v} \to 0$ for $n \to \infty$. \\
	Notation: $v_m \to v$ in $(E, \norm{.})$. \\
	Note: If we have $\norm{.}$ and $\norm{.}_{*}$ are equivalent, then
	\[
		v_n \to v \text{ in }(E,\norm{.}) \qquad  \Leftrightarrow \qquad v_n \to v \text{ in }(E,\norm{.}_{*})
	\] 
	Back to $(*)$: Argue by contradiction. \\
	Assume there is no $\alpha >0$ such that
	\[
		\alpha \norm{x}_{*} \leq \norm{x} \qquad \text{for all } x \in E
	\]
	For $k=1,2,3,\dots$ there are $y_k \in E$ such that
	\[
		\frac{1}{k}\norm{y_k}_{*} > \norm{y_k}. \qquad (**)
	\]
	We have 
	\[
		y_k = \alpha_1^{(k)} x_1 + \dots + \alpha_n^{(k)} x_n
	\]
	where $\alpha_1^{(k)}, \dots, \alpha_n^{(k)}$ are unique scalars and $k = 1,2, \dots$. \\
	$(**)$ implies that
	\[
		k \norm{y_k} < \abs{\alpha_1^{(k)}} + \dots + \abs{\alpha_n^{(k)}}
	\]
	WLOG we can assume $\abs{\alpha_1^{(k)}}+ \dots + \abs{\alpha_n^{(k)}} = 1$. ( If not consider 
	\begin{align*}
		\lambda z &= \lambda ( \alpha_1(z)x_1+ \dots+ \alpha_n(z)x_n)  \\
		&= (\lambda \alpha_1(z))x_1 + \dots + (\lambda \alpha_n (z))x_n \\
		&= \alpha_1(\lambda z)x_1 + \dots + \alpha_n(\lambda z)x_n
	\end{align*}
	We have \[
		\alpha_k(\lambda z) = \lambda \alpha_k(z), \qquad k=1,2,\dots,n)
	\]
	We have 
	\[
		k \norm{y_k} < 1 \qquad k=1,2,\dots
	\]
	which implies $y_k \to 0$ in $(E,\norm{.})$. \\
	\begin{Large}
		\underline{IF:}
	\end{Large} \begin{align*}
		\alpha_1^{(k)} &\to \bar{\alpha_1} \\
		\alpha_2^{(k)} &\to \bar{\alpha_2} \\
		&\vdots \\
		\alpha_n^{(k)} &\to \bar{\alpha_n}
	\end{align*}
	for $k \to \infty$. Then set
	\[
		\bar{y} = \bar{\alpha_1}x_1 + \dots + \bar{\alpha_n}x_n
	\]
	and get
	\begin{align*}
		\norm{y_k-\bar{y}} &= \norm{(\alpha_1^{(k)}-\bar{\alpha_1})x_1 + \dots+ (\alpha_n^{(k)}-\bar{\alpha_n})x_n} \\
		&\leq \underset{\to 0}{\underbrace{\abs{\alpha_1^{(k)}-\bar{\alpha_1}}}}\underset{< \infty}{\underbrace{\norm{x_1}}} 
		+ \dots + \underset{\to 0}{\underbrace{\abs{\alpha_n^{(k)}-\bar{\alpha_n}}}}\underset{< \infty}{\underbrace{\norm{x_n}}} \to 0, \qquad k \to \infty
	\end{align*}
	\[
		\norm{\bar{y}} = \norm{\bar{y}-y_k + y_k} \leq \underset{\to 0}{\underbrace{\bar{y}-y_k}} + \underset{\to 0}{\underbrace{\norm{y_k}}} \to 0, \qquad k \to \infty
	\]
	So $\norm{\bar{y}} = 0$ hence $\bar{y}=0$. But
	\[
		\abs{\bar{\alpha_1}} + \abs{\bar{\alpha_2}} + \dots + \abs{\bar{\alpha_n}} = 1.
	\]
	This contradicts $x_1, \dots,x_n$ is a basis. \\
	We have for $k= 1,2, \dots$ the vector $(\alpha_1^{(k)},\alpha_2^{(k)},\dots,\alpha_n^{(k)})$ where
	\[
		\abs{\alpha_1^{(k)}}+ \dots + \abs{\alpha_n^{(k)}} = 1
	\]
	We focus on the first one and we have
	\[
		\abs{\alpha_1^{(k)}} \leq 1, \qquad k =1,2,\dots
	\]
	By Bolzano-Weierstraß then there exists a converging subsequence $(\alpha_{1,1}^{(k)})_{k=1}^{\infty}$ of $(\alpha_{1}^{(k)})_{k=1}^{\infty}$. Set
	\[
		\bar{\alpha_1} = \lim_{k \to \infty} \alpha_{1,1}^{(k)}
	\]
	consider
	\[
		(\alpha_{1,1}^{(k)},\alpha_{2,1}^{(k)}, \dots ,\alpha_{n,1}^{(k)}), \qquad k=1,2,\dots
	\]
	We have 
	\[
		\abs{\alpha_{2,1}^{(k)}} \leq 1, \qquad k=1,2,\dots
	\]
	Bolzano-Weierstraß implies that there exists a converging subsequenz $(\alpha_{2,2}^{(k)})_{k=1}^{\infty}$ of $(\alpha_{2,1}^{(k)})_{k=1}^{\infty}$. 
	Set 
	\[
		\bar{\alpha_2} = \lim_{k \to \infty} \alpha_{2,2}^{(k)}
	\]
\end{beweis}

\begin{definition*}[normed space]
	Let $E$ be a vector space over $\mathbb{R}$ or $\mathbb{C}$. $\norm{.}:E \to \mathbb{R}$ a norm on $E$ if
	\begin{enumerate}[(i)]
		\item $\norm{.} >0 \qquad $ for any $x \in E \setminus \set{0}$
		\item $\norm{\lambda x} = \abs{\lambda x} \qquad $ for any $\lambda \in \mathbb{C},x \in E$.
		\item $\norm{x+y} \leq \norm{x} + \norm{y} \qquad$ for any $x,y \in E$.
	\end{enumerate}
	Obs. $\norm{x}=0$ if $x =0$. $(E, \norm{.})$ is called a normed space. A norm generates a distance function (metric)
	\[
		L(x,y):= \norm{x-y} \qquad \text{ for any }x,y \in E.
	\]
\end{definition*}
\begin{beispiele}
	\begin{itemize}
		\item $\mathbb{R}^n$ with $\norm{x}_2 = \sqrt{\sum^{n}_{i=1}\abs{x_i}^2}$ is the eucledian norm.
		\item $C([0,1])$ continuous functions in $[0,1]$ with
		\[
			L(f,g)=\norm{f-g}_{\infty}:= \max_{x \in [0,1]}\abs{f(x)-g(x)}
		\]
	\end{itemize}
\end{beispiele}
\begin{definition*}[balls]
	 Let $x \in E$, $r >0$. Define
	\begin{align*}
		B(x,r) &:= \set[y \in E]{\norm{x-y}<r} \qquad \text{open ball} \\
		\bar{B}(x,r) &:= \set[y \in E]{\norm{x-y}\leq r} \qquad \text{closed ball}
	\end{align*}
\end{definition*}
\begin{definition*}[open/closed]
	A subset $A \subset E$ of a normed space $(E,\norm{.})$ is called \underline{open} of any point $x$ of $A$ is inner, i.e 
	\[
		\exists\,r>0 \,:\, B(x,r) \subset A.
	\]
	It is called \underline{closed} if the complement $E \setminus A$ is open.
\end{definition*}
\begin{bemerkung}
	\begin{itemize}
		\item open balls are open sets.
		\item closed balls are closed.
		\item $(C([0,1]),\norm{.}_{\infty})$ with $\norm{f}_{\infty}= \max_{x \in [0,1]}\abs{f(x)}.$ 
		\[
			A := \set[g \in C([0,1])]{f(x) < g(x),\,\forall\, x \in [0,1]}
		\]
		is an open set $C([0,1])$.
		\[
			B := \set[g \in C([0,1])]{f(x) \leq g(x),\,\forall\, x \in [0,1]}
 		\]
		is a closed set.
	\end{itemize}
	\minisec{Properties}
	\begin{itemize}
		\item Any union of open sets is an open set.
		\item Any \underline{finite} intersection of open sets is open.
		\item $\emptyset,E$ are both closed and open.
		\item Normed spaces are topological spaces.
	\end{itemize}
\end{bemerkung}
\begin{definition*}[convergence in normed spaces]
	Let $(E,\norm{.})$ be a normed space $\set{x_n}_n \subset E$. We say that $x_n$ converges to $x \in E$ if 
	\[
		\norm{x_n-x} \to 0, \qquad n \to \infty
	\]
\end{definition*}
One can define open and closed using the definition of convergence:
\begin{satz} % statement
	$A \subseteq E$ is closed if any convergent sequence in $A$ has a limit in $A$, i.e
	\[
		\substack{x_n \to x \\ \text{for }n \to \infty \\ x_n \in A} \Rightarrow x \in A
	\]
\end{satz}
\begin{beweis}
	\begin{description}
		\item[$\Rightarrow$:]Assume that $A$ is closed and $x_n \to x$. $x_n \in A$, but $x_n \not \in A$. (try to get a contradiction). \\
	 $A$ is closed $\Rightarrow $ $E \setminus A$ is open and hence $\exists\, r >0$ such that
	 \[
	 	B(x,r) \subset E \setminus A.
	 \]
	 Hence $\norm{x_n -x} \geq r$ for any $n$. This is a contradiction because in that case $x_n \not \to x$
	 \item[$\Leftarrow $:] Assume that for any sequence $\set{x_n} \subset A$ such that $x_n \to x$ we have $x \in A$. We try to get a contradiction and assume that $A$ is not closed. Hence $E \setminus A$ is not open and therefore $\exists\, x \in E \setminus A$ which is not inner.
	 \[
	 	\Rightarrow \qquad  \forall\, B(x,\frac{1}{n}) \text{ containts points outside }E \setminus A 
	 \]
	 i.e.
	 \[
	 	\exists\, x_n \in B(x, \frac{1}{n}), \, x_n \in A.
	 \]
	 We get a sequence $\set{x_n} \subset A$ such that
	 \[
	 	\norm{x_n-x} < \frac{1}{n} \qquad \Rightarrow \qquad x_n \to x
	 \]
	 This is a contradiction
	\end{description}
\end{beweis}
\begin{definition*}[closure]
	$A \subset E$. The closure of $A$ is the minimal closed subset containing $A$. We write $\bar{A}$.
\end{definition*}
\begin{proposition*}
	$\bar{A}$ is the set of all limit points of $A$ which means
	\[
		\bar{A} := \set[x \in E]{\text{there exists $\set{x_n} \subseteq A$ such that $x_n \to x$}}
	\]
\end{proposition*}
\begin{beweis}
	exercise.
\end{beweis}
\begin{definition*}[dense]
	$A \subset E$ is dense in $E$ if 
	\[
		\bar{A} = E.
	\]
\end{definition*}
\begin{bemerkung}
	This definition of dense is equivalent to the following definition:
	\[
		\forall\, x \in E,\,\forall\, \varepsilon>0 \,\exists\,y \in A \text{ such that } \norm{x-y} < \varepsilon.
	\]
\end{bemerkung}
\begin{beispiele}
	\begin{enumerate}[1)]
		\item $\mathbb{Q} \subseteq \mathbb{R}$ with $\abs{.}$ usual absolut value function. $\mathbb{Q}$ is dense in $\mathbb{R}$.
		\item $C([a,b])$. The \underline{Weirestrasstheorem} says that the set of all polynomials are dense in $(C([a,b],\norm{.}_{\infty}))$:
		\[
			\forall\, f \in C([a,b]),\,\forall\, \varepsilon>0 \,\exists\,p-\text{polynomial such that }\max_{x \in [a,b]}\abs{f(x)-p(x)} < \varepsilon.
		\]
	\end{enumerate}
\end{beispiele}
Another example is $(C_0, \norm{.}_{\infty})$ where
		\[
			C_0 = \set[x = (x_1,x_2,\dots)]{x_k \to 0 \text{ as }k \to \infty}
		\]
		\[
			\norm{x}_{\infty}= \sup_{i}\abs{x_i}
		\]
		$(C_0,\norm{.}_{\infty})$ is a normed space. 
		\[
			C_F = \set[x = (x_1,x_2,\dots)]{\text{only a finite number of }x_i \neq 0} \subset C_0
		\]
\begin{satz}
	$C_F$ is dense in $C_0$
\end{satz}
\begin{beweis}
	\[
		\forall\,  x \in C_0 \,\forall\, \varepsilon>0 \text{ must find }y \in C_F \text{ such that }\norm{y-x}_{\infty} < \varepsilon.
	\]
	\[
		x \in C_0 \qquad \Rightarrow \qquad x_k \to 0 \text{ for }k \to \infty 
	\]
	\[
		\Rightarrow \qquad \forall\, \varepsilon >0 \,\exists\,K \,\text{ such that } \abs{x_k} < \varepsilon \, \forall\, k \geq K
	\]
	Let now $y = (x_1,x_2, \dots,x_K, 0, \dots) \in C_F$. Then 
	\[
		\norm{x-y}_{\infty} = \norm{(0,0,\dots,0,x_{K+1},x_{K+2},\dots)}_{\infty} = \sup_{k >K}\abs{x_k} < \varepsilon
	\]
\end{beweis}
\begin{definition*}[separable]
	A normed space $(E,\norm{.})$ is called \underline{separable} if it contains a countable dense subset.
\end{definition*}
\begin{beispiele}
	\begin{itemize}
		\item $(\mathbb{R},\abs{.})$ is separable as $\mathbb{Q}$ is countable and dense in $\mathbb{R}$.
		\item $(\mathbb{R}^n,\norm{.}_2)$ is separable, $\mathbb{Q}^n$ is countable and dense in $\mathbb{R}$.
	\end{itemize}
\end{beispiele}
\begin{definition*}[compact set]
	For a normed space $(E,\norm{.})$ is $A \subset E$ a compact set if any sequence $\set{x_n} \subset A$ has a subsequence convergent to an element $x \in A$.
\end{definition*}
\begin{beispiel}
	 Any bounded and closed subset in $\mathbb{R}, \mathbb{R}^n, \mathbb{C}^n$ is compact. A sequence $\set{x_n}$ of a bounded set is bounded. From real Analysis one knows it has a subsequence that is convergent. If the subset is closed then the limit point is inside the set. 
\end{beispiel}
\begin{lemma*}
	$S \subset$ compact in $(E, \norm{.})$ implies that $S$ is closed and bounded.(Bounded means that $S \subset B(0,R)$ for some $R>0$)
\end{lemma*}
\begin{beweis}
	Let $S$ be a compact subset of $E$. Assume that $S$ is not bounded. Hence for any $n >0$ there exists points in $S$ which are outside $B(0,n)$, i.e. 
	\[
		\exists\, x_n \in S \,: \norm{x_n} >n.
	\]
	Then $\set{x_n}$ can not have a convergent subsequence as if $x_{n_k} \to x$ then
	\[
		n_k < \norm{x_{n_k}} = \norm{x_{n_k}-x + x} \leq \norm{x_{n_k}-x} + \norm{x} \to \norm{x}
	\]
	but $n_k \to \infty$. This is a contradiction, hence $S$ must be bounded. \\ $S$ must be closed, because if $x_n \to x$ then any subsequence converges to $x$. From the definition of compactness and uniqueness of the limit we have $x \in S$. \\
\end{beweis}
\begin{bemerkung}
	In general, $S$ bounded and closed doesn't imply that $S$ is compact. \\
For instance let $E= C([0,1])$. Then $S=\set[g \in C([0,1])]{\norm{g}_{\infty}\leq 1}$ is closed and bounded, but not compact. \\
Take $x_n(t):=t^n$. Then $x_n \in S$. $\set{x_n}$ does not have a subsequence convergent to a continuous function.
\end{bemerkung}
\begin{theorem}
	$(E,\norm{.})$ normed space and $\dim E < \infty$ \\ iff $\set{\forall\, A \subset E,\,A \text{compact} \Leftrightarrow A \text{ is closed and bounded}}$
\end{theorem}
\begin{beweis}
	\begin{description}
		\item[$\Rightarrow$:]If $\dim E < \infty$ then $A$ is compact iff $A$ is bounded and closed (exsercise)
		\item[$\Leftarrow$:]Enough to prove the following: \\
		If $\dim E = \infty$ then the unit ball $S = \set[x \in E]{\norm{x}\leq 1}$ is not compact.
	\end{description}
\begin{lemma*}[Riesz's lemma]
	If $X$ is a proper closed subspace of a normed space $(E,\norm{.})$ then for every $\varepsilon \in (0,1)$ there exists an $x_{\varepsilon} \in E$ with $\norm{x_\varepsilon}=1$ such that
	\[
		\norm{x_{\varepsilon}-x} \geq \varepsilon \qquad \forall\, x \in X.
	\]
\end{lemma*}
\begin{beweis}
	Let $z \in E \setminus X$ ($X$ proper and hence $E \setminus X \neq \emptyset$). Set 
	\[
		d:= \inf_{x \in X}\norm{z-x}
	\] As $X$ is closed, $d >0$, otherwise $z$ is a limit point in $E \setminus X$. Fix $\varepsilon \in (0,1)$. Then there exists $x_0 \in X$ such that
	\[
		d \leq \norm{z-x_0} < \frac{d}{\varepsilon}.
	\]
	Let $x_\varepsilon := \frac{z-x_0}{\norm{z-x_0}}$; We have $\norm{x_\varepsilon}=1$ and
	\begin{align*}
		\norm{x- x_\varepsilon} &= \norm{x - \frac{z-x_0}{\norm{z-x_0}}} \\
		&= \frac{\norm{x \norm{z-x_0}-z + x_0}}{\norm{z-x_0}} \\
		&= \frac{\norm{\overset{\in X}{\overbrace{x \norm{z-x_0}+ x_0 }}- z}}{\norm{z-x_0}} \\
		&\geq \frac{d}{d}\varepsilon = \varepsilon
	\end{align*}
\end{beweis}
Continue now proof of the theorem above: \\
Let $x_1 \in S$. Consider $X = \text{span} \set{x_1}$ which is a proper closed subspace of $E$. Hence by Riesz's lemma exists $x_2$ with $\norm{x_2}=1$ such that
\[
	\norm{x_2-x_1} \geq \frac{1}{2} 
\]
and
\[
	\norm{x_2-x} \geq \frac{1}{2} \qquad \forall\, x \in X.
\]
Now consider $\text{span} \set{x_1,x_2}$ which is a proper closed subspace of $E$. By Riesz's lemma follows
\[
	\exists\,x_3 \in E,\, \norm{x_3}=1: \, \norm{x_3-x_1}\geq \frac{1}{2}, \norm{x_3-x_2} \geq \frac{1}{2}.
\]
Continuing in the same fashion we get $\set{x_n}$, $\norm{x_n}=1$ such that 
\[
	\norm{x_n-x_m} \geq \frac{1}{2} \qquad \forall\, n,m,\,n \neq m.
\]
Clearly $\set{x_n} \subset S$ has no convergent subsequence. Hence $S$ is not compact.
\end{beweis}
\begin{definition*}[Cauchy sequence]
	$(E, \norm{.})$ normed space. $\set{x_n} \subseteq E$ is called Cauchy if
	\[
		\forall\, \varepsilon >0 \,\exists\,N: \,\norm{x_n-x_m}< \varepsilon \,\text{ for any }n,m \geq N.
	\]
\end{definition*}
\begin{beispiel}
	$(C_F,\norm{.}_{\infty})$, $\norm{x}_{\infty}= \sup_{k \in \mathbb{N}}\abs{x_k}$ where $x = (x_1,x_2,\dots)$. Define
	\[
		x_n = (1, \frac{1}{2}, \frac{1}{3}, \dots, \frac{1}{n}, 0, \dots)
	\]
	Then $\set{x_n}$ is Cauchy, as for $n >m$ 
	\begin{align*}
		\norm{x_n-x_m}_{\infty} &= \norm{(0, \dots,0, \frac{1}{m+1}, \dots, \frac{1}{n},0,\dots)}_{\infty} \\
		&= \frac{1}{m+1}
	\end{align*}
	Observe that $x_n$ is convergent in $(C_0,\norm{.}_{\infty})$
	\[
		\underset{\in C_F}{\underbrace{x_n}} \to (1, \frac{1}{2}, \frac{1}{3}, \dots, \frac{1}{n}, \dots) \in C_0 \setminus C_F
	\]
\end{beispiel}
\begin{satz}
	A convergent sequence is always a Cauchy sequence.
\end{satz}
\begin{definition*}[complete space]
	A normed vector space $(E, \norm{.})$ is called \underline{complete} if any Cauchy sequence in $E$ is convergent in $E$.
\end{definition*}
\begin{definition*}[Banach space]
	A complete normed space is called \underline{Banach space}.
\end{definition*}
\begin{beispiele}
	\begin{itemize}
		\item $(\mathbb{R},\abs{.})$ is a Banach space.
		\item $(\mathbb{C},\abs{.})$ as well.
		\item $(l^2,\norm{.}_2)$ where
		\[
			l^2= \set[(x_1,x_2,\dots)]{\sum^{\infty}_{i=1} \abs{x_i}^2 < \infty, x_i \in \mathbb{C}}
		\]
		and 
		\[
			\norm{(x_1,x_2,\dots)}_2 = \left( \sum_{i=1}^{\infty} \abs{x_i}^2 \right)^{\frac{1}{2}}
		\]
		$(l^2,\norm{.}_2)$ is complete.
		\begin{beweis}
			Let $x_n = (x_1^n,x_2^n,\dots)$ be a Cauchy sequence in $l^2$. We must show that it has a limit in $l^2$. We will do it in a few steps:
			\begin{enumerate}[Step 1:]
				\item Find a candidate for a limit $a$
				\item Show that $a \in l^2$.
				\item $\norm{x_n - a }_2 \to 0$ as $n \to \infty$.
			\end{enumerate}
			\begin{enumerate}[Step 1:]
				\item Let
				\begin{align*}
					x_1 &= (x_1^1,x_2^1, \dots) \\
					x_2 &= (x_1^2,x_2^2, \dots) \\
					\vdots & \qquad \vdots \\
					x_n &= (x_1^n,x_2^n, \dots)
				\end{align*}
				For each $k$ consider sequence $\set{x_k^n} \subset \mathbb{C}$ ($k$-th coordinates in each $x_n$). \\
				Each sequence is Cauchy, as for all $n,m \geq N$
				\[
					\abs{x_k^n-x_k^m} < \left( \sum_{k=1}^{\infty} \abs{x_k^n-x_k^m}^2 \right)^{\frac{1}{2}} = \norm{x_n-x_m}_2 < \varepsilon
				\]
				As $(\mathbb{C}, \abs{.})$ is complete, $\set{x_k^n}_n$ has a limit $a_k \in \mathbb{C}$. Candidate for limit of $x_n$ is 
				\[
					a= (a_1,a_2, \dots, a_k, \dots).
				\]
				\item Write 
				\[
					a = \underset{\in l^2}{\underbrace{x_n}} - (x_n - a)
				\]
				In order to show that $a \in l^2$ it is enough to see that $x_n - a \in l^2$ for some $n$. \\
				$\set{x_n}$ Cauchy implies
				\[
					\forall\, \varepsilon>0 \,\exists\,N: \,\forall\, n,m \geq N: \,\norm{x_n-x_m}_2 < \varepsilon.
				\]
				Consider for some $u>0$
				\begin{align*}
					\sum^{u}_{i=1} \abs{x_i^n-x_i^m}^2 \leq \sum_{i=1}^{\infty}\abs{x_i^n-x_i^m}^2 = \norm{x_n-x_m}^2_2 < \varepsilon^2
				\end{align*}
				Let $m \to \infty$. We get 
				\[
					\sum^{m}_{i=1} \abs{x_i^n-a_i}^2 \leq  \varepsilon^2
				\]
				This holds for any $u \in \mathbb{N}$. Hence for any $n \geq \mathbb{N}$
				\[
					\underset{= \norm{x_n-a}_2^2}{\underbrace{\sum_{i=1}^{\infty}\abs{x_i^n-a_i}^2}} \leq \varepsilon^2.
				\]
				Hence $x_n - a \in l^2$ and moreover $\norm{x_n - a} \to 0$ as $n \to \infty$.
			\end{enumerate}
		\end{beweis}
		\item $(C([a,b]),\norm{.}_{\infty})$ is a Banach space.
		\item $(l^p,\norm{.}_{l^p})$ for $1 \leq p < \infty$ are all Banach spaces.
		\item $(C([a,b]),\norm{.}_2)$ with
		\[
			\norm{f}_2 = \left( \int_{}^{} \abs{f(t)}^2 \,\mathrm{d}t \right)^{\frac{1}{2}}
		\]
		One can prove that $(C([a,b]),\norm{.}_2)$ is not a Banach space.
		\minisec{Exercise:} $[a,b] = [0,1]$ and \[
			f_n(t)= \begin{cases}
				0, &\text{ falls }t < \frac{1}{2} - \frac{1}{n}\\
				1, &\text{ falls }t > \frac{1}{2}\\
				\text{continuous linear function}
			\end{cases}.
		\]
		Show that $\set{f_n}$ is Cauchy in $C([0,1],\norm{.}_2)$ but $f_n \not \to f \in C([0,1])$.
	\end{itemize}
\end{beispiele}
\begin{definition*}[Convergent and absolutely convergent series]
	A series $\sum_{n=1}^{\infty}x_n$ in $E$ is called \underline{convergent} if $\set{\sum_{n=1}^{m}x_n}_m$, a sequence of partial sums, is convergent in $E$. If $\sum_{n=1}^{\infty}\norm{x_n} < \infty$ then we say that $\sum_{n=1}^{\infty}x_n$ converges absolutely.
\end{definition*}
\begin{theorem}
	A normed space $E$ is complete iff every absolutely convergent series converges in $E$.
\end{theorem}
\begin{beweis}
	\begin{description}
		\item[$\Rightarrow$:] Suppose $X$ is complete and $\sum_{n=1}^{\infty}\norm{x_n} < \infty$. Let 
		\[
			S_N := \sum_{n=1}^{N}x_n \in E.
		\] 
		For $M >N$:
		\begin{align*}
			\norm{S_N-S_M} &= \norm{\sum_{n=N+1}^{M}x_n} \\
			&\leq \sum_{n=N+1}^{M} \norm{x_n} \\
			&\leq \sum_{n=N+1}^{\infty} \norm{x_n} \to 0 \qquad \text{as }N \to \infty
		\end{align*}
		Hence $\set{S_N}$ is Cauchy. As $E$ is complete, $S_N$ has a limit in $E$ i.e. $\sum_{n=1}^{\infty}x_n$ converges in $E$.
		\item[$\Leftarrow$:] Assume that every absolut convergent series is convergent in $E$. We want to see that $E$ is complete. \\
		Let $\set{x_n}$ be a Cauchy sequence. We want to prove that $\set{x_n}$ has a limit in $E$. We know that
		\[
			\forall\, k \,\exists\,n_k: \, \norm{x_n-x_m}< \frac{1}{2^k} \qquad \forall\, n,m \geq n_k.
		\]
		We can assume that $\set{n_k}$ is an increasing sequence. Write
		\[
			x_{n_k} = (x_{n_k}-x_{n_{k-1}})+ (x_{n_{k-1}}-x_{n_{k-2}}) + \dots +(x_{n_1}-\underset{=0}{\underbrace{x_{n_0}}}) = \sum_{l=1}^{k}(x_{n_l}-x_{n_{l-1}}).
		\]
		\[
			\sum_{l=1}^{\infty}\norm{x_{n_l}-x_{n_{l-1}}} \leq \sum_{l=1}^{\infty}\frac{1}{2^l} < \infty
		\]
		Hence $\sum_{l=1}^{\infty}(x_{n_l}-x_{n_{l-1}})$ is absolutely convergent. By assumption 
		\[
			\sum_{l=1}^{\infty}(x_{n_l}-x_{n_{l-1}}) 
		\]
		is convergent in $E$. Hence the partial sums is convergent. Subsequence is convergent. $\set{x_{n_k}}$ is convergent to some $x \in E$.
		\minisec{Exercise:} Show that the whole $\set{x_n} \to x$.
	\end{description}
\end{beweis}
%%% 8.9.2016
\minisec{Recall:}
converging squences $(x_n)_{n=1}^{\infty}$ in $(E,\norm{.})$. $\norm{x_n-x} \to 0$ for $n \to \infty$ for some $x \in E$. (Notation: $x_n \to x$ in $(E,\norm{.})$)
\begin{bemerkung}
	Assume $x_n \to x$ in $(E,\norm{.})$ Then
	\begin{enumerate}[1)]
		\item $\norm{x_n} \to \norm{x}$ in $(E,\norm{.})$. 
		\item $\sup_{n} \norm{x_n} < \infty$.
	\end{enumerate}
	because
	\begin{enumerate}[1)]
		\item \[
			\norm{x_n} \leq \norm{x_n-x} + \norm{x}
		\]
		so
		\[
			\norm{x_n} - \norm{x} \leq \norm{x_n -x}
		\]
		it follows
		\[
			-(\norm{x_n}-\norm{x}) \leq \norm{x_n -x}
		\]
		So
		\[
			\abs{\norm{x_n}-\norm{x}} \leq \norm{x_n -x} \to 0, \qquad \text{for } n \to \infty
		\]
		Cauchy sequence in $(x_n)_{n=1}^{\infty}$ in $(E,\norm{.})$ if $\norm{x_n-x_m} \to 0$ for $n,m \to \infty$. \\
		We obtain:
	 	$(x_n)_{n=1}^{\infty}$ converges in $(E,\norm{.})$  $\qquad \Rightarrow \qquad$  $(x_n)_{n=1}^{\infty}$ Cauchy sequence in $(E,\norm{.})$. ($\not \Leftarrow $ in general).
		If $\Leftarrow$ then we call $(E,\norm{.})$ a Banach space. 
	\end{enumerate}
	$\sum_{n=1}^{\infty}x_m$ converges in $(E,\norm{.})$ if $\left( \sum_{n=1}^{k}x_n \right)_{k=1}^{\infty}$ converges in $(E,\norm{.})$. \\
	$\sum_{n=1}^{\infty}x_m$ converges absolutely in $(E,\norm{.})$ if $\sum_{n=1}^{\infty}\norm{x_n}$ converges $(\mathbb{R},\norm{.})$. \\
\end{bemerkung}

\subsection{Mappings between normed spaces} 
\label{sub:mappings_between_normed_spaces}
\begin{definition*}
	Let $(E_1,\norm{.}_1)$, $(E_2,\norm{.}_2)$ be normed spaces. $T: E_1 \to E_2$ (not necessarily linear) is called continuous at $x_0 \in E_1$, if 
	\[
		x_n \to x_0 \text{ in } (E_1,\norm{.}_1) \qquad \Rightarrow \qquad T(x_n) \to T(x_0) \text{ in } (E_2,\norm{.}_2)
	\]
	$T$ is called \underline{continuous} if it is continuous at $x_0 \in E_1$ for all $x_0 \in E_1$. We say that $T: E_1 \to E_2$ is \underline{linear} if 
	\[
		T(\lambda_1 x_1 + \lambda_2 x_2) = \lambda_1 T(x_1) + \lambda_2 T(x_2)
	\]
	for all scalars $\lambda_1$, $\lambda_2$ and $x_1,x_2 \in E_1$. \\
	$T: E_1 \to E_2$ linear is called \underline{bounded} if there exists $M>0$ such that
	\[
		\norm{T(x)}_2 \leq M \norm{x}_1 \qquad \text{for all }x \in E_1.
	\]If $T$ is bounded linear $E_1 \to E_2$ define
	\[
		\norm{T} = \norm{T}_{E_1 \to E_2} := \inf \set[M \geq 0]{\norm{T(x)}_2 \leq M \norm{x}_1 \text{ for all }x \in E_1}
	\]
\end{definition*}
\begin{lemma*}
	\[
		\norm{T} = \sup\limits_{\substack{x \in E_1 \\ x \neq 0}} \frac{\norm{T(x)}_2}{\norm{x}_1} = \sup\limits_{\substack{x \in E_1 \\ \norm{x}_1=1}} \norm{T(x)}_2
	\]
\end{lemma*}
\begin{proposition*}
	Assume $T: E_1 \to E_2$ linear. Then all the following statements are equivalent:
	\begin{enumerate}[(1)]
		\item $T$ continuous at $0 \in E_1$.
		\item $T$ continuous at $x_0 \in E_1$ for some $x_0 \in E_1$.
		\item $T$ continuous at $x_0 \in E_1$ for all $x_0 \in E_1$.
		\item $T$ is bounded.
	\end{enumerate}
\end{proposition*}
\begin{beweis}
	\begin{description}
		\item[$(1) \Rightarrow (4)$:] Assume $T$ is continuous at $0 \in E_1$. i.e. 
		\[
			x_n \to 0 \text{ in }(E_1, \norm{.}_1) \qquad \Rightarrow \qquad T(x_n) \to T(\underset{\in E_1}{\underbrace{0}}) = \underset{\in E_2}{\underbrace{0}} \text{ in }(E_2,\norm{.}_2)
		\] 
		We want to prove that $T$ is bounded. We search a $M>0$ such that
		\[
			\norm{T(x)}_2 \leq  M \norm{x}_1
		\]
		We assume that this doesn't hold true. \\
		For $n=1,2,\dots$ there exists $x_n \in E_1$ such that 
		\[
			\norm{T(x_n)}_2 > n \norm{x_n}_1.
		\]
		Set for $n=1,2,\dots$
		\[
			z_n := \frac{1}{n \norm{x_n}_1}x_n
		\]
		(Note that $\norm{x_n}_1 >0$. Otherwise we would get a contradiction.) \\
		Note
		\begin{align*}
		\norm{z_n}_1 &= \norm{\frac{1}{n \norm{x_n}_1}}_1 = \frac{1}{n \norm{x_n}_1} \norm{x_n}_1 = \frac{1}{n} \to 0, \qquad \text{for }n \to \infty
		\end{align*}
		We have $z_n \to 0$ in $(E_1,\norm{.}_1)$. But 
		\[
			\norm{T(z_n)}_2 = \norm{\frac{1}{n \norm{x_n}_1}T(x_n)_2} = \frac{1}{n \norm{x_n}_1} \norm{T(x_n)}_2 > 1 \qquad \text{ for all }n.
		\]
		Hence
		\[
			T(z_n) \not \to 0 \qquad \text{ in }(E_2, \norm{.}_2).
		\]
		This is a contradiction.
		\item[$(1) \Leftarrow (4)$:] Assume $T$ is bounded. For some $M > 0$ 
		\[
			\norm{T(x)}_2 \leq M \norm{x}_1, \qquad \text{ for all }x \in E_1.
		\] 
		We need to show that $T$ is continuous at $0 \in E_1$, i.e.
		\[
			x_n \to 0 \text{ in } (E_1, \norm{.}_1) \qquad \Rightarrow \qquad T(x_n) \to T(0) = 0 \text{ in } (E_2, \norm{.}_2)
		\]
		From \[
			\norm{T(x_n)}_2 \leq  M \norm{x_n}_1 \to 0
		\]
		so
		\[
			T(x_n) \to \underset{=T(0)}{\underbrace{0}} \text{ in }(E_2, \norm{.}_2).
		\]
	\end{description}
\end{beweis}
\begin{beispiele}
	\begin{enumerate}[(A)]
	\item 
	$E_1 = E_2 = C([0,1])$, $\norm{.}_1 = \norm{.}_2 = \norm{.}_{\infty}=: \norm{.}$, i.e.
	\[
		\norm{f} := \max \limits _{x \in [0,1]} \abs{f(x)}.
	\]
	\[
		T(f)(x) = \int_{0}^{1-x} \min(x,y)f(y) \,\mathrm{d}y, \qquad \text{for }f \in C([0,1]), x \in [0,1].
	\]
	\begin{enumerate}[(1)]
		\item $T(f) \in C([0,1])$ for $ f \in C([0,1])$,
		\item $T$ linear,
		\item $T$ bounded,
		\item Calculate $\norm{T}$.
	\end{enumerate}
	\begin{beweis}
		\begin{enumerate}[(1)]
			\item Fix $f \in C([0,1])$ arbitrary and fix $x \in [0,1]$. Show that $T(f)$ is continuous at $x$. Consider a sequence $(x_n)_{n=1}^{\infty}$ in $[0,1]$ such that $x_n \to x$ in $(\mathbb{R},\abs{.})$. \\
			To show $T(f)(x_n) \to T(f)(x)$ in $(\mathbb{R},\abs{.})$
			\begin{align*}
				\abs{T(f)(x_n)- T(f)(x)} &= \set{\text{assume that }x_n \leq x} \\
				&= \abs{\int_{0}^{1-x_n}\min(x_n,y)f(y) \,\mathrm{d}y - \int_{0}^{1-x} \min (x,y)f(y) \,\mathrm{d}y} \\
				&\leq  \abs{\int_{0}^{1-x}(\min (x_n,y) - \min(x,y) )f(y) \,\mathrm{d}y} \\ 
				&\qquad  + \abs{\int_{1-x}^{1-x_n}\min(x_n,y)f(y) \,\mathrm{d}y} \\
				&\leq \underset{\leq \abs{x_n-x} \norm{f}}{\underbrace{\int_{0}^{1-x} \underset{\leq \abs{x_n-x }}{\underbrace{\abs{\min (x_n,y) - \min(x,y)}}}
				 \underset{\leq \norm{f}}{\underbrace{\abs{f(y)}}} \,\mathrm{d}y}} \\ 
				& \qquad + \underset{0 \leq \dots \leq \abs{x_n-x}\cdot \norm{f}}{\underbrace{\int_{1-x}^{1-x_n}\underset{\leq
					 	1}{\underbrace{\min(x_n,y)}}\underset{\leq \norm{f}}{\underbrace{\abs{f(y)}}} \,\mathrm{d}y }} \to 0, \qquad \text{ as }n \to \infty
			\end{align*}
			If $x_n > x$ we get a similar calculation. Conclusion: 
			\[
				T(f)(x_n) \to T(f)(x) \text{ in }(\mathbb{R},\abs{.}) \text{ as } n \to \infty.
			\]
			\item Fix $f_1,f_2 \in C([0,1])$ and $\lambda_1, \lambda_2$ scalars. Then
			\begin{align*}
				T(\lambda_1 f_1 + \lambda_2 f_2)(x) &= \int_{0}^{1-x} \min(x,y)\underset{= \lambda_1 f_1(y)+\lambda_2 f_2(y)}{\underbrace{(\lambda_1 f_1 + \lambda_2 f_2)(y)}} \,\mathrm{d}y \\
				&= \lambda_1 \int_{0}^{1-x}\min(x,y)f_1(y) \,\mathrm{d}y + \lambda_2 \int_{0}^{1-x} \min(x,y)f_2(y) \,\mathrm{d}y \\
				&= \lambda_1 T(f_1)(x) + \lambda_2 T(f_2)(x) \qquad \text{ for }x \in [0,1]
			\end{align*}
			\item Fix $f \in C([0,1])$. For $x \in [0,1]$
			\begin{align*}
				\abs{T(f)(x)} &= \abs{ \int_{0}^{1-x} \underset{\geq 0}{\underbrace{\min(x,y)f(y)}} \,\mathrm{d}y }\\
				&\stackrel{(*_1)}{\leq} \int_{0}^{1-x}\min(x,y)\underset{\leq \norm{f}}{\underbrace{\abs{f(y)}}} \,\mathrm{d}y \\
				&\stackrel{(*_2)}{\leq} \int_{0}^{1-x} \min(x,y) \,\mathrm{d}y \norm{f}
			\end{align*}
			Clearly 
			\[
				\max\limits_{x \in [0,1]}\int_{0}^{1-x} \min(x,y) \,\mathrm{d}y \leq 1
			\]
			This gives:
			\[
				\norm{T(f)} = \max\limits_{x \in [0,1]}\abs{T(f)(x)} \leq 1 \cdot \norm{f}, \qquad \text{for all }f \in C([0,1]).
			\]
			Conclusion: $T$ is bounded with ($M=1$)
			\item Consider the unequality above. $(*_1)$ is an equality if $f$ has a constant sign. $(*_2)$ is an equality if $f$ is a constant function. So we have to calculate 
			\[
				\int_{0}^{1-x} \min(x,y) \,\mathrm{d}y \qquad \text{for }x \in [0,1].
			\]
			\begin{description}
				\item[case 1:]$1-x \leq x$ i.e. $ \frac{1}{2} \leq x$ and we get
				\begin{align*}
					\int_{0}^{1-x} \underset{=y}{\underbrace{\min(x,y)}} \,\mathrm{d}y &= \left[ \frac{1}{2} y^2 \right]_0^{1-x}  \\ &= \frac{1}{2} (1-x)^2
				\end{align*}
				\item[case 2:] $x < 1-x$ i.e. $ x < \frac{1}{2}$ and we get
				\begin{align*}
					\int_{0}^{1-x} \min(x,y) \,\mathrm{d}y &= \int_{0}^{x} y  \,\mathrm{d}y + \int_{x}^{1-x}x \,\mathrm{d}y  \\ &= \frac{1}{2}x^2 + x(1-2x) 
					\\ & = x - \frac{3}{2}x^2
				\end{align*}
				Claim 
				\[
					\norm{T} = \max \left( \max\limits_{x \in [\frac{1}{2},1]} \frac{1}{2}(1-x)^2 , \max\limits_{x \in [0,\frac{1}{2}]}\left( x - \frac{3}{2}x^2
					 \right) \right) = 
					\dots = \frac{1}{6}
				\]
				Note 
				\begin{itemize}
					\item $\norm{T(f)}\leq \norm{T} \cdot \norm{f}$ for all $f \in C([0,1])$,
					\item $\norm{T(1)} = \norm{T} \cdot \norm{1}$ where $1(x)=1$ for $x \in [0,1]$.
				\end{itemize}
			\end{description}
		\end{enumerate}
	\end{beweis}
	\item $E_1 = C([0,1])$ with maximumnorm, $E_2 = \mathbb{R}$ with absolut value. $T: E_1 \to E_2$ with
	\[
		T(f) = \int_{0}^{\frac{1}{2}}f(y) \,\mathrm{d}y - \int_{\frac{1}{2}}^{1} f(y) \,\mathrm{d}y \qquad \text{for }f \in E_1
	\]
	\begin{align*}
		\abs{T(f)} &= \abs{\int_{0}^{\frac{1}{2}}f(y) \,\mathrm{d}y - \int_{\frac{1}{2}}^{1} f(y) \,\mathrm{d}y} \\
		&\leq \abs{\int_{0}^{\frac{1}{2}}f(y) \,\mathrm{d}y} + \abs{\int_{\frac{1}{2}}^{1} f(y) \,\mathrm{d}y} \\
		&\leq \int_{0}^{\frac{1}{2}}\underset{\leq \norm{f}}{\underbrace{\abs{f(y)}}} \,\mathrm{d}y 
		+ \int_{\frac{1}{2}}^{1} \underset{\leq \norm{f}}{\underbrace{\abs{f(y)}}} \,\mathrm{d}y \\
		&\leq 1 \norm{f}
	\end{align*}
	Hence $T$ is bounded and $\norm{T}\leq 1$.
	\[
		T(f) = \int_{0}^{1}k(y)f(y) \,\mathrm{d}y 
	\]
	where 
	\[
		T(f_n)= \begin{cases}
			nachholen, &\text{ falls }case\\
			
		\end{cases}
	\]
	\[
		T(f_n) \leq 1 \left( \frac{1}{2} - \frac{1}{2n} + \frac{1}{2} - \frac{1}{2n} \right) = 1 - \frac{1}{n}, \qquad  n=1,2,\dots
	\]
	note
	\[
		k(y)f_n(y) \geq 0 \qquad \text{ for } y \in [0,1].
	\]
	Hence $\norm{T} \leq 1- \frac{1}{n}$ for $n =1,2,\dots$. Note $\norm{f_n}=1$ for all $n$. Conclusion $\norm{T}=1$. \\
	Here
	\[
		\abs{T(f)} \leq \underset{\leq 1}{\underbrace{\norm{T}}} \norm{f} \text{ for all }f \in C([0,1])
	\]
	but
	\[
		\abs{T(f)} < \norm{T} \norm{f} \qquad \text{ for all }f \in C([0,1]).
	\]
	\end{enumerate}
\end{beispiele}
\begin{satz}

	$T_1,T_2$ bounded linear mappings $(E_1,\norm{.}_1) \to (E_2,\norm{.}_2)$ and $\lambda$ scalar. Set
	\begin{align*}
		(T_1+T_2)(x) &= T_1(x) + T_2(x) \qquad x \in E_1 \\
		( \lambda T_1)(x) &= \lambda T_1(x) \qquad x \in E_1
	\end{align*}
	Claim:
	\begin{enumerate}[(1)]
		\item $T_1 + T_2$ and $\lambda T_1$ are both linear mappings $(E_1,\norm{.}_1) \to (E_2,\norm{.}_2)$,
		\item $T_1 + T_2$ and $\lambda T_1$ are both bounded mappings $(E_1,\norm{.}_1) \to (E_2,\norm{.}_2)$. \\
		$B(E_1,E_2)$ denote the vector space of all bounded linear mappings $(E_1,\norm{.}_1) \to (E_2,\norm{.}_2)$.
		\item \[
			\norm{T}_{E_1 \to E_2} := \inf \set[M > 0]{\norm{T(x)}_2 \leq M \norm{x}_1 \text{ for all }x \in E_1}
		\]
		defines a norm in $B(E_1,E_2)$.
	\end{enumerate}
\end{satz}
\begin{beweis}
	\begin{enumerate}[(1)]
		\item $\norm{T}=0$ implies that $\norm{T(x)}_2 = 0$ for all $x \in E_1$ $ \,\, \Rightarrow \,\, $ $T(x) = 0 \in E_2$.
		\[
			T = 0 \in B(E_1,E_2)
		\]
		\item $T \in B(E_1,E_2)$ and $\lambda$ scalar. 
		\begin{align*}
			\norm{\lambda T} &= \inf \set[M >0]{\norm{(\lambda T)(x)}_2 \leq M \norm{x}_1 \text{ for all }x \in E_1} \\
			&= \inf \set[M>0]{\abs{\lambda} \norm{T(x)}_2 \leq M \norm{x}_1 \text{ for all }x \in E_1} \\
			&= \set{\text{if }\lambda \neq 0} \\
			&= \inf \set[\underset{= \abs{\lambda} \tilde M}{\underbrace{M}}>0]{\norm{T(x)}_2 \leq \underset{= \tilde M}{\underbrace{\frac{M}{\abs{\lambda}}}}\norm{x}_1 \text{ for all }x \in E_1} \\
			&= \abs{\lambda} \inf \set[\tilde M >0]{ \norm{T(x)}_2 \leq \tilde M \norm{x}_1 \text{ for all }x \in E_1} \\
			&= \abs{\lambda} \norm{T}
		\end{align*}
		\item Set $T_1,T_2 \in B(E_1,E_2)$.
		\begin{align*}
			\norm{T_1+ T_2} &= \inf \set[M>0]{\norm{(T_1+T_2)(x)}_2 \leq M \norm{x}_1 \text{ for all }x \in E_1} \\
			&\leq \inf \set[M_1 + M_2>0]{\norm{T_1(x)}_2 \leq M_1 \norm{x}_1, \, \norm{T_2(x)}_2 \leq M_2 \norm{x}_1 \text{ for all }x \in E_1} \\
			&= \norm{T_1} + \norm{T_2}
		\end{align*}
	\end{enumerate}
\end{beweis}
Conclusion: $(B(E_1,B_2),\norm{.}_{E_1 \to E_2})$ is a normed space. 
\begin{satz}
	 $(B(E_1,B_2),\norm{.}_{E_1 \to E_2})$ is a Banach space if $(E_2,\norm{.}_2)$ is a Banach space.
\end{satz}
\begin{beweis}
	Assume $(T_n)_{n=1}^{\infty}$ is a Cauchy sequence in $(B(E_1,B_2),\norm{.}_{E_1 \to E_2})$ where $(E_2, \norm{.}_2)$ is a Banach space. Fix $x \in E_1$
	\begin{align*}
		\norm{T_n(x)-T_m(x)}_2 &= \norm{(T_n-T_m)(x)}_2  \\
		&\leq \underset{\substack{\to 0 \\ n,m \to \infty}}{\underbrace{\norm{T_n-T_m}_{E_1 \to E_2}}} \cdot \norm{x}_1 \to 0, \qquad n,m \to \infty
	\end{align*}
	Hence $(T_n(x))_{n=1}^{\infty}$ is a Cauchy sequence in $(E_2, \norm{.}_2)$. This is a Banach space which implies that $(T_n(x))_{n=1}^{\infty}$ converges in 
	$(E_2,\norm{.}_2)$. Call the limit $T(x) \in E_2$ for all $x \in E_1$. Show now 
	\begin{enumerate}[(1)]
		\item $T: E_1 \to E_2$ is linear,
		\item $T$ is bounded,
		\item $\norm{T_n - T}_{E_1 \to E_2} \to 0$ for $n \to \infty$.
	\end{enumerate}
	\begin{enumerate}[(1)]
		\item Observe 
		\begin{align*}
		T(\lambda_1 x_1 + \lambda_2 + x_2)\leftarrow T_n(\lambda_1 x_1 + \lambda_2 x_2) = \set{T \text{ linear}} = \underset{\to \lambda_1 T(x_1) + \lambda_2 T(x_2)}{\underbrace{\underset{\to \lambda_1 T(x_1)}{\underbrace{\lambda_1 \underset{\to T(x_1)}{\underbrace{T_n(x_1)}}}} + \underset{\to \lambda_2 T(x_2)}{\underbrace{\lambda_2 \underset{\to T(x_2)}{\underbrace{T_n(x_2)}}}}}}
		\end{align*}
		So for $n \to  \infty$ it is
		\[
			T(\lambda_1 x_1 + \lambda_2 + x_2) = \lambda_1 T(x_1) + \lambda_2 T(x_2) \qquad \text{ in }(E_2, \norm{.}_2).
		\]
		\item Fix $\varepsilon >0$. Then there exists $N$ such that:
		\[
			\norm{T_n- T_m}_{E_1 \to E_2} < \varepsilon \qquad \text{for }n,m \geq N
		\]
		So for $x \in E_1$
		\[
			\norm{T_n(x)-T_m(x)}_2 \leq \norm{T_n - T_m}_{E_1 \to E_2} \norm{x}_1 < \varepsilon \norm{x}_1 \qquad \text{for }n,m \geq N
		\]
		Let $m \to \infty$.
		\[
			\norm{T_n(x)- T(x)}_2 \leq \varepsilon \norm{x}_1 \qquad \text{for }n \geq N
 		\]
		So
		\begin{align*}
			\norm{T(x)}_2 &\leq  \norm{T(x)- T_N(x)}_2 + \norm{T_N(x)}_2 \\
			&\leq \varepsilon \norm{x}_1 + \norm{T_N}_{E_1 \to E_2} \cdot \norm{x}_1 \\
			&= \left( \varepsilon +  \norm{T_N}_{E_1 \to E_2} \right) \norm{x}_1 \qquad \text{for }x \in E_1
		\end{align*}
		\item Look above and get
		\[
			\norm{T_n - T}_{E_1 \to E_2} \to 0, \qquad  n \to \infty.
		\]
	\end{enumerate}
\end{beweis}
\begin{theorem}[Banach-Steinhaus theorem (uniform boundedness principle)]
	$(E_1,\norm{.}_1)$ Banach space, $(E_2,\norm{.}_2)$ normed space and $\mathcal{F} \subset B(E_1,E_2)$. Assume
	\[
		\sup\limits_{T \in \mathcal{F}}\norm{T(x)}_2 < \infty \qquad \text{for all } x \in E_1
	\]
	then
	\[
		\sup\limits_{T \in \mathcal{F}}\norm{T}_{E_1 \to E_2} < \infty.
	\]
	\end{theorem}
	\begin{bemerkung}
		The implication $\Leftarrow$ is easy to prove. If $\mathcal{F}$ is a finite set, the theorem is trivial.
	\end{bemerkung}
	\begin{beweis}
		\begin{enumerate}[step 1:]
			\item Assume 
			\[
				\exists\,x_0 \in E_1\, \exists\, r >0 \,\exists\, M>0: \,\forall\, x \in \overline{B(x_0,r)} \, \forall\,  T \in \mathcal{F}: \,\norm{T(x)}_2 \leq M
			\]
			We have to show that 
			\[
				\sup\limits_{T \in \mathcal{F}} \norm{T}_{E_1 \to E_2} < \infty.
			\]
			Fix $T \in \mathcal{F}$. For $\norm{x}_1 \leq r$
			\[
				\norm{T(x_0+x)}_2 \leq M
			\]
			Note that $x_0+x \in \overline{B(x_0,r)}$.
			\begin{align*}
				\norm{T(x)}_2 &= \norm{T(x_0+x-x_0)}_2 \\ &= \set{T \text{ linear}} \\ &= \norm{T(x_0 + x)-T(x_0)}_2 \\ &\leq \norm{T(x_0+x)}_2 +
				\norm{T(x_0)}_2 \\ &\leq 2M
			\end{align*}
			For $0 \neq x \in E_1$ 
			\[
				\norm{T \left( \frac{r}{\norm{x}_1} x \right)}_2 \leq 2M
			\]
			$\frac{r}{\norm{x}_1} $ has the $\norm{.}_1$-norm equal to $r$. This implies , since T linear,
			\[
				\frac{r}{\norm{x}_1} \norm{T(x)}_2 \leq 2M
			\]
			i.e.
			\[
				\norm{T(x)}_2 \leq \frac{2M}{r}\norm{x}_1 \qquad \text{for all }0 \neq x \in E_1.
			\]
			We have
			\[
				\norm{t}_{E_1 \to E_2} \leq \underset{\substack{\text{independant}\\ \text{of }T}}{\underbrace{\frac{2M}{r}}} < \infty
			\]
			\[
				\sup\limits_{T \in \mathcal{F}}\norm{T}_{E_1 \to E_2} \leq \frac{2M}{r} < \infty
			\]
			\item Justify the assumption in step 1. This assumption is equivalent to
			\[
			\exists\,x_0 \in E_1\, \exists\, r >0 \,\exists\, M>0: \,\forall\, x \in B(x_0,r) \, \forall\,  T \in \mathcal{F}: \,\norm{T(x)}_2 \leq M	
			\]
			(Note $\overline{B(x_0,r_1)} \subset B(x_0,r) \subset B(x_0,r_2)$ for $0 < r_1 < r < r_2$). \\
			Argue by contradiction. Assume that the assumption is false. Then it holds
			\[
				\forall\, x_0 \in E_1 \, \forall\, r >0 \,\forall\,  M>0: \,\exists\, x \in B(x_0,r) \,\exists\, T \in \mathcal{F} : \, \norm{T(x)}_2 > M.
			\]
			Idea: Find a converging sequence $x_n \in E_1$, $x_n \to x$ in $(E_1,\norm{.}_1)$ and a sequence $(T_n)_{n=1}^{\infty} \subset \mathcal{F}$ such that
			\[
				\norm{T_n(x_n)}_2 > n \qquad \text{for all }n, \qquad \text{and} \qquad \norm{T_n(x)}_2 > n \qquad \text{ for all }n.
			\]
			We have from above $x_1 \in B(0,1)$ and $T_1 \in  \mathcal{F}$ such that \[
				\norm{T_1(x_1)}_2 > 1.
			\] $T_1$ is bounded linear, hence continuous. This implies that there exists $0<r_1 < \frac{1}{2}$ such that
			\[
				\norm{T_1(x)}_2 >1 \qquad \text{for }x \in B(x_1,r_1)
			\]
			and \[
				\overline{B(x_1,r_1)}\subset B(0,1).
			\]
		\end{enumerate}
	\end{beweis}
\subsection{Fixed point theory} 
\label{sub:fixed_point_theory}
\begin{beispiel}
	Consider
	\[
		f(x)+ 5 \int_{0}^{1-x} \min(x,y)f(y) \,\mathrm{d}y = g(x), \qquad x \in [0,1] \qquad (*)
	\]
	where $g \in C([0,1])$. \\ 
	\minisec{Claim:}There exists an unique solution $f \in C([0,1])$ that $(*)$. \\
	Idea:
	\[
		f(x) = f(x) - 5 \int_{0}^{1-x} \min(x,y)f(y) \,\mathrm{d}y, \qquad x \in [0,1]
	\]
	Set für $x \in [0,1]$ 
	\[
			\tilde T(f)(x) = RHS(x)
	\]
	To find a solution to $(*)$ is the same finding $f \in C([0,1])$ such that 
	\[
		f = \tilde T(f)
	\]
	Clearly $ \tilde T : C([0,1]) \to C([0,1])$. (continual later).
\end{beispiel}

\begin{theorem}[Banach's fixed point theorem]
	$(E, \norm{.})$ Banach space. $T: E \to E$ (no assumption on linearity) is a contraction on $E$, i.e. there exists $c>1$ such that
	\[
		\norm{T(x)-T(\tilde x)} \leq c \norm{x- \tilde x} \qquad \text{for all }x,\tilde x \in E.
	\]
	Then there exists a unique $ \bar{x} \in E$ such that 
	\[
		\bar{x} = T( \bar{ x})
	\]
	($\bar{x}$ is a fixed point)
\end{theorem}
\begin{beweis}
	\begin{description}
		\item[Uniqueness:]Assume $T( \bar{x}) = \bar{x}$ and $T ( \tilde x) = \tilde x$. Then
		\[
			\underset{\geq 0}{\underbrace{\norm{ \bar{ x} - \tilde x }}} = \norm{T( \bar{x})- T( \tilde x)} \leq \underset{< 1}{\underbrace{c}} \norm{ \bar{x}- \tilde x}
		\] 
		Thus $\norm{\bar{x}- \tilde x} = 0$, i.e. $\bar{x} = \tilde x$.
		\item[Existence] Pick an arbitrary $x_0 \in E$. Set
		\[
			x_{n+1} = T(x_{n}), \qquad n=0,1,2,\dots
		\]
		\minisec{Claim:}$(x_n)_{n=1}^{\infty}$ is a Cauchy sequence in $(E,\norm{.})$.
		Note:
		\begin{align*}
			\norm{x_{n+1}-x_n}  &= \norm{T(x_n)-T(x_{n-1})} \\
			&\leq  c \norm{x_n - x_{n-1}} \\
			&\leq \dots \\
			&\leq  c^n \norm{x_1-x_0}, \qquad n=1,2,\dots 
		\end{align*}
		For $n>m$
		\begin{align*}
			\norm{x_n-x_m} &= \norm{x_n - x_{n-1}+ x_{n-1}- \dots + x_{m+1}- x_m} \\
			&\leq \norm{x_n - x_{n-1}} + \norm{x_{n-1} - x_{n-2}} + \dots + \norm{x_{m+1}- x_m} \\
			&\leq (c^{n-1}+ c^{n-2} + \dots c^m) \norm{x_1-x_0} \\
			&\leq \frac{c^m}{1-c} \norm{x_1 - x_0} \to 0 \qquad \text{as }n,m \to \infty
		\end{align*}
		Hence $(x_n)_{n=1}^{\infty}$ is a Cauchy sequence in $(E,\norm{.})$. $(E, \norm{.})$ is a Banach space. So $(x_n)_{n=1}^{\infty}$ converges in $(E,\norm{.})$. Call the limit $\bar{x}$. \\
		\minisec{Claim:}$\bar{x}$ is a fixed point for $T$. 
		\begin{align*}
			\norm{\bar{ x}- T(\bar{x})} & = \norm{\bar{x}-x_{n+1}+ x_{n+1} - T(\bar{x})} \\
			&\leq \norm{\bar{x}-x_{n+1}} + \norm{\underset{T(x_n)}{\underbrace{x_{n+1}}} - T(\bar{x})} \\
			&\leq \underset{\to 0}{\underbrace{\norm{\bar{x}- x_{n+1}}}} + c \underset{\to 0}{\underbrace{\norm{x_n - \bar{x}}}} \to 0, \qquad n \to \infty
		\end{align*}
	\end{description}
\end{beweis}
\begin{bemerkung}
	\begin{enumerate}[(1)]
		\item $x_n \to \bar{x}$ for $n \to \infty$ independend of the choice of $x_0$
		\item Fix $z \in E$
		\begin{align*}
			\norm{\bar{x}-z} &= \norm{T(\bar{x})- T(z) + T(z) -z} \\
			&\leq \norm{T(\bar{x})-T(z)} + \norm{T(z) -z} \\
			&\leq c \norm{\bar{x}-z} + \norm{T(z) - z} 
		\end{align*}
		Hence 
		\[
			\norm{\bar{x}-z} \leq \frac{1}{1-c}\norm{T(z)-z}
		\]
	\end{enumerate}
\end{bemerkung}
\begin{beispiel}
	Consider now the example from above: $(C([0,1]), \norm{.})$ with $\norm{f} = \max_{x \in [0,1]}\abs{f(x)}$ is a Banach space! To apply Banach's fixed point theorem we need $\tilde T$ to be a contraction. \\
	Fix $f_1,f_2 \in C([0,1])$ and get for $x \in [0,1]$
	\begin{align*}
		\abs{(\tilde T(f_1)- \tilde T(f_2))(x)} & = \abs{5 \int_{0}^{1-x} \min(x,y)f_2(y) \,\mathrm{d}y - 5 \int_{0}^{1-x}\min(x,y)f(y) \,\mathrm{d}y} \\
		&= \abs{5 \int_{0}^{1-x} \min(x,y)(f_2(y)-f_1(y)) \,\mathrm{d}y} \\
		&\leq 5 \int_{0}^{1-x} \min(x,y) \underset{\leq \norm{f_2-f_1}}{\underbrace{\abs{f_2(y)-f_1(y)}}} \,\mathrm{d}y \\
		&\leq 5 \underset{0 \leq  \dots \leq \frac{1}{6}}{\underbrace{\int_{0}^{1-x} \min(x,y)\,\mathrm{d}y}} \norm{f_2-f_1} \\
		&\leq \frac{5}{6} \norm{f_2-f_1} 
	\end{align*}
	Hence \[
		\norm{\tilde T(f_1)- \tilde T(f_2)} \leq \frac{5}{6} \norm{f_1-f_2}
	\]
	We conclude that $\tilde T$ is a contraction. We can take $c = \frac{5}{6}$. By Banach's fixed point theorem $\tilde T$ has a unique fixed point. Finally $(*)$
	has a unique solution $f \in C([0,1])$ which is the fixed point. 
\end{beispiel}
\begin{theorem}[Banach's fixed point theorem (generalization)]
	$(E, \norm{.})$ Banach space. $T: F \to F$ where $F$ is a closed set in $E$. $N$ positive integer. Assume $T^N = \underset{N-\text{times}}{\underbrace{T \circ T \circ \dots \circ T}}$ is a contraction on $F$, i.e. there exists $c > 1$ such that
	\[
		\norm{T^N(x)- T^N(\tilde x)} \leq c \norm{x-\tilde x}, \qquad \text{for all }x, \tilde x \in F.
	\]
	Then $T$ has unique fixed point $\bar{ x}$, i.e.
	\[
		\bar{x} = T(\bar{x}) \in F
	\]
\end{theorem}
\begin{beweis}
	\begin{description}
		\item[$N=1$:] Fix $x_0 \in F$ and consider $(x_n)_{n=1}^{\infty}$ where $x_{n+1} = T(x_n)$ for $n=0,1,2, \dots$. There $(x_n)_{n=1}^{\infty}$ is a Cauchy sequence and hence this converges in $E$ since this is a Banach space. Call the limit $\bar{x}$. Note
		\[
			\underset{\in F}{\underbrace{x_n}} \to \bar{x} \text{ in }E \text{ and $F$ is closed}
		\] 
		implies $\bar{x} \in F$. The rest of the argument is the same as before.
		\item[$N>1$:] By previous result we know that $T^N$ has a unique fixpoint $\bar{x} \in F$, i.e. $\bar{x} = T^N(\bar{x})$. \\
		\minisec{Claim:}$\bar{x}$ is a fixed point for $T$.
		\begin{align*}
			\norm{T(\bar{x})-\bar{x}} &= \norm{T(T^N(\bar{x}))- T^N(\bar{x})} \\
			&= \norm{T^N(T(\bar{x}))- T^N(\bar{x})} \\
			&\leq c \norm{T(\bar{x})-\bar{x}}
 		\end{align*}
		This gives 
		\[
			\norm{T(\bar{x}-\bar{x})} = 0, \qquad \text{i.e. }\bar{x} = T(\bar{x}).
		\]
		Existence of a fixed point for $T$ done. For the uniqueness assume $\bar{x} = T(\bar{x})$ and $\tilde x = T( \tilde x)$. Then
	\begin{align*}
		\bar{x} &= T( \bar{x}) = T^2(\bar{x}) = \dots = T^N(\bar{x}) \\
		\tilde x &= T(\tilde x) = T^2(\tilde x) = \dots = T^N(\tilde x)
	\end{align*}
	But $T^N$ has a unique fixed point so 
	\[
		\bar{x} = \tilde x
	\]
	\end{description}
\end{beweis}
\begin{bemerkung}
	\begin{enumerate}[(1)]
		\item $T: (0,1] \to (0,1]$ where $T(x) = \frac{x}{2}$. Clearly $T$ is a contraction on $(0,1]$ but has no fixed point. Note that $(0,1]$ is not a closed intervall. 
		\item $T: [0,\infty) \to [0,\infty)$, where $T(x) = x + \frac{1}{x}$. Clearly $[0,\infty)$ is a closed intervall in $\mathbb{R}$ but $T$ has no fixed point. \\
		\minisec{Claim:}$T$ is not a contraction but 'close' to be a contraction. \\
		\begin{align*}
			\abs{T(x)-T(\tilde x)} < \abs{x- \tilde x} \qquad \text{for }x, \tilde x \in [1, \infty), x \neq \tilde x
		\end{align*}
		Note \[
			\abs{ T(x)- T( \tilde x)} = \abs{\underset{\substack{(1- \frac{1}{t})\leq 1 \\ \text{for }t \in [1,\infty)}}{\underbrace{T'(x)}}}\abs{x- \tilde x}
		\] for some $t$ betweeen $x$ and $\tilde x$.
	\end{enumerate}
\end{bemerkung}
\begin{beispiel}
	$(E,\norm{.})$ Banach space. $K$ compact set in $E$ and $T : K \to K$ where
	\[
		\norm{T(x)- T( \bar{x})} < \norm{x - \bar{x}} \qquad \text{for all }x, \bar{x} \in K, x \neq \bar{x}.
	\]
	Show: $T$ has a unique fixed point in $K$.
	\begin{description}
		\item[Uniqueness:] Assume $\bar{x} = T(\bar{x})$ and $\tilde x = T( \tilde x)$ and $\bar{x} \neq \tilde x$ for $ \bar{x}, \tilde x \in K$. Then
		\[
			\norm{\bar{x} - \tilde x} = \norm{ T( \bar{ x})- \tilde x} < \norm{ \bar{x}- \tilde x}
		\]
		Contradiction because then $\bar{x} = \tilde x$.
		\item[Existence:] To show: There exists $x \in K$ such that $x = T(x)$, i.e.
		\[
			\norm{T(x)- x} = 0.
		\]
		Set $d := \inf_{x \in K} \norm{T(x)-x}$. Let $(x_n)_{n=1}^{\infty}$ be a sequence in $K$ such that 
		\[
			\norm{T(x_n)-x_n} \to d, \qquad \text{as }n \to \infty.
		\]
		$K$ compact implies that there exists a subsequence $(\tilde x_n)_{n=1}^{\infty}$ of $(x_n)_{n=1}^{\infty}$ such that $(\tilde x_n)_{n=1}^{\infty}$ converges in $K$. Call the limit element $\bar{x} \in K$. We know
		\[
			\tilde x_n \to  \bar{x} \qquad \text{in }K
		\]
		and	 
		\[
			\norm{T( \tilde x_n)- \tilde x_n} \to d.
		\]
		Question: \[
			T(\tilde x_n) \to T(\bar{x}) \qquad \text{ in }K?
		\]
		But since
		\[
			\norm{T(x)- T( \tilde x)} \leq  \norm{x- \tilde x} \qquad \text{ for all }x, \tilde x \in K
		\]
		we have 
		\[
			\tilde x_n \to \bar{x} \qquad \text{ in }K
		\]
		which implies
		\[
			T( \tilde x_n) \to T( \bar{ x}) \text{ in }K.
		\]
		Hence: 
		\[
			\norm{T( \bar{ x})- \bar{x}} \leftarrow \norm{T(\tilde x_n)- \tilde x_n} \to d, \qquad  n \to  \infty.
		\]
		We obtain
		\[
			\norm{T(\bar{x})- \bar{x}} = d.
		\]
		Question: Is $d=0$? \\
		If $d>0$ then $\bar{x} \neq  T( \bar{x})$, $\bar{x}, T( \bar{x}) \in K$
		\[
			\norm{T(\bar{x})- T(T(\bar{x}))} < \norm{\bar{x}- T(\bar{x})} = d = \inf_{x \in K} \norm{x- T(x)}.
		\]
		This is a contradiction which gives $d=0$ and so $\bar{x} = T(\bar{x})$.
	\end{description}
\end{beispiel}
\begin{beispiel}
	Consider
	\[
		f(x) = \int_{0}^{x}k(x,y)h(y,f(y)) \,\mathrm{d}y + g(x), \qquad x \in [0,1] \qquad (*)
	\]
	where $g \in C([0,1])$, $k \in C([0,1] \times [0,1])$ and $h: [0,1] \times \mathbb{R} \to \mathbb{R}$ continuous and satisfies: \\
	There exists $M>0$ such that
	\[
		\abs{h(x,z_1)-h(x,z_2)} \leq M \abs{z_1- z_2} \qquad \text{for all }x \in [0,1],\,z_1,z_2 \in \mathbb{R}
	\]
	\minisec{Claim:}$(*)$ has a unique solution $f \in C([0,1])$. For $f \in C([0,1])$ set
	\[
		T(f)(x) = \int_{0}^{x}k(x,y)h(y,f(y)) \,\mathrm{d}y + g(x) \qquad x \in [0,1].
	\]
	Here $T(f)(x) \in C([0,1])$. \\ Want to show: $T: C([0,1]) \to C([0,1])$ has a unique fixed point. \\
	Start with the Banach space $(C([0,1]), \text{max-norm})$. Check if $T$ is a contraction in $C([0,1])$. Fix $f_1,f2 \in C([0,1])$
	\[
		T(f_1)(x)- T(f_2)(x) = \int_{0}^{x} k(x,y)(h(y,f_1(y))-h(y,f_2(y))) \,\mathrm{d}y
	\] 
	$k$ is continuous on the compact set $[0,1] \times [0,1]$ so 
	\[
		\sup\limits_{(x,y) \in [0,1]\times[0,1]} \abs{k(x,y)} =: N < \infty.
	\]
	We obtain 
	\begin{align*}
		\abs{(T(f_1)-T(f_2))(x)} &\leq \int_{0}^{x} \underset{\leq N}{\underbrace{\abs{k(x,y)}}}\underset{\leq M \underset{\leq \norm{f_1-f_2}}{\underbrace{f_1(y)-f_2(y)}}}{\underbrace{h(y,f_1(y))-h(y,f_2(y))}} \,\mathrm{d}y \\ & \leq \int_{0}^{x}NM \,\mathrm{d}y \norm{f_1-f_2} \\& \leq NM \norm{f_1-f_2}
		\end{align*}
	this yields
	\[
		\norm{T(f_1)-T(f_2)} \leq NM \norm{f_1-f_2}.
	\]
	\underline{IF:} \,$NM<1$ Then $T$ is a contaction. \\ Trick: For $a >0$ set 
	\[
		\norm{f}_a = \max\limits_{x \in [0,1]} e^{-ax}\abs{f(x)}
	\] 
	for $f \in C([0,1])$. \\
	\minisec{Claim:}$\norm{.}_a$ defines a norm on $C([0,1])$. This is easy to check. \\
	\minisec{Claim:}$\norm{.}$ and $\norm{.}_a$ are equivalent. \\
	This follows from
	\[
		e^{-a} \norm{f} \leq \norm{f}_a \leq \norm{f}
	\]
	for all $f \in C([0,1])$ (note that $\norm{.}$ is the max-norm).\\
	\minisec{Claim:}$(C([0,1]), \norm{.}_a)$ is a Banach space. \\
	This follows from the fact that $\norm{.}$ und $\norm{.}_a$ are equivalent and $(C([0,1]),\norm{.})$ is a Banach space. \\
	\minisec{Claim:}$T$ is a contraction on $(C([0,1]),\norm{.}_a)$ for $a >0$ large enough. \\
	For $f_1,f_2 \in C([0,1])$ and $x \in [0,1]$ we have
	\begin{align*}
		\abs{(T(f_1)-T(f_2))(x)} &\leq \int_{0}^{x} NM \abs{(f_1-f_2)(y)} \,\mathrm{d}y \\
		&= \int_{0}^{x}NM e^{ay} \cdot \underset{\leq \norm{f_1-f_2}_a}{\underbrace{e^{-ay} \abs{(f_1-f_2)(x)}}} \,\mathrm{d}y \\
		&\leq NM \underset{\frac{1}{a}(e^{ax}-1)}{\underbrace{\int_{0}^{x} e^{ay} \,\mathrm{d}y}} \norm{f_1-f_2}_a 
	\end{align*}
	So
	\[
		e^{-ax} \abs{(T(f_1)-T(f_2))(x)} \leq \frac{NM}{a}(1-e^{-ax})\norm{f_1-f_2}_a
	\]
	and
	\[
		\norm{T(f_1)-T(f_2)}_a \leq  \frac{NM}{a} \norm{f_1-f_2}_a
	\]
	For $a > NM$ is $T$ a contraction on $(C([0,1]),\norm{.}_a)$. Banach fixed point theorem implies that there is a unique $f \in C([0,1])$ that solves $(*)$.
\end{beispiel}
%%% 15.9.2016
\begin{theorem}
	$(E,\norm{.})$ Banach space, $(Y,\norm{.})$ normed space. $T: E \times Y \to E$ where
	\begin{enumerate}[(1)]
		\item There exists a $C > 1$ such that
		\[
			\norm{T(x,y)-T(\tilde x,y)} \leq C \norm{x - \tilde x} \qquad \text{for all }x, \tilde x \in E,\, y \in Y.
		\]
		\item $T_x: Y \to E$ where $T_x(y)= T(x,y)$ is continuous for all $x \in E$.
	\end{enumerate}
	$\Rightarrow $ For every $y \in Y$ there exists a unique $g(y) \in E$ such that \[
		g(y)= T(g(y),y)
	\] and $g: Y \to E$ is continuous.
\end{theorem}
\begin{beweis}
	The existence of a unique element $g(y) \in E$ for every $y \in Y$ follows from Banach's fixed point theorem. \\
	Assume $y_n \to \tilde y$ in $(Y, \norm{.}_{*})$, i.e. \[
		\norm{y_n - \tilde y}_* \to 0, \qquad n \to \infty
	\]
	Remains to show
	\[
		g(y_m) \to g(\tilde y) \qquad \text{ in }(E(,\norm{.}))
	\]
	\begin{align*}
		\norm{g(y_n)- g( \tilde y)} &= \norm{T(g(y_n),y_n) - T(g(\tilde y), \tilde y)} \\
		&\leq  \underset{ \stackrel{(1)}{\leq } c \norm{g(y_n)-g(\tilde y)}}{\underbrace{\norm{T(g(y_n),y_n) - T(g( \tilde y),y_n)}}} + 
		\underset{^{(2)}\to 0, \, n \to \infty}{\underbrace{\norm{T(g(\tilde y),y_n)- T(g(\tilde y),\tilde y)}}}
	\end{align*}
	We obtain
	\[
		\norm{g(y_n)-g(\tilde y)} \leq \frac{1}{1-c} \norm{T(g(\tilde y), y_n) - T(g(\tilde y),\tilde y)} \to 0, \qquad n \to \infty.
	\]
\end{beweis}

\begin{theorem}[Brouwer's fixed point theorem]
	$K$ compact ($=$ closed and bounded) convex subset of $\mathbb{R}^n$ and $T: K \to K$ continuous. Then $T$ has a fixed point, i.e. there exists $\bar{x} \in K$ with
	\[
		T(\bar{x}) = \bar{x}.
	\]
\end{theorem}
\begin{bemerkung}
	\begin{itemize}
		\item No uniqueness! Consider the case $T= \id_K$.
		\item Set $K \subseteq \mathbb{R}^n$ (in general) is convex if
		\[
			x, \tilde x \in K \text{ and } \lambda \in [0,1] \qquad \Rightarrow \qquad \lambda x + ( 1- \lambda)\tilde x \in K.
		\]
	\end{itemize}
\end{bemerkung}

\begin{theorem}[Perron's theorem]
	$A$ real-valued $n \times n$-Matrix with positive entries. $A = [a_{ij}]_{i,j=1, \dots,n}$ all $a_{ij}>0$. \\
	$\Rightarrow $ The mapping for $x \in \mathbb{R}^n$ 
	\[
		x \mapsto Ax
	\]
	has an eigenvalue $>0$ with an eigenvecto with positive entries, i.e. there exists $\lambda >0$ and $\tilde x \in \mathbb{R}^n$ with $A \tilde x = \lambda \tilde x$and all entries in $\tilde x$ are positive.
\end{theorem}

\begin{beweis}
We use Brouwer's fixed point theorem. Set \[
	K := \set[(x_1,x_2,\dots,x_n) \in \mathbb{R}^n]{x_k \geq 0, \, \sum^{n}_{i=1} x_i = 1}
\]	
\minisec{Claim:}$K$ is closed, bounded and a convex set in $\mathbb{R}^n$. Thus $K$ is compact (since $K \subseteq \mathbb{R}^n$). Set
\[
	T(x_1,\dots,x_n) = \underset{\in K}{\underbrace{\frac{1}{\norm{Ax}_{l^1}}A \cdot \begin{pmatrix}
		x_1 \\ \vdots \\ x_n
	\end{pmatrix}}} \qquad \text{for all }(x_1,\dots,x_n) \in K
\]
\minisec{Claim:}$T: K \to K$ is continuous. \\
Since
\[
	x_k \to x \qquad \text{ in } K \text{ w.r.t. }l^1-\text{norm}.
\]
To show:
\[
	T(x_k) \to T(x) \qquad \text{ in } K \text{ w.r.t. }l^1-\text{norm}.
\]
Set
\begin{align*}
	x &= (x_1,x_2, \dots,x_n) \\
	x_k &= (x_1^{(k)},x_2^{(k)}, \dots, x_n^{(k)}) \qquad k = 1,2,\dots.
\end{align*}
Consider
\begin{align*}
	\norm{T(x_k)-T(x)}_{l^1} &= \norm{ \frac{1}{\norm{Ax_k}_{l^1}} A x_k - \frac{1}{\norm{Ax}_{l^1}} A x }_{l^1} \\
	&\leq  \norm{\frac{1}{\norm{Ax_k}_{l^1}} A x_k - \frac{1}{\norm{Ax}_{l^1}} A x_k}_{l^1} + \norm{\frac{1}{\norm{Ax}_{l^1}} A x_k - \frac{1}{\norm{Ax}_{l^1}} A x}_{l^1} \\
	&= \abs{\frac{1}{\norm{Ax_k}_{l^1}} - \frac{1}{\norm{Ax}_{l^1}}} \norm{A x_k}_{l^1} + \frac{1}{\norm{Ax}_{l^1}} \norm{A(x -x_k)}_{l^1}
\end{align*}
and
\begin{align*}
	\norm{A(x-x_k)}_{l^1} &= \sum^{n}_{i=1} \abs{ \sum^{n}_{j=1} a_{ij}(x_j-x_j^{(k)})} \\
	&\leq  \sum^{n}_{i=1} \sum^{n}_{j=1} a_{ij} \abs{x_j-x_j^{(k)}} \\
	&\leq \underset{< \infty}{\underbrace{n \cdot \max\limits_{i,j} a_{ij}}} \underset{\to 0}{\underbrace{\norm{x-x_k}_{l^1}}} \to 0, \qquad k \to \infty
\end{align*}
So \[
	Ax_k \to Ax \qquad \text{in }l^1.
\]
This implies
\[
	\norm{Ax_k}_{l^1} \to \norm{Ax}_{l^1} \qquad \text{ in }\mathbb{R}.
\]
Brouwer's fixed point theorem implies that $T$ has a fixed point $\bar{x} \in K$.
\begin{align*}
	\bar{x} &= (\bar{x}_1,\bar{x}_2,\dots,\bar{x}_n) \\
	\bar{x} &= T(\bar{x}) = \frac{1}{\norm{A \bar{x}}_{l^1}} A \bar{x} 
\end{align*}
Hence
$A \bar{x} = \norm{ A \bar{x}}_{l^1} \bar{x}$ where $\abs{A \bar{x}}_l^1 >0$ and $\bar{x}$ has all entries $>0$.
\end{beweis}

\begin{theorem}[Schander's fixed point theorem]
	$(E, \norm{.})$ Banach space. $K$ compact, convex set in $E$. $T: K \to K$ continuous. \\
	$\Rightarrow $ $T$ has a fixed point in $K$.
\end{theorem}
\begin{beispiel}
	\[
		S = \set[f \in C([0,1])]{f(0) = 0,\, f(1)=1,\, \norm{f} = \max\limits_{x \in [0,1]} \abs{f(x)} \leq 1}
	\]
	$T: S \to S$ defined by
	\[
		T(f)(x) = f(x^2), \qquad x \in [0,1].
	\]
	$C([0,1])$ is equipped with the max-norm. \\
	\minisec{Claim:}\begin{itemize}
		\item $S$ is closed, bounded and convex in $C([0,1])$.
		\item $T: S \to S$ is continuous
		\item $T$ has no fixed point in $S$
	\end{itemize}
	\begin{itemize}
		\item 
	$S$ bounded: $f \in S$ implies $\norm{f}\leq 1$. 
	\item $S$ closed: $f_n \to f$ in $(C([0,1]),\norm{.})$. \\
	To show: $f \in S$. \\
	Note \[
		\max_{x \in [0,1]}\abs{f_n(x)-f(x)} \to 0, \qquad n \to \infty
	\]
	This implies
	\[
		\abs{f(0)} = \abs{f_n(0)-f(0)} \to 0, \qquad n \to \infty.
	\]
	So $f(0)=0$.
	\[
		\abs{1-f(1)} = \norm{f_n(1)-f(1)} \to 0, \qquad n \to \infty.
	\]
	So $f(1)=1$. For $x \in [0,1]$ we get
	\begin{align*}
		\abs{f(x)} &\leq \norm{f(x)-f_n(x)} + \abs{f_n(x)} \\
		&\leq \underset{\to 0}{\underbrace{\norm{f-f_n}}} + \underset{\leq 1}{\underbrace{\norm{f_n}}}. 
	\end{align*}
	Conclusion $f \in S$
	\[
		\norm{f} = \max_{x \in [0,1]}\abs{f(x)} \leq 1.
	\]
	\item $f,\tilde f \in S$ and $\lambda \in [0,1]$. \\
	To show: 
	\[
		\lambda f + (1- \lambda) \tilde f \in S
	\]
	Trivial since
	\[
		(\lambda f + (1-\lambda) \tilde f)(0) = 0 
	\]
	\[
		(\lambda f + (1- \lambda) \tilde f)(1) = \lambda f(1)+ (1- \lambda)\tilde f(1)= 1
	\]
	and	
	\[
		\norm{\lambda f + (1-\lambda) \tilde f} \leq \abs{\lambda} \norm{f} + \abs{1- \lambda} \norm{ \tilde f} \leq 1
	\]
	\end{itemize}
	We want to show that $T: S \to S$ is continuous. (obvious that $T(S) \subseteq S$)\\ Assume $f_n \to f$ in $S$ in max-norm, i.e.
	\[
		\max_{x \in [0,1]} \abs{f_n(x)-f(x)} \to 0, \qquad n \to \infty
	\]
	To show: $T(f_n) \to T(f)$ in $S$ in max-norm.
	\begin{align*}
		\norm{T(f_n)-T(f)} &= \max_{x \in [0,1]}\abs{T(f_n)(x)- T(f)(x)} \\ & = \max_{x \in [0,1]}\abs{f_n(x^2)-f(x^2)}  \\ &= \norm{f_n -f} \to 0, \qquad n \to \infty
	\end{align*}
	$T: S \to S $ has no fixed point. \\
	If $f \in S$ is a fixed point for $T$ then 
	\[
		f(x^2) = T(f)(x) = f(x), \qquad x \in [0,1].
	\]
	To show: there can be no such $f \in S$. \\
	Set $a = \inf \set[x \in [0,1]]{f(x) = \frac{1}{2}} \neq \emptyset \text{ since $f$ is continuous}$. $a \in (0,1)$ since if $a = 0$ then there exists a sequence
	\[
		a_n \in \set[x \in [0,1]]{f(x)= \frac{1}{2}} 
	\]
	such that $a_n \to a$ in $\mathbb{R}$ as $n \to \infty$. Contradiction since 
	\[
		\frac{1}{2} = f(a_n) \to f(a) = f(0) = 0
	\]
	since $f$ is continuous. \\
	But $0 < a^2 < a$ and $f(a^2) = f(a) = \frac{1}{2}$. This is a contradiction. \\
	If we believe in Schauder then we can conclude that $S \subseteq C([0,1])$ is not compact.
\end{beispiel}
\begin{theorem}[Arzela-Ascoli theorem]
	Assume $K$ is a compact set in $\mathbb{R}^n$ (e.g. $K = [0,1]$ in $\mathbb{R}$n $n=1$) and $S \subseteq C(K)$ where $C(K)$ is equipped with the max-norm. \\
	$\Rightarrow $ S is relatively compact in $C(K)$ iff
	\begin{enumerate}[(1)]
		\item $S$ uniformly bounded.
		\item $S$ is equicontinuous.
	\end{enumerate}
\end{theorem}
\begin{definition*}
	\begin{enumerate}[(i)]
		\item $S$ is uniformly bounded if
		\[
			\sup\limits_{f \in S} \norm{f} < \infty
		\]
		\item $S$ is equicontinuous if: for every $\varepsilon >0$ there exists $\delta >0$ such that
		\[
			\abs{x- \tilde x} < \delta, \, x, \tilde x \in K \qquad \Rightarrow \qquad \abs{f(x)-f(\tilde x)}< \varepsilon.
		\]
		$\delta = \delta (\varepsilon)$ must not depend on $f$. \\
	\end{enumerate}
\end{definition*}
$S$ is relatively compact in $C(K)$ if for every sequence $(f_n)_{n=1}^{\infty}$ in $S$ there exists a converging subsequence in $C(K)$. \\
To show:
$S$ is relatively compact in $C(K)$ iff the closure $\bar{S}$ is compact in $C(K)$. 
\minisec{things to do:}
\begin{enumerate}[(1)]
	\item Proof of Schander's theorem
	\item Proof of Arzela-Ascoli theorem
	\item Application with Schander
	\item Proof of Brouwer's thereom (special case)
	\item Completion of normed spaces
\end{enumerate}	
For (4) wie consider the following lemma
\begin{lemma*}[Sperner's lemma]
	Big triangle $T$ 
	\[
		T = \bigcup_{a \in A} T_a
	\]
	$\set{T_a}_{a \in A}$ is triangle of $T$, i.e. for any pair $T_a$, $T_{\tilde a}$ in the triangulation
	\[
		T_a \cup T_{\tilde a}= \set{\emptyset \text{ or common vertrex or common side or }T_a = T_{\tilde a}}.
	\]
	$\Rightarrow $ There must exists a triangle $T_a$ with all vertices colored differently. MISSING FIGURE!
\end{lemma*}

\begin{description}
	\item[Proof of Schander's fixed point theorem:]
	To prove: $(E, \norm{.})$ Banach space, $K$ compact convex set in $E$ and $T: K \to K$ continuous. \\
	\minisec{Claim:}$T$ has a fixed point. \\
	\begin{beweis}
		\begin{lemma}
			Assume $(x_n)_{n=1}^{\infty}$ sequence in $K$ such that
			\[
				\norm{T(x_n)-x_n} \to 0, \qquad  n \to \infty
			\]
			T has a fixed point in $K$
		\end{lemma}
		\begin{beweis}
			Consider $(T(x_n))_{n=1}^{\infty}$ in $K$. $K$ compact implies that there exists a $z \in K$ and a subsequence $(T(\tilde x_n))_{n=1}^{\infty}$ of $(T(x_n))_{n=1}^{\infty}$ such that 
			\[
				T(\tilde x_n) \to  z \qquad  \text{in $K$ as }n \to \infty.
			\]
			Then
			\[
				\norm{\underset{\to z}{\underbrace{T(\tilde x_n)}}- \tilde x_n} \to 0, \qquad \text{as }n \to \infty
			\]
			So $\tilde x_n \to z$ for $n \to \infty$. But $T$ continuous implies 
			\[
				z \leftarrow T( \tilde x_n) \to T(z), \qquad  n \to \infty.
			\]
			Conclusion: $z = T(z)$ so $z$ is a fixed point.
		\end{beweis}
		\begin{lemma}
			$K$ compact set in $E$. Let $\varepsilon >0$. Then there exists a finite set $x_1,\dots,x_n \in K$ such that for all $x \in K$
			\[
				\min\limits_{k = 1, \dots, N} \norm{x- x_k} < \varepsilon
			\] 
		\end{lemma}
		\begin{beweis}
			Assume there is no finite sequence $x_1, \dots, x_N$. Then there exists a sequence $(x_n)_{n=1}^{\infty}$ such that
			\[
				\norm{x_k-x_l} \geq \varepsilon, \qquad \text{for }k \neq l
			\]
			Clearly $(x_n)_{n=1}^{\infty}$ has no converging subsequence. This contradicts $K$ beeing compact.
		\end{beweis}
		Fix positive integer $n$. Apply previous lemma with $\varepsilon = \frac{1}{\varepsilon}$. then there exists a finite set $x_1,\dots,x_N$ such that
		\[
			K \subset \bigcup_{k=1}^N B \left(x_k, \frac{1}{n} \right)
		\]
		Set 
		\begin{align*}
			K_n  &= \set{\text{set of all convex combinations of $x_1, \dots,x_N$}} \\
			&= \set[\sum_{k=1}^{N} \lambda_k x_k]{\lambda_k \geq 0 \text{ for all }k,\, \sum_{k=1}^{N}\lambda_k = 1}
		\end{align*}
		This set is a closed and bounded set in $\text{span}(K_n)$ finite dimensional. Also $K_n$ is convex.  \\
		(want $T_n: K_n \to K_n$ where $T_n$ close to $T$) \\
		Set $f_k(x)= \max \left(0, \frac{1}{n}- \norm{x-x_k}\right)$ for $x \in K$ and $k=1,2, \dots,N$. \\
		For each $x \in K$ there exists a $k$ such that $f_k(x)>0$. Set
		\[
			P_n(x) = \frac{f_1(x)x_1+f_2(x_2)+ \dots+ f_N(x_N)}{f_1(x)+f_2(x)+ \dots+ f_N(x)}, \qquad x \in K.
		\]
		$P_n$ is a convex combination of $x_1,\dots,x_N$ for every $x \in K$. So $P_n(x) \in K_n$ for every $x \in K$. \\
		\minisec{Claim:}$\norm{P_n(x)-x} < \frac{1}{n}$ for all $x \in K$.Set $T_n$ to be defined like
		\[
			T_n := P_n T : K_n \to K_n
		\]
		Here $T_n$ is continuous since $T$ and $P_n$ are continuous. $K_n$ is compact and convex in a finite dimensional space. Brouwer's fixed point theorem implies that $T_n$ has a fixed point in $K_n$,i.e. there exists $x_n \in K_n$ such that
		\[
			x_n = T_n(x_n)= P_n(x_n).
		\]
		But then
		\[
			\norm{x_n - T(x_n)} \leq  \underset{=0}{\underbrace{\norm{x_n - \underset{=T_n}{\underbrace{P_nT(x_n)}}}}} + \underset{< \frac{1}{n}}{\underbrace{\norm{ P_nT(x_n)- T(x_n)}}}
		\]
		The first lemma above gives that $T$ has a fixed point in $K$.
	\end{beweis} 
\end{description}
\begin{beispiel}
	Assume $k(x,y)$ continuous on $[0,1] \times [0,1]$ and $h(y,z)$ continuous on $[0,1]\times \mathbb{R}$ and 
	\[
		\sup\limits_{(y,z) \in [0,1] \times \mathbb{R}} \abs{h(y,z)} \equiv B < \infty
	\]
	Then there exists a solution $f \in C([0,1])$ to 
	\[
		f(x) = \int_{0}^{1} k(x,y)h(y,f(y)) \,\mathrm{d}y, \qquad x \in [0,1]
	\]
	Methos: Set $f \in C([0,1])$ and
	\[
		T(f)(x) = \int_{0}^{1}k(x,y)h(y,f(y)) \,\mathrm{d}y, \qquad x \in [0,1] \qquad (*)
	\]
	We want to apply (a generalized version of) Schander's fixed point theorem. Assume $(E, \norm{.})$ is a Banach space and $F$ closed convex subset of $E$. Moreover assume $T: E \to E$ continuos and $T(F)$ relatively compact in $(E,\norm{.})$. Then $T$ has a fixed point in $F$. \\
	\begin{description}
		\item[Step 1:] $T$ as in $(*)$. \\
		\minisec{Claim:}$T(C([0,1])) \subseteq C([0,1])$. \\
		To proof this we note that $k$ is continuous on $[0,1] \times [0,1]$ whicht is compact in $\mathbb{R}^2$. This implies that $k$
 is uniformly continuous on $[0,1]\times [0,1]$. Fix now $\varepsilon >0$. \\
 Then there exists $\delta = \delta (\varepsilon) >0$ such that
 \[
 	\abs{k(x_1,y_1)- k(x_2,y_2)} < \frac{\varepsilon}{B}
 \]
 for $\abs{(x_1,y_1)- (x_2,y_2)}< \delta $. \\
 Fix $f \in C([0,1])$
 	\begin{align*}
 		\abs{T(f)(x_1)-T(f)(x_2)} & = \abs{ \int_{0}^{1}(k(x_1,y)-k(x_2,y))h(y,f(y)) \,\mathrm{d}y} \\
		&\leq \int_{0}^{1}\underset{< \frac{\varepsilon}{B} \text{ if } \abs{x_1-x_2}< \delta }{\underbrace{\abs{k(x_1,y)-k(x_2,y)}}}\underset{\leq B}{\underbrace{\abs{h(y,f(y))}}} \,\mathrm{d}y < \varepsilon, \qquad \text{provided }\abs{x_1-x_2}< \delta
 	\end{align*}
	Conclusion: $T(f) \in C([0,1])$ for $f \in C([0,1])$
	\item[Step 2:] Choose $F$. \\
	$k$ is a continuous function on a compact set $[0,1] \times [0,1]$ implies
	\[
		\sup\limits_{(x,y) \in [0,1] \times [0,1]} \abs{k(x,y)} \equiv A < \infty.
	\]
	Hence 
	\[
		\abs{T(f)(x)} \leq  AB \qquad \text{ for all }f \in C([0,1]).
	\]
	Set 
	\[
		F:= \set[f \in C([0,1])]{\norm{f} = \max_{x \in [0,1]}\abs{f(x)} \leq AB}
	\]
	Clearly $F$ is closed convex in $(C([0,1]),\norm{.})$ which is a Banach space.
	\item[Step 3:] \minisec{Claim:}$T(F)$ is relatively compact. \\
	To prove this we use the Arzela-Ascoli Theorem. \\
	$\phantom{...}$ \\
	Let $K$ be a compact set in $\mathbb{R}^n$. Let $\mathcal{S} \subset C(K)$ (realvalued continuous functions on $K$). \\
	Then $\mathcal{S}$ is relatively compact in $(C(K),\norm{.}_{\infty})$ if 
	\begin{enumerate}[(1)]
		\item $\mathcal{S}$ uniformly bounded, i.e.
		\[
			\sup_{f \in \mathcal{S}} \norm{f} < \infty
		\]
		\item equicontinuity of $f \in \mathcal{S}$, i.e.
		\begin{align*}
			\forall\, \varepsilon>0 \,\exists\, \delta = \delta (\varepsilon) >0: \,\forall\,  f \in \mathcal{S}: & \\
			\abs{x_1-x_2} < \delta, \, x_1,x_2 \in K \qquad \Rightarrow & \qquad \abs{f(x_2)-f(x_1)}< \varepsilon
		\end{align*}
	\end{enumerate}
	In our example it is $\mathcal{S} = F$, $K = [0,1]$ in $\mathbb{R}$. Check that (1) and (2) in AA-Theorem are satisfied. \\
	\begin{enumerate}[(1)]
		\item $F$ is uniformly bounded since
	\[
		\sup_{f \in F}\norm{f} \leq AB < \infty
	\]
	\item Equicontinuity follows from calculations in Step 1. \\
	\end{enumerate}	
	Conclusion: $T(F)$ is relatively compact.
	\item[Step 4:] \minisec{Claim:}$T: F \to F$ continuous \\
	In step 1 we had $f \in F$ and $x_n \to x$ in $[0,1]$. We have shown that $T(f)(x_n) \to T(f)(x)$ in $\mathbb{R}$. So $T(f)$ is a continuous function. \\
	Now we want to show that for $f_n \to f$ in $F$ we've got $T(f_n) \to T(f)$ in $C([0,1])$. \\
	Note that $h: [0,1] \times [-AB,AB] \to \mathbb{R}$ is continuous and $[0,1] \times [-AB,AB]$ is compact set in $\mathbb{R}^2$. So $h: [0,1] \times [-AB,AB] \to \mathbb{R}$ is uniformly continuous. \\
	Fix $\varepsilon >0$. Then there exists a $\delta = \delta (\varepsilon) >0$ such that
	\[
		\abs{h(y_1,z_1)-h(y_2,z_2)} < \frac{\varepsilon}{A}
	\] 
	for $\abs{(y_1,z_1)-(y_2,z_2)} < \delta $. For $f_1,f_2 \in F$ with
	\[
		\norm{f_1-f_2} < \delta 
	\]
	We have 
	\begin{align*}
		\abs{T(f_1)(x)-T(f_2)(x)} &= \abs{\int_{0}^{1}k(x,y)(h(y,f_1(y))-h(y,f_2(y))) \,\mathrm{d}y} \\
		&\leq  \int_{0}^{1}\underset{\leq A}{\underbrace{\abs{k(x,y)}}}\underset{< \frac{\varepsilon}{A}}{\underbrace{\abs{h(y,f_1(y))-h(y,f_2(y))}}} \,\mathrm{d}y < \varepsilon 
	\end{align*}
	Conclusion: $T: F \to F$ is continuous. 
	\item[Step 5:] Apply Schander's fixed point theorem.
	\end{description}
\end{beispiel}
\subsection{Completion of normed spaces} 
\label{sub:completion_of_normed_spaces}
$(E,\norm{.})$ normed spaces. We say that $(\tilde E, \norm{.}_*)$ is a completion of $(E,\norm{.})$ if $(\tilde E, \norm{.}_*)$ is a normed space such that
\begin{enumerate}[(1)]
	\item $\exists\, \Phi: E \to \tilde E$ injective and linear.
	\item $\norm{x} = \norm{\Phi(x)}_*$ for all $x \in E$.
	\item $\Phi(E)$ is dense in $\tilde E$.
	\item $(\tilde E, \norm{.}_*)$ is a Banach space.
\end{enumerate}
\minisec{Construction:}
Let $(x_n)_{n=1}^{\infty}$ and $(y_n)_{n=1}^{\infty}$ be Cauchy sequences in $(E,\norm{.})$. We say that $(x_n)_{n=1}^{\infty}$ and $(y_n)_{n=1}^{\infty}$ are equivalent, denoted by $(x_n) \sim (y_n)$, if 
\[
	\norm{x_n-y_n} \to 0, \qquad n \to \infty.
\]
Set \[
	\tilde E= \set[ \left((x_n) \right)_N]{(x_n)_{n=1}^{\infty} \text{ Cauchy sequence in } (E,\norm{.})}
\]
Vecotr space structure:
\[
	\begin{cases}
		[(x_n)]_N + [(\tilde x_n)]_N &= [(x_n + \tilde x_n)]_N \\
		\lambda [(x_n)]_N &= [(\lambda x)_n]_N
	\end{cases}
\]
Show that these definitions are well-defined, i.e. independent of the choice of representative Norm
\[
	\norm{ [(x_n)]_N}_* = \lim_{n \to \infty} \norm{x_n}
\]
Note \[
	(x_n) \sim (y_n)
\]
implies
\[
	\lim_{n \to \infty}\norm{x_n} = \lim_{n \to \infty} \norm{y_n}.
\]
Since
\[
	\abs{\norm{x_n}- \norm{y_n}} \leq \norm{x_n-y_n} \to 0, \qquad n \to \infty
\]
Check that the axioms for being a norm are satisfied. \\
Now we have $(\tilde E,\norm{.}_*)$ is a normed space. \\
Define $\Phi$: For $x \in E$ set $\Phi(x) = \left[ (x)_{n=1}^{\infty} \right]_N$ where 
\[
	(x)_{n=1}^{\infty} = (x,x,x, \dots).
\]
\begin{description}
\item[Claim 1 \& 2:] easy to prove. 
\item[Claim 3:] item $\Phi(E)$ dense in $(\tilde E,\norm{.}_*)$. Fix $\left[ (x_n) \right]_N \in \tilde E$. Consider $\Phi(x_k)$ where $x_k$ is the element in the $k$-th position in the sequence $(x_1,x_2, \dots,x_n, \dots)$.
\begin{align*}
	\norm{\left[ (x_n) \right]_N - \Phi(x_k)}_* = \lim_{n \to \infty}\norm{x_n - x_k} \to 0 \qquad k \to \infty
\end{align*}
Since $(x_n)_{n=1}^{\infty}$ is a Cauchy sequence. \\
\item[Claim 4:] item $(\tilde E, \norm{.}_*)$ is a Banach space.\\
Consider a Cauchy sequence $z_n \in \tilde E$ such that $\norm{z_n - z} \to 0$ as $n \to \infty$. \\
To show: There exists $z \in \tilde E$ such that 
\[
	\norm{z_n - z} \to 0, \qquad n \to \infty.
\]
By 3 we have that $\Phi(E)$ is dense in $ \tilde E$ so for $n=1,2,\dots$ there exists $x_n \in E$, $n=1,2,\dots$ such that
\[
	\norm{z_n - \Phi(z_n)} < \frac{1}{n}, \qquad  n=1,2,\dots
\]
Set $z=: \left[ (x_n) \right]_N$. \\
Need to show that $(x_n)_{n=1}^{\infty}$ is a Cauchy sequence
\begin{align*}
	\norm{x_n - x_m} &= \norm{\Phi(x_n)-\Phi(x_m)}_* \\
	& \leq  \norm{\Phi(x_n)- z_n}_* + \norm{z_n-z_m}_* + \norm{z_m - \Phi(x_m)}_* \\
	&< \frac{1}{n} + \norm{z_n-z_m} + \frac{1}{m} \to 0, \qquad n,m \to \infty
\end{align*}
Conclusion: $(x_n)_{n=1}^{\infty}$ is a Cauchy sequence in $(E, \norm{.})$. Remains to show:
\[
	\norm{z_n-z}_* \to 0, \qquad n \to \infty
\]
\[
	\norm{z_n - z}_* \leq \underset{< \frac{1}{n}}{\underbrace{\norm{z_n - \Phi(x_n)}_*}} + \underset{= \lim_{n \to \infty}\norm{x_n-x_m}}{\underbrace{\norm{\Phi(x_n)-z}_*}} \to 0, \qquad n \to \infty.
\]
\end{description}

Consider $ f \in C([0,1])$
\begin{itemize}
	\item max-norm: $\norm{f} = \max_{x \in [0,1]}\abs{f(x)}$. Then $(C([0,1]),\norm{.})$ is a Banach space.
	\item $p \geq 1:$
	\[
		\norm{f}_{L^p} = \left( \int_{0}^{1}\abs{f(x)}^p \,\mathrm{d}x \right)^{\frac{1}{p}} 
	\]
	defines a norm for $C([0,1])$
\end{itemize}
\begin{bemerkung}
	\begin{itemize}
		\item Consider piecewise linear $f_n \in C([0,1])$ for $n =1,2, \dots$
		\[
			f_n(x) = \begin{cases}
				1, &\text{ if } \frac{1}{2} \leq x \leq 1 \\
				0, &\text{ if } x \leq \frac{1}{2} - \frac{1}{2n}
			\end{cases}
		\]
		with
		\[
			\norm{f_n-f_m}_{L^1} \leq \frac{1}{2} \frac{1}{\min(m,n)} \to 0, \qquad n,m \to \infty
		\]
		So $(f_n)_{n=1}^{\infty}$ is a Cauchy sequence in $(C([0,1]),\norm{.}_{L^1})$ but $(f_n)_{n=1}^{\infty}$ does not converge in $(C([0,1]),\norm{.}_{L^1})$ since
		if $\norm{f_n - f}_{L^1} \to 0$ as $n \to \infty$ and $f \in C([0,1])$ then
		\[
			f(x) = \begin{cases}
				0, &\text{ if }x \in [0,\frac{1}{2})\\
				1, &\text{ if }x \in [\frac{1}{2},1]
			\end{cases}
		\]
		Conclusion: $(C([0,1]), \norm{.}_{L^1})$ is not a Banach space.
		\item Consider:
		\[
			f(x) = \begin{cases}
				1, &\text{ if }x = \frac{1}{2}\\
				0, &\text{ if }x \in [0,1] \setminus \set{\frac{1}{2}}
			\end{cases}
		\]
		Then
		\[
			\norm{f}_{L^1} = 0 = \norm{0}_{L^1}.
		\]
		Compare this with the first axiom for a norm function. Replace $[0,1]$ with $\mathbb{R}$. For $f : \mathbb{R} \to \mathbb{R}$ set \[
			\supp(f) = \set[x \in \mathbb{R}]{f(x) \neq 0}
		\]
		Set 
		\[
			C_0(\mathbb{R}) = \set[f \in C(\mathbb{R})]{ \supp(f) \text{ is compact in }\mathbb{R}}
		\]
		\minisec{Claim:} $C_0(\mathbb{R})$ forms a vector space and for every $p \geq 1$ and $f \in C_0(\mathbb{R})$
		\[
			\norm{f}_{L^p} = \left( \int_{\mathbb{R}}^{} \abs{f(x)}^p \,\mathrm{d}x \right)^{\frac{1}{p}}
		\] defines a norm on $C_0(\mathbb{R})$. \\
		Problem: $(C_0(\mathbb{R}), \norm{.}_{L^p})$ for $p \geq 1$ are not Banach spaces. \\
		$(L^1(\mathbb{R}),\norm{.}_{L^1})$ is a completion of $(C_0(\mathbb{R}),\norm{.}_{L^1})$. \\
		Note $A \subset \mathbb{R}$ and $A$ bounded. Define
		\[
			f_A(x) \begin{cases}
				1, & x \in A\\
				0, \text{elsewhere}
			\end{cases}
		\]
		Lebesguesmeasure of $A = \norm{f_A}_{L^1} = \mu(f_A)$. $A \subset \mathbb{R}$ and $A$ unbounded
		\[
			\mu(A) = \lim_{n \to \infty} \mu ( A \cap [-n,n]).
		\]
		We say that $A \subset \mathbb{R}$ is a $0$- set if for all $\varepsilon >0$ there exist open intervals $I_n$, $n=1,2, \dots$ such that
		\begin{enumerate}[(1)]
			\item $ A \subseteq \bigcup_{n=1}^{\infty}I_n$
			\item $\sum_{n=1}^{\infty}$ lenghts of $I_m < \varepsilon$
		\end{enumerate} 
		In particular
		\[
			A = \mathbb{Q} = \set[r_n]{n=1,2,\dots}\qquad \text{is a $0$-set}	
		\]
	\end{itemize}
\end{bemerkung}
%% 20.9
\newpage
\section{Hilbert spaces} 
\label{sec:hilbert_spaces}
\begin{beispiel}
	Consider $\mathbb{C}^n = \set[(x_1,x_2,\dots,x_n)]{x_i \in \mathbb{C}}$ and $x,y \in \mathbb{C}^n$ with
	$x= (x_1,\dots,x_n)$, $y = (y_1,\dots,y_n)$. Define the inner product of $x,y$ (scalar product)
	\[
		\skal{x}{y} = \sum^{n}_{i=1}x_i \bar{y}_i \in \mathbb{C}
	\]
	We have a map
	\begin{align*}
		\mathbb{C}^n \times \mathbb{C}^n &\to \mathbb{C} \\
		(x,y) &\mapsto \skal{x}{y}
	\end{align*}
	This mapping has properties:
	\begin{itemize}
		\item $x \neq 0$ folgt $\skal{x}{x} = \sum^{n}_{i=1}x_i \bar{x}_i = \sum^{n}_{i=1} \abs{x_i}^2 >0$
		\item $\skal{\lambda x}{y} = \lambda \skal{x}{y}$ for $x,y \in \mathbb{C}^n$, $\lambda \in \mathbb{C}$.
		\item $\skal{x}{y} = \sum^{n}_{i=1} x_i \bar{y}_i = \overline{\sum^{n}_{i=1}y_i \bar{x}_i}$ for $x,y \in \mathbb{C}^n$. \\
		In particular $\skal{x}{\lambda y} = \bar{\lambda} \skal{x}{y}$ for $\lambda \in \mathbb{C}$.
		\item $\skal{x+y}{z} = \skal{x}{z}+ \skal{y}{z}$ for $x,y,z \in \mathbb{C}^n$. 
	\end{itemize}
\end{beispiel}
\begin{definition}
	An inner product space $V$ is a complex vector space with an inner product which is a map 
	\[
		\skal{.}{.}: V \times V \to \mathbb{C}
	\]
	satisfying
	\begin{itemize}
		\item $\skal{\lambda x}{y} = \lambda \skal{x}{y}$ for any $x,y \in V$, $\lambda \in \mathbb{C}$
		\item $\skal{x+y}{z} = \skal{x}{z}+ \skal{y}{z}$ for any $x,y,z \in V$
		\item $\skal{x}{y} = \overline{y,x}$ for any $x,y \in V$
		\item $\skal{x}{x}>0$ for any $x \in V, x \neq 0$
	\end{itemize}
\end{definition}
Can we generalize $\mathbb{C}^n$? \\
\[
	\mathbb{C}^{\mathbb{N}} \set[(x_1,x_2, \dots)]{x_i \in \mathbb{C}}
\]
with
\[
	\skal{x}{y} = \sum^{\infty}_{i=1} x_i \bar{y}_i 
\]
This is not necesserily convergent.
\begin{beispiele}
	\begin{enumerate}[(1)]
		\item 	\[
		l^2 = \set[(x_1,x_2, \dots)]{ \sum^{\infty}_{i=1} \abs{x_i}^2 < \infty}.
	\]
	We have with Cauchy Schwarz
	\[
		\sum^{n}_{i=1} \abs{x_i \bar{y}_i} \leq \left( \sum^{n}_{i=1} \abs{x_i}^2 \right)^{\frac{1}{2}} \left( \sum^{n}_{i=1} \abs{y_i}^2 \right)^{\frac{1}{2}}
	\]
	if $x \in l^2$ and $y \in l^2$ we get
	\begin{align*}
		\sum^{n}_{i=1}\abs{x_i \bar{y}_i} \leq \left( \sum^{\infty}_{i=1} \abs{x_i}^2 \right)^{\frac{1}{2}} \left( \sum_{i=1}^{\infty} \abs{y_i}^2 \right)^{\frac{1}{2}} < \infty.
	\end{align*}
	It follows that $\sum_{i=1}^{\infty} x_i \bar{y}_i$ converges absolutely and hence it is convergent. The following 
	\[
		\skal{x}{y} = \sum^{\infty}_{i=1} x_i \bar{y}_i
	\]
	is well-defined for vectors $x,y \in l^2$. Like for $\mathbb{C}^n$ one can easily check that $\skal{.}{.}$ satisfies the axioms for inner products. \\
	$(l^2, \skal{.}{.})$ is an inner product space.
	\item Consider $C([0,1])$ with the inner product
	\[
		\skal{f}{g} = \int_{0}^{1}f(t) \overline{g(t)} \,\mathrm{d}t \qquad \forall\, f,g \in C([0,1])
	\]
	\begin{itemize}
		\item 	\[
			\skal{\lambda f}{g} = \int_{0}^{1}\lambda f(t) \overline{g(t)} \,\mathrm{d}t = \lambda \int_{0}^{1}f(t) \overline{g(t)} \,\mathrm{d}t = \lambda \skal{f}{g}
		\]
		\item \[
			\skal{f}{f} = \int_{0}^{1}f(t) \overline{f(t)} \,\mathrm{d}t = \int_{0}^{1} \abs{f(t)}^2 \,\mathrm{d}t >0
		\]	
		\item $\dots$
	\end{itemize}
	\end{enumerate}
\end{beispiele}
If we take $\mathbb{R}^3$ with the Eucledian norm on $\mathbb{R}^3$
\[
	\norm{(x_1,x_2,x_3)} = \sqrt{x_1^2 + x_2^2 + x_3^2} = \left( \sum_{i=1}^{3} \abs{x_i}^2 \right)^{\frac{1}{2}} = \skal{x}{x}^{\frac{1}{2}}
\]
Let $V$ be an inner product space with $\skal{.}{.}$ as the inner product. Let for $x \in V$
\[
	\norm{x} := \skal{x}{x}^{\frac{1}{2}}
\]
\begin{satz}
	The $x \mapsto  \norm{x}$ with $\norm{.}$ defined above is a norm.
\end{satz}
\begin{beweis}
	We are going to prove the norm axioms but first we need another theorem
	\begin{theorem}[Cauchy-Schwarz inequalitiy]
		For any $x,y \in V$ (inner product space) 
		\[
			\abs{\skal{x}{y}} \leq \skal{x}{x}^{\frac{1}{2}} \skal{y}{y}^{\frac{1}{2}}
		\]
		The equality holds iff $x,y$ are linearly dependent.
	\end{theorem}
	\begin{beweis}
		Assume $x,y$ linearly dependent. We can assume that $x= \lambda y$ for some $\lambda \in \mathbb{C} $.
		\[
			\abs{\skal{x}{y}} = \abs{ \skal{\lambda y}{y}} = \abs{\lambda} \skal{y}{y}
		\]
		and
		\begin{align*}
					\skal{x}{x}^{\frac{1}{2}} \skal{y}{y}^{\frac{1}{2}} &= \skal{\lambda y}{\lambda y}^{\frac{1}{2}} \skal{y}{y}^{\frac{1}{2}} \\
					&= \abs{\lambda} \skal{y}{y}^{\frac{1}{2}} \skal{y}{y}^{\frac{1}{2}} \\
					&= \abs{\lambda} \skal{y}{y}
		\end{align*}
		Hence \[
			\abs{\skal{x}{y}} = \skal{x}{x}^{\frac{1}{2}} \skal{y}{y}^{\frac{1}{2}}.
		\]
		Assume $x,y$ are linearly independent. Hence $x + \lambda y \neq 0$ for any $\lambda \in \mathbb{C}$. By an axiom for inner product we get
		\[
			0< \skal{x+ \lambda y}{x + \lambda y} = \skal{x}{x} + \lambda \skal{y}{x} + \bar{\lambda} \skal{x}{y} + \abs{\lambda}^2 \skal{y}{y}
		\]
		Pick now
		\[
			\lambda = - \frac{\skal{x}{y}}{\skal{y}{y}}
		\]
		(Note that $y \neq 0$ as $x,y$ linearly independent.)
		We have \begin{align*}
						0 &< \skal{x}{x} - \frac{\overset{= \abs{\skal{x}{y}}^2}{\overbrace{\skal{x}{y}\skal{y}{x}}}}{\skal{y}{y}} - \frac{\overset{= \abs{\skal{x}{y}}^2}{\overbrace{\overline{\skal{x}{y}}\skal{x}{y}}}}{\skal{y}{y}}+ \frac{\abs{\skal{x}{y}}^2}{\skal{y}{y}^2} \skal{y}{y} \\
						&= \skal{x}{x} - \frac{\abs{\skal{x}{y}}^2}{\skal{y}{y}}
		\end{align*}
		This gives
		\[
			\frac{\abs{\skal{x}{y}}^2}{\skal{y}{y}} < \skal{x}{x}
		\]
		and it follows
		\[
			\abs{\skal{x}{y}}^2 < \skal{x}{x} \skal{y}{y}
		\]
	\end{beweis}
	\begin{enumerate}[(i)]
		\item $\norm{x} >0$ for all $x \neq 0$ in $V$ (Exercise)
		\item $\norm{\lambda x} = \abs{\lambda} \norm{x}$ for all $x \in V$, $\lambda \in \mathbb{C}$ (Exercise)
		\item Let $x,y \in V$. Then 
		\begin{align*}
			\norm{x+y}^2 &= \skal{x+y}{x+y} \\ &= \skal{x}{x}+ \skal{x}{y}+ \skal{y}{x} + \skal{y}{y} \\
			&= \skal{x}{x} + 2 \text{Re}( \skal{x}{y}) + \skal{y}{y} \\
			&\leq  \skal{x}{x}+ 2 \abs{\skal{x}{y}} + \skal{y}{y} \\
			&\leq  \skal{x}{x} + 2 \skal{x}{x}^{\frac{1}{2}}\skal{y}{y}^{\frac{1}{2}} + \skal{y}{y} \\
			&= \left( \skal{x}{x}^{\frac{1}{2}} + \skal{y}{y}^{\frac{1}{2}} \right)^2 
		\end{align*} 
		So
		\[
			\norm{x+y}^2 \leq \left( \norm{x} + \norm{y} \right)^2
		\]
	\end{enumerate}
\end{beweis}
\begin{theorem}[The Parallelogram Law]
	Let $(V, \skal{.}{.})$ be an inner product space. Let $\norm{x} = \skal{x}{x}^{\frac{1}{2}}$. Then
	\[
		\norm{x+y}^2 + \norm{x-y}^2 = 2 (\norm{x}^2 + \norm{y}^2) \qquad \forall\, x,y \in V.
	\]
\end{theorem}
\begin{satz}
	$l^p$ has inner product $\skal{.}{.}_{l^p}$ such that
	\[
		\norm{x}_p = \sqrt{\skal{x}{x}_{l^p}}
	\]
	iff $p =2$.
\end{satz}
\begin{beweis}
	Enough to show that $\norm{.}_p$-norm does not satisfy the parallelogram law for some $x,y \in l^p$ if $p \neq 2$. Take, for example, $x = (1,0,0, \dots)$
	and $y= (0,1,0, \dots)$.
\end{beweis}
\minisec{Exercise:}Show that $(C([0,1]),\norm{.}_{\infty})$ is not an inner product space.
\begin{bemerkung}
	Whenever a norm satisfies the parallelogram law then there exists an inner product on $V$ such that
	\[
		\norm{x} = \skal{x}{x}^{\frac{1}{2}}
	\]
\end{bemerkung}
\begin{theorem}[The Polarization Identity]
	Let $(V,\skal{.}{.})$ be an inner product space. Then 
	\[
		4 \skal{x}{y}  = \norm{x+y}^2- \norm{x-y}^2 + i \norm{x+ iy}^2 - i \norm{x - iy}^2
	\]
\end{theorem}
\begin{definition}
	Let $(V, \skal{.}{.})$ be an inner product space. We say that $x,y$ in $V$ are othogonal if $\skal{x}{y} = 0$ (We write $x \perp y$). Let $M \subseteq V$
	Define the orthogonal complement
	\[
		M^{\perp} = \set[x \in V]{x \perp y \text{ for any }y \in M}
	\]
\end{definition}
\begin{proposition}
	If $M \subseteq V$ then $M^{\perp}$ is a subspace of $V$
\end{proposition}
\begin{theorem}[Pythagorean formula]
	$x,y \in V$ (inner product space). Then
	\[
		x \perp y \qquad \text{iff} \qquad \norm{x+y}^2 = \norm{x}^2 + \norm{y}^2.
	\]
\end{theorem}

\begin{theorem}
	GAP BECAUSE OF LAZINESS
\end{theorem}
%%%% 27.09.2016

Consider $(H, \skal{.}{.})$- Hilbert space (inner product space which is complete w.r.t. to a norm $\norm{x}= \sqrt{\skal{x}{x}}$). \\
Let $M$ be a cloased subspace of $H$. 
\[
	\mathcal{M}^{\perp} = \set[y \in H]{\skal{x}{y}= 0, \, \forall\,  x \in M}.
\]
Then we know $H = M + M^{\perp}$, i.e. for any $x \in H$ there exists a unique $y \in M$ and $z \in M^{\perp}$ such that
\[
	x = y + z.
\]
\begin{theorem}
	r
\end{theorem}




\cleardoubleoddemptypage
\pagenumbering{Alph}
\setcounter{page}{1}

\end{document}