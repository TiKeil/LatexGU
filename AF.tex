%!TEX TS-program = xelatex

\newcommand{\Semester}{WiSe 2016/2017, Term 1}
\newcommand{\fach}{Applied Functionalanalysis}
\newcommand{\prof}{Prof.\ Peter Kumlin}

\input{!config/VorlagenTim/preambel.tex}

\numberwithin{equation}{section}
\numberwithin{figure}{section}

\begin{document}

\maketitle
\cleardoubleoddemptypage

\pagenumbering{Alph}
\section*{foreword --- cooperation}
This document is a transcript of the lecture \enquote{\fach, \Semester}, by \prof.
It mainly contains the written content of the lecture. I will not assume any responsibility for the correctness of the content! For questions, remarks and mistakes please write an email to \href{mailto:keil.menden@web.de}{\nolinkurl{keil.menden@web.de}}. I'm grateful for every email. 
\newpage

\newpage

\tableofcontents
\cleardoubleoddemptypage
\pagenumbering{arabic}
\setcounter{page}{1}

\section{Introduction}
\subsection{Introduction example} 
\label{sub:introduction_example}
We have
\[
	\begin{cases}
		f''+f =g, &\text{ in }I = [0,1]\\
		f(0)=1, \,f'(0)=1
	\end{cases}
\]
where $g$ is a known continous function in $I$. We will now consider different cases:

\begin{enumerate}[1.]
	\item $g=0$
	\[
		\Rightarrow \,f(x) = A \cos(x) + B \sin(x), x \in I
	\]
	where $A,B \in \mathbb{R}$.
	\item $g$ arbitrary. We will now introduce the Method of variation of constants. Set
	\[
		f(x)=A(x) \cos(x)+ B(x) \sin(x)
	\]
	Differentiate
	\[
		f'(x) = A'(x) \cos(x) + B'(x) \sin(x) - A(x) \sin(x) + B(x) \cos(x)
	\]
	Aussume (This is part of the method)
	\[
		A'(x)\cos(x) + B'(x) \sin(x) = 0, \qquad x \in I
	\]
	Differentiate $f'(x)$ and get
	\[
		f''(x)=\underset{= -f(x)}{\underbrace{-A(x) \cos(x) - B(x) \sin(x)}} - A'(x) \sin(x) + B'(x) \cos(x)
	\]
	We get
	\[
		g(x) = f''(x)+f(x) = -A'(x) \sin(x) + B'(x) \cos(x).
	\]
	Now:
	\[
		\begin{cases}
			A'(x)\cos(x) + B'(x) \sin(x) = 0, & x \in I\\
			- A'(x) \sin(x)+ B'(x) \cos(x) = g(x), & x \in I \\
			A(0)=1, \qquad B(0)=0 &
		\end{cases}
	\]
	We get
	\begin{align*}
		A'(x) &= - g(x)\sin(x) \\
		A(0) &= 1 \\
		B'(x) &= g(x) \cos(x) \\
		B(0) &=0
	\end{align*}
	This implies
	\begin{align*}
		A(x) &= A(0) + \int_{0}^{x} A'(t) \,\mathrm{d}t = 1 - \int_{0}^{x} g(t) \sin(t) \,\mathrm{d}t \\
		B(x) &= B(0) + \int_{0}^{x}B'(t) \,\mathrm{d}t = 0 + \int_{0}^{x}g(t)\cos(t) \,\mathrm{d}t
	\end{align*}
	Hence
	\begin{align*}
		f(x) &= \cos(x) - \int_{0}^{x} g(t) \sin(t) \,\mathrm{d}t \cos(x) + \int_{0}^{x} g(t) \cos(t) \,\mathrm{d}t \sin(x) \\
		&= \cos(x) + \int_{0}^{x} (\underset{=\sin(x-t)}{\underbrace{\sin(x)\cos(t)- \sin(t)\cos(x)}})g(t) \,\mathrm{d}t \\
		&= \cos(x) + \int_{0}^{x}\sin(x-t)g(t) \,\mathrm{d}t \qquad (*)
	\end{align*}
	Check that $f(x)$ in $(*)$ satisfies the PDE.
	\minisec{special case:}
	Assume for $x \in I$
	\[
		g(x) = k(x)f(x)
	\]
	Here $k$ is a known continous function in $I$. Insert this in $(*)$. We obtain
	\[
		f(x) = \cos(x) + \int_{0}^{x} \sin(x-t)k(t)f(t) \,\mathrm{d}t, \qquad x \in I \qquad (**)
	\]
	Observe that $f$ appears both in LHS and RHS. $(**)$ is a reformulation of the PDE with $g=kf$. Pick a $\underset{\in C(I)}{\underbrace{\text{continous function in $I$}}}$. call it $f_0$. Set
	\begin{align*}
		f_1(x) &= \cos(x) + \int_{0}^{x}\sin(x-t)k(t)f_0(t) \,\mathrm{d}t \\
		f_2(x) &= \cos(x) + \int_{0}^{x}\sin(x-t)k(t)f_1(t) \,\mathrm{d}t \\
		\vdots &\qquad \qquad  \vdots \\
		f_{n+1}(x) &= \cos(x) + \int_{0}^{x}\sin(x-t)k(t)f_n(t) \,\mathrm{d}t, \qquad n=1,2,3, \dots \\
	\end{align*}
	\minisec{Hope:} $f_n$ tends to some continous function $f$ on $I$, denoted $f_n \to f$. 'Tends to' has to be more precis! 
	\begin{align*}
		f_{n+1}(x) &= \cos(x) + \int_{0}^{x} \sin(x-t)k(t)f_n(t) \,\mathrm{d}t \\
		\downarrow & \qquad \qquad \downarrow \\
		f(x) &= \cos(x) + \int_{0}^{x} \sin(x-t)k(t)f(t) \,\mathrm{d}t
	\end{align*}
	for $x \in I$. Simplify notation set for $v \in C(I)$
	\[
		\begin{cases}
			u(x)&=\cos(x)\\
			kv(x)&= \int_{0}^{x} \sin(x-t)k(t)v(t) \,\mathrm{d}t
		\end{cases}
	\]
	We have $f_0 \in C(I)$, $f_{n+1}=u + k f_n$ for $n=0,1,2, \dots$ (!) \\
	Facts from previous calculus classes:
	\begin{definition*}[Sequenze of continous functions]
		\[
			v_n \in C(I), \qquad n=1,2,\dots
		\]
		We say that $(v_n)_{n=1}^{\infty}$ converges uniformly in $I$ if
		\[
			\max_{x \in I} \abs{v_n(x)-v_m(x)} \to 0 , \qquad n,m \to \infty
		\]
		i.e.
		\[
			\forall\, \varepsilon >0 \exists\, N: \forall\, n,m \geq N: \, \max_{x \in I}\abs{v_n(x)-v_m(x)}< \varepsilon
		\]
	\end{definition*}
	\begin{lemma*}
		Suppose that $(v_n)_{n=1}^{\infty}$ converges uniformly on $I$. then there exists $v \in C(I)$ such that
		\[
			 \max_{x \in I}\abs{v_m(x)-v(x)} \to 0 \qquad \text{as }m \to \infty
		\]
	\end{lemma*}
	Back to (!): \\
	More Notation:
	\[
		k(kv) = k^2 v, \qquad v \in C(I)
	\]
	and
	\[
		k^{n+1}v = k(k^nv), \qquad n=1,2,\dots
	\]
	We have $f_0 \in C(I)$, $f_1=u+kf_0$ and 
	\[
		f_2 = u + kf_1 = u + k(u+kf_0)
	\]
	and so on. Note that
	\[
		k(v+w)=kv+kw
	\]
	Then 
	\begin{align*}
		f_2 &= u +k (u+kf_0) = k + ku + k(kf_0) = u + ku +k^2f_0 \\
		f_3 &= u + kf_2 = u + ku + k^2u + k^3f_0
	\end{align*}
	and in general for $n=1,2,\dots$
	\[
		f_n = ku + \dots + k^{n-1}u + k^n f_0, \qquad n=1,2,\dots
	\]
	Assume $n>m$ then
	\[
		f_n-f_m = k^mu + \dots + k^{n-1}u + k^nf_0 - k^mf_0
	\]
	Set for $v \in C(I)$
	\[
		\norm{v} = \max_{x \in I}\abs{v(x)}
	\]
	Note
	\[
		\norm{v+w} \leq \norm{v} + \norm{w} \qquad \text{for }v,w \in C(I)
	\]
	and
	\[
		\norm{-v}=\norm{v}.
	\]
	We have
	\begin{align*}
		\norm{f_n-f_m} &= \norm{k^mu + \dots + k^{n-1}u + k^nf_0 - k^m f_0} \\
		&\leq \norm{k^mu} + \dots + \norm{ k^{n-1}u} + \norm{k^nf_0} + \norm{- k^mf_0}.
	\end{align*}
	Assumption
	\[
		\sum_{l=1}^{\infty} \norm{k^lv} < \infty \qquad \text{for all }v \in C(I) \qquad (***)
	\]
	Under this assumption
	\[
		\norm{f_n-f_m} \to 0 \qquad \text{as }n,m \to \infty
	\]
	since
	\begin{align*}
		\sum_{l=1}^{\infty}\norm{k^lu} &< \infty \qquad \qquad (u(x)=\cos(x)) \\
		\sum_{l=1}^{\infty}\norm{k^lf_0} &< \infty \qquad \qquad (f_0 \in C(I))
	\end{align*}
	conclusion: $(f_n)_{n=1}^{\infty}$ converges uniformly on $I$. By lemma above there exists $f \in C(I)$ such that
	\[
		\max_{x \in I}\abs{f_n(x)-f(x)} \to 0, \qquad n \to \infty
	\]
	i.e.
	\[
		\norm{f_n -f} \to 0, \qquad n \to \infty
	\]
	'Back hope':
	$f_n$ tends to $f$, denoted $f_n \to f$ shall be interpretated as
	\[
		\norm{f_n -f} \to 0, \qquad n \to \infty
	\]
	Remember
	\[
		f_{n+1}(x) = u(x) + k f_n(x) \to ?
	\]
	For $x \in I$ there is
	\begin{align*}
		\abs{k f_n(x)- kf(x)} &= \abs{ \int_{0}^{x} \sin(x-t)k(t)f_n(t) \,\mathrm{d}t- \int_{0}^{x}\sin(x-t)k(t)f(t) \,\mathrm{d}t} \\
		&\leq \int_{0}^{x}\abs{\sin(x-t)k(t)}\underset{\leq \norm{f_n-f}}{\underbrace{\abs{f_n(t)-f(t)}}} \,\mathrm{d}t \\
		&\leq \int_{0}^{x}\abs{\sin(x-t)k(t)} \,\mathrm{d}t \norm{f_n-f}
	\end{align*}
	In particular
	\begin{align*}
		\norm{k f_n- kf} &\leq \max_{x \in I}\int_{0}^{x} \underset{\leq 1}{\underbrace{\abs{\sin(x-t)}}} \underset{\max_{t \in I}\abs{k(t)}< \infty}{\underbrace{\abs{k(t)}}} \,\mathrm{d}t \norm{f_n -f} \\
		&\leq \norm{k} \norm{f_n-f}
	\end{align*}
	We have, provided $(***)$ holds, shown
	\begin{align*}
		f_{n+1} &= u + k f_n \\
		\downarrow & \\
		f &= u + kf
	\end{align*}
	Let us try to prove $(***)$. For $v \in C(I)$ arbitrary and for $x \in I$
	\begin{align*}
		\norm{kv(x)} &= \abs{\int_{0}^{x}\sin(x-t)k(t)v(t) \,\mathrm{d}t} \\
		&\leq \int_{0}^{x}\underset{\leq 1}{\underbrace{\abs{\sin(x-t)}}}\underset{\leq \norm{k}}{\underbrace{\abs{k(t)}}}\abs{v(t)} \,\mathrm{d}t \\
		&\leq \int_{0}^{x}\underset{\leq \norm{v}}{\underbrace{\abs{v(t)}}} \,\mathrm{d}t \norm{k} \\
		&\leq \norm{k} \norm{v}x
	\end{align*}
	In particular
	\[
		\norm{kv} \leq \norm{k}\norm{v}
	\]
	and
	\begin{align*}
		\abs{k^2v(x)} &\leq \int_{0}^{x} \abs{kv(t)} \,\mathrm{d}t \norm{k} \\
		&\leq \int_{0}^{x}\norm{k}\norm{v}t \,\mathrm{d}t \cdot \norm{k} \\
		&= \norm{k}^2 \norm{v} \frac{x^2}{2}
	\end{align*}
	In particular
	\[
		\norm{k^2v} \leq \norm{k}^2 \norm{v} \frac{1}{2}
	\]
	By induction we get
	\begin{align*}
		\abs{k^n v(x)} &\leq \norm{k}^n \norm{v} \frac{x^m}{m!} \qquad x \in I \\
		\norm{k^n v} &\leq  \norm{k}^n \norm{v} \frac{1}{n!}
	\end{align*}
	So 
	\begin{align*}
		\sum_{l=1}^{\infty}\norm{k^lv} &\leq \sum_{l=1}^{\infty}\norm{k}^l \norm{v} \frac{1}{l!} \\
		&= \norm{v} \sum_{l=1}^{\infty} \frac{\norm{k}^l}{l!} \\
		&\leq \norm{v} e^{\norm{k}} < \infty
	\end{align*}
	consider Taylor expansion.
	$\Rightarrow $ $(***)$ holds true. \\
	We have now shown that $f = u+kf$ where $u(x) = \cos(x)$ and
	\[
		kv = \int_{0}^{x}\sin(x-t)k(t)v(t) \,\mathrm{d}t
	\]
	$x \in I$ for $v \in C(I)$, has a solution $f \in C(I)$. \\
	Question: Is the solution unique? \\
	Assume $f,\tilde f \in C(I)$ such that $f = u + k f$ and $\tilde f = u+ k \tilde f$. Set 
	\[
		v = f- \tilde f \in C(I)
	\]
	\begin{align*}
		\Rightarrow v &= (u+kf) - (u+ k \tilde f) \\ &= kf - k \tilde f \\ &= k(f- \tilde f) \\ &= kv
	\end{align*}
	We have $v = kv$, implies that $kv = k(kv) = k^2v$. So for $n=1,2,\dots$
	\[
		v = kv = k^2v = \dots = k^nv
	\]
	We know 
	\[
		\sum_{n=1}^{\infty}\norm{k^n \hat{v}} < \infty \qquad \text{for all }\hat{v} \in C(I).
	\]
	Apply this to $\hat{v}=v$:
	\[
		\sum_{n=1}^{\infty}\underset{=\norm{v}}{\underbrace{\norm{k^nv}}} < \infty 
	\]
	So $\norm{v}=0$ with implies $v(x)=0$ for all $x \in I$.
	So we have $f(x)=\tilde f(x)$ for $x \in I$. \\
	$\Rightarrow $ Answer to the question above: YES ! 
\end{enumerate}
We have more or less proved the following theorem:
\begin{theorem}
	Set $I=[0,1]$. Suppose $u \in C(I)$ and $k \in C(I \times I)$. Consider 
	\[
		f(x) = u(x)+ \int_{0}^{x} k(x,t) f(t) \,\mathrm{d}t, \qquad x \in I \qquad \qquad (1)
	\]
	Then $(1)$ has a unique solution $f \in C(I)$
\end{theorem}
With the same technology we can prove:
\begin{theorem}
	Set $I = [0,1]$. Suppose $u \in C(I)$, $k \in C(I \times I)$ and $\max\limits_{(x,t) \in I \times I} \abs{k(x,t)} <1$. Consider \[
		f(x) = u(x) + \int_{0}^{1}k(x,t)f(t) \,\mathrm{d}t, \qquad x \in I \qquad \qquad (2).
	\]
	Then $(2)$ has a unique solution $f \in C(I)$.
\end{theorem}
Different notions: see intoductory example.
\begin{definition*}[vector space]
	$C(I)$ with the operations for $x \in I$
	\begin{description}
		\item[addition] $v,w \in C(I)$: $\qquad (v+w)(x) = v(x)+ w(x)$ 
		\item[mult. by scalar] $v \in C(I)$, $ \lambda \in \mathbb{R}$: $\qquad (\lambda v)(x) = \lambda v(x)$ 
	\end{description}
	Note that $v+w, \lambda v \in C(I)$.
\end{definition*}
\begin{definition*}[norm]
	norm on $C(I)$ for instance 
	\[
		\norm{v} = \max_{x \in I} \abs{v(x)}
	\]
	with norm given we can talk about convergence and confirmity
\end{definition*}
\begin{definition*}[Cauchy sequence]
	In our example a sequence $(f_n)_{n=1}^{\infty}$ is called Cauchy sequence if $\norm{f_n-f_m} \to 0$ for $n,m \to \infty$.
\end{definition*}
\begin{definition*}
	$C(I)$ with the max-norm. Lemma above says that every Cauchy sequence converges i.e.
	\[
		\norm{v_n-v_m} \to 0, \qquad n,m \to \infty
	\]
	This applies
	\[
		\exists\, v \in C(I): \norm{v_n-v} \to 0, \qquad n \to \infty
	\]
	This is the defining property of a Banach space. \\
	$K$ linear mapping $C(I) \to C(I)$ with
	\begin{align*}
		K(v+w) &= K(v) + K(w) \\
		K(\lambda v) &= \lambda K(v)
	\end{align*}
	for $v,w \in  C(I)$, $\lambda \in \mathbb{R}$. \\
	$K$ bounded linear:
	\[
		\norm{Kv} \leq M \norm{v} \qquad \forall\, v \in C(I)
	\]
	where $M >0$ independent of $v$.	
\end{definition*}
\begin{definition*}[operator norm]
	Define
	\[
		\norm{K}= \inf \set[M>0]{\norm{Kv} \leq M \norm{v} \text{ for all }v \in C(I)}.
	\]
\end{definition*}
\minisec{fixed point results:}
Our example: $f=u+kf =: T(f)$ and $f_0 \in C(I)$ fixed. \\
Form sequence of iterants $(f_n)_{n=1}^{\infty}$, $f_n = T(f_{n-1})$, $n=1,2,\dots$ if
\[
	\norm{T(v)-T(w)} \leq c \norm{v-w}
\]
for all $v,w \in C(I)$ for some $c<1$. Then there is a unique $v \in C(I)$ such that $v = T(v)$. \\
This is \underline{Banach's fixed point theorem}.
\begin{definition*}[Green's function]
	Our example: 
	\[
		L = \left( \diffd{}{x} \right)^2 + 1 
	\]
	differential operator. Boundary conditions 
	\[
		f(0) = f'(0) = 0.
	\]
	Then 
	\[
		f(x) = \int_{0}^{1} g(x,t)h(t) \,\mathrm{d}t 
	\]
	is a solution to
	\[
		\begin{cases}
			f''+f &= h, \\
			f(0) = f'(0)& = 0	
		\end{cases}
	\]
\end{definition*}
\begin{definition*}[real vector space]
	We say that $E$ is a real vector space  if it is a non-empty set with the operations 
	\begin{description}
		\item[addition] $E \times E \to E$, $\qquad (x,y) \mapsto x+y$
		\item[mult. with scalar] $\mathbb{R} \times E \to E$, $ \qquad (\lambda,x) \mapsto \lambda x$ 
	\end{description}
	satisfying the axioms:
	\begin{enumerate}[(1)]
		\item $x+y = y+x, \qquad$ for all $x,y \in E$
		\item $x+(y+z)= (x+y)+z, \qquad $ for all $x,y,z \in E$
		\item For all $x,y \in E$ there exists $z \in E$ such that $x+z = y$
		\item $\alpha (\beta x) = (\alpha \cdot \beta)x, \qquad $ for all $\alpha,\beta \in \mathbb{R}, x \in E$
		\item $\alpha(x+y) = \alpha x+ \alpha y, \qquad $ for all $\alpha \in \mathbb{R}, x,y \in E$
		\item $(\alpha + \beta) x = \alpha x + \beta x, \qquad $ for all $\alpha, \beta \in \mathbb{R}, x \in E$
		\item $1 \cdot x = x, \qquad $ for all $x \in E$.  
	\end{enumerate}
\end{definition*}
\begin{bemerkung}
	$E$ is a complec vector space if all $\mathbb{R}$ in the definition above are replaced by $\mathbb{C}$.
\end{bemerkung}
\begin{bemerkung}
	\begin{enumerate}[(1)]
		\item \[
			\exists\,! 0 \in E: \qquad x + 0 = x \qquad \text{for all }x \in E.
		\]
		since: Fix $x \in E$, by $(3)$, $\exists\, 0_x$ such that $0_x + x =x$. \\
		Fix $y \in E$. We want to show that $y + 0_y = y$. By $(3)$, there exists $z \in E$ such that $x+z = y$. So
		\begin{align*}
			y + 0_x & \stackrel{\hphantom{(1)}}{=} (x+z)+ 0_x \\
			&\stackrel{(1)}{=} (z+x)+ 0_x \\
			&\stackrel{(2)}{=} z + (x + 0_x) \\
			&\stackrel{\hphantom{(1)}}{=} z+x \\
			&\stackrel{(1)}{=}x+z \\
			&\stackrel{\hphantom{(1)}}{=} y.
		\end{align*}
		Assume $x+ 0_1 = x$, $x+ 0_2 =x$ for all $x \in E$. We want to show $0_1 = 0_2$:
		\[
			0_1 = 0_1 + 0_2 = 0_2 + 0_1 = 0_2
		\]
		\item 
		\[
			\forall\, x \in E: \, \exists\,! \,-x \in E: \,x+(-x)=0
		\]
		proof: exercise.
		\item \begin{align*}
			0x &=0 \qquad \text{for all }x \in E \\
			(-1)x &= -x \qquad \text{for all }x \in E
		\end{align*}
	\end{enumerate}
\end{bemerkung}
\begin{beispiele}[Examples of real vector spaces]
	\begin{enumerate}[1)]
		\item $\mathbb{R}$ with standard addition and mult. by scalar.
		\item $\mathbb{R}^n$, $n=2,3, \dots$
		\begin{description}
			\item[addition] $(x_1,x_2,\dots) + (y_1,y_2, \dots) = (x_1+y_1,x_2+y_2, \dots)$ 
			\item[mult.] $ \lambda (x_1,x_2,\dots) = (\lambda x_1, \lambda x_2, \dots)$
		\end{description} 
		\item $\mathbb{R}^{\infty} = \set[(x_1,\dots,x_n,\dots)]{x_n \in \mathbb{R}, n=1,2,\dots}$
		\item $1 \leq p < \infty$, 
		\[
			l^p = \set[(x_1,\dots,x_n, \dots) \in \mathbb{R}^{\infty}]{\left( \sum_{n=1}^{\infty} \abs{x_n}^p \right)^{\frac{1}{p}} < \infty}
		\]
		with the same addition and mult. by scalar as in $\mathbb{R}^{\infty}$. We have to check:
		\begin{enumerate}[(1)]
			\item $x,y \in l^p \qquad \Rightarrow \qquad x+y \in l^p$
			\item $x \in l^p, \lambda \in \mathbb{R} \qquad \Rightarrow \qquad \lambda x \in l^p$ 
		\end{enumerate}
		For $(1)$ we assume $x = (x_1, \dots, x_n, \dots)$ and $y = (y_1, \dots, y_n, \dots)$.
		\begin{align*}
			x \in l^p \qquad &\Rightarrow \qquad \sum_{n=1}^{\infty}\abs{x_n}^p < \infty \\
			y \in l^p \qquad &\Rightarrow \qquad \sum_{n=1}^{\infty}\abs{y_n}^p < \infty
		\end{align*}
		\[
			\Rightarrow \qquad  x+y = (x_1+y_1, \dots) \stackrel{?}{\in } l^p?
		\]
		\begin{align*}
			\Rightarrow \sum_{n=1}^{\infty}\abs{x_n+y_n}^p & \leq \set{\abs{x_n+y_n} \leq \abs{x_n}+ \abs{y_n} \leq 2 \max \set{\abs{x_n},\abs{y_n}}} \\
			& \,\set{\abs{x_n+y_n}^p \leq 2^p \left( \abs{x_n}^p + \abs{y_n}^p \right)} \\
			&\leq \sum_{n=1}^{\infty}2^p (\abs{x_n}^p + \abs{y_n}^p) \\
			&= 2^p \underset{< \infty}{\underbrace{\sum_{}^{}\abs{x_n}^p}}+ 2^p \underset{< \infty}{\underbrace{\sum_{}^{}\abs{y_n}^p}} < \infty
		\end{align*}
		and \[
			\sum_{n=1}^{\infty} \abs{\lambda x_n}^p = \sum_{n=1}^{\infty} \abs{\lambda}^p \cdot \abs{x_n}^p = \abs{\lambda}^p \sum_{n=1}^{\infty}\abs{x_n}^p < \infty
		\]
		\item function spaces, say real-valued functions on $I$.
		\begin{description}
			\item[addition:] $(f+g)(x) = f(x)+ g(x), \qquad x \in I$
			\item[mult. by scalar:] $(\lambda f)(x)= \lambda f(x) \qquad $ for functions $f$ and $g$ 
		\end{description}
		\item $C(I):$ addition and mult. by scalar as in $(5)$. \\ $f,g$ continuous in $I$ implies that $f+g$ is continuous in $I$. \\
		Also if $f$ is continuous and $\lambda \in \mathbb{R}$ then $(\lambda f)$ is continuous in $I$.
		\item $P(I)= \,$ polynomials in $I$.
		\item $P_k(I)= \,$ polynomials of degree at most $k$ in $I$.
	\end{enumerate}
\end{beispiele}

%01.09.2016
\begin{theorem*}[Hölder's inequality]
	Assume $1<p<\infty$ and $\frac{1}{p}+ \frac{1}{q}=1$. Let $(x_1, \dots, x_n, \dots)$ and $(y_1,y_2, \dots, y_n, \dots)$ be sequences of complex numbers. Then
	\[
		\sum_{n=1}^{\infty}\abs{x_ny_n} 
		\leq \left( \sum_{n=1}^{\infty}\abs{x_n}^p \right)^{\frac{1}{p}} \cdot \left( \sum_{n=1}^{\infty}\abs{y_n}^q \right)^{\frac{1}{q}}
	\]
	Remark there the LHS can be infinity, but the RHS can also be infinity.
\end{theorem*}
\begin{beweis}
	\begin{description}
		\item[Step 1] We're going to proof 
		\[
			ab \leq \frac{a^p}{p}+ \frac{b^q}{q}, \qquad \text{for all }a,b >0
		\] 
		\[
			\int_{0}^{a} x^{p-1} \,\mathrm{d}x = \frac{a^p}{p}
		\]
		Note $y = x^{p-1}$ gives \[
			x  = y ^{\frac{1}{p-1}} = y^{\frac{1}{\frac{1}{1-\frac{1}{q}}-1}}= y ^{\frac{1}{\frac{q}{q-1}-1}} = y^{q-1}
		\] 
		so
		\[
			\int_{0}^{b}y^{q-1} \,\mathrm{d}y = \frac{b^q}{q}
		\]
		We get
		\[
			ab \leq \frac{a^p}{p}+ \frac{b^q}{q}
		\]
		(You also get condition for $=$)
		\item[Step 2] It is enough to consider the cases LHS $>0$ and RHS $< \infty$. There consists integer $N$ such that
		\[
			0 < \sum_{n=1}^{N}\abs{x_n}^p, \, \sum_{n=1}^{N}\abs{y_n}^q < \infty
		\]
		Set 
		\begin{align*}
			a &= \frac{\abs{x_k}}{\left( \sum_{n=1}^{N}\abs{x_n}^p \right)^{\frac{1}{p}}}, \qquad k = 1,2, \dots,N, \\
			b &= \frac{\abs{y_k}}{\left( \sum_{n=1}^{N}\abs{y_n}^q \right)^{\frac{1}{q}}}, \qquad k = 1,2, \dots,N.
		\end{align*}
		Insert into
		\[
			ab \leq \frac{a^p}{p}+ \frac{b^q}{q}.
		\]
		\[
			\frac{\abs{x_ky_k}}{\left( \sum_{n=1}^{N}\abs{x_n}^p \right)^{\frac{1}{p}}\left( \sum_{n=1}^{N}\abs{y_n}^q \right)^{\frac{1}{q}}} 
			\leq \frac{\abs{x_k}^p}{p \sum_{n=1}^{N}\abs{x_n}^p} + \frac{\abs{y_k}^q}{q \sum_{n=1}^{N}\abs{y_n}^q}, \qquad k = 1,2, \dots, N.
		\]
		We sum over $k$ from $1$ to $N$.
		\[
			\sum_{k=1}^{N}\abs{x_ky_k} \leq  \left( \sum_{n=1}^{N}\abs{x_n}^p \right)^{\frac{1}{p}} \cdot \left( \sum_{n=1}^{N}\abs{y_n}^q \right)^{\frac{1}{q}}
		\]
		Let $N \to \infty$. First in RHS and then in LHS. 
	\end{description}
\end{beweis}
\begin{theorem*}[Minkowski's inequality]
	Assume $1 \leq p < \infty$. and $X,Y \in l^p$. Then
	\[
		\norm{X+Y}_{l^p} \leq \norm{X}_{l^p} + \norm{Y}_{l^p}
	\]
\end{theorem*}
\begin{beweis}
	\begin{description}
		\item[$p=1$] 
		\begin{align*}
			\norm{X+Y}_{l^1} &= \norm{(x_1,x_2, \dots,x_n, \dots)+ (y_1,y_2, \dots,y_n, \dots)}_{l^1} \\
			&= \norm{(x_1+y_1, \dots,x_n + y_n, \dots)}_{l^1} \\
			&= \sum_{n=1}^{\infty} \abs{x_n+y_n} \\
			&\leq \sum_{n=1}^{\infty} (\abs{x_n}+\abs{y_n}) \\
			&= \sum_{n=1}^{\infty}\abs{x_n}+ \sum_{n=1}^{\infty}\abs{y_n} \\
			&= \norm{X}_{l^1}+ \norm{Y}_{l^1}
		\end{align*} 
		\item[$1 < p < \infty$] 
		\begin{align*}
					\norm{X+Y}_{l^p}^p &= \sum_{n=1}^{\infty}\abs{x_n+y_n}^p \\
					&= \sum_{n=1}^{\infty}\abs{x_n+y_n}\abs{x_n+y_n}^{p-1} \\
					&\leq \sum_{n=1}^{\infty}\abs{x_n}\abs{x_n+y_n}^{p-1} + \sum_{n=1}^{\infty}\abs{y_n}\abs{x_n+y_n}^{p-1}.
		\end{align*}
		Use Hölder to get
		\begin{align*}
			\sum_{n=1}^{\infty}\abs{x_n}\abs{x_n+y_n}^{p-1} &\leq
			 \underset{=\norm{X}_{l^p}}{\underbrace{\left( \sum_{n=1}^{\infty}\abs{x_n}^p \right)^{\frac{1}{p}}}} \cdot \left( \sum_{n=1}^{\infty}\abs{x_n+y_n}^{(p-1)q} \right)^{\frac{1}{q}} \\
			 &= \set{(p-1)q = (p-1)\frac{1}{1-\frac{1}{p}}=p} \\
			 &= \norm{X}_{l^p}  \left( \sum_{n=1}^{\infty}\abs{x_n+y_n}^p \right)^{\frac{1}{q}}.
		\end{align*}
		We have
		\[
			\norm{X+Y}_{l^p}^p \leq \left( \norm{X}_{l^p} + \norm{Y}_{l^p} \right) \norm{X+Y}_{l^p}^{\frac{p}{q}}
		\]
		If $\norm{X+Y}_{l^p} \neq 0$ then
		\[
			\norm{X+Y}_{l^p}^{p-\frac{p}{q}} \leq \norm{X}_{l^p} + \norm{Y}_{l^p}
		\]
		there
		\[
			p- \frac{p}{q} = p (1- \frac{1}{q}) = p \frac{1}{p} = 1.
		\]
	\end{description}
\end{beweis}
\begin{bemerkung}
	$f \in C([0,1])$ then for $1 \leq p < \infty$
	\[
		\norm{f}_{L^p} = \left( \int_{0}^{1} \abs{f(t)}^p \,\mathrm{d}t \right)^{\frac{1}{p}}.
	\]
	Claim:
	\begin{align*}
		\norm{fq}_{L^1} = \int_{0}^{1} \abs{f(t)\cdot g(t)} \,\mathrm{d}t \leq \norm{f}_{L^p} \cdot \norm{g}_{L^q}
	\end{align*}
	where $\frac{1}{p}+ \frac{1}{q}= 1$. Also we have
	\[
		\norm{f+q}_{L^p} \leq \norm{f}_{L^p}+ \norm{g}_{L^p}
	\]
	This is proven with the same technique as we used for $l^p$. $\sum_{n=1}^{\infty}$ is replaced by $\int_{0}^{1} \,\mathrm{d}t$. \\
	$E$ real/complex vector space. $x_1, \dots,x_n \in E$, $\lambda_1, \dots, \lambda_n$ scalar. We say that 
	\[
		\lambda_1 x_1, \dots, \lambda_n x_n
	\]
	is a linear combination of $x_1,\dots,x_n$. We say that $x_1,\dots,x_n$ are linear independent if 
	\[
		\alpha_1 x_1 + \dots + \alpha_n x_n = 0 \qquad \Rightarrow \qquad \alpha_1 = \dots = \alpha_n = 0.
	\]
	If $A \subset E$, we say that $A$ is linear independant if every linear combination of vectors in $A$ is linear independant.
\end{bemerkung}
	\begin{beispiele}
		\begin{enumerate}[(1)]
			\item 
		Set $E = P([0,1])$ and $A = \set[p_k]{p_k(x) = x^k, x \in [0,1], k= 0,1, \dots}$. A is linear independant since: \\ consider
		\[
			\alpha_0 p_0 + \alpha_1 p_1 + \dots + \alpha_np_n = 0
		\]
		i.e. 
		\[
			\alpha_0 p_0(x) + \alpha_1 p_1(x) + \dots + \alpha_n p_n(x) = 0(x), \qquad x \in [0,1] 
		\]
		i.e.
		\[
			\alpha_0 + \alpha_1 x + \dots + \alpha_n x^n = 0, \qquad x \in [0,1]
		\]
		If $x = 0$ then $\alpha_0 = 0$
		\[
			\alpha_1 x + \dots + \alpha_n x^n = 0, \qquad x \in [0,1].
		\]
		Differentiate
		\[
			\alpha_1 + 2 \alpha_2 x + \dots + n \alpha_n x^{n-1} = 0
		\]
		gives $\alpha_1 = 0$. Continue and get
		\[
			\alpha_0 = \alpha_1 = \dots = \alpha_n = 0.
		\]
		Set $B \subset E$ where
		\begin{align*}
			\text{span } B &= \set{\text{set of all linear combinations of elements in B}} \\
			&= \set[\sum_{k=1}^{n}\lambda_k x_k]{x_k \in B, \lambda_k \in \mathbb{R}, k=1,2,\dots,n \text{ where n is a positive integer}}
		\end{align*}
		\begin{bemerkung}
			\[
				\sum_{k=1}^{n}\lambda_k x_k \in E
			\]
			\[
				\sum_{k=1}^{\infty} \lambda_k x_k \text{    has no meaning}
			\]
		\end{bemerkung}
		$C \subset E$ is called a basis for E if
		\begin{enumerate}[1)]
			\item $C$ linear independant.
			\item $ \text{span } C = E$
		\end{enumerate}
		continue of the example above: \\
		Claim: $A$ is a basis for E.
		\item Set $E = l^2$ and
		\[
			A = \set[X_k]{k =1,2,\dots}
		\]
		\[
			X_k = (0,0,\dots,0,1,0,0,\dots)
		\]
		Claim: A is linear independant since
		\[
			\alpha_1 X_1 + \alpha_2 X_2 + \dots + \alpha_n X_n = 0
		\]
		Here 
		\[
			\alpha_1 X_1 = (\alpha_1,0,0,\dots), \qquad etc
		\]
		and
		\[
			0 = (0,0, \dots)
		\]
		So
		\[
			(\alpha_1,\alpha_2, \dots, \alpha_n,0, \dots) = (0,0,\dots)
		\]
		So $\alpha_1= \alpha_2 = \dots = \alpha_n = 0$. \\
		Question: Is $A$ a basis for $l^2$? \\
		We note: If $X \in \text{span }A$ then
		\[
			X = (x_1,x_2, \dots,x_n,0,0,\dots)
		\]
		for some positive integer $n$, i.e. $X$ has only finitely many nonzero positions. \\
		Cosider:
		\[
			X := (1, \frac{1}{2}, \dots, \frac{1}{n}, \dots)
		\]
		\[
			\norm{X}_{l^2} = \left( \sum_{n=1}^{\infty} \frac{1}{n^2} \right)^{\frac{1}{2}} < \infty
		\]
		So $X \in l^2 \setminus \text{span }A$.
		\end{enumerate}
		\begin{bemerkung}
			Every vector space has a basis (if we are allowed to use Axiom of Choice/ zorns lemma). \\ Basis = vector space basis = Hamel basis
		\end{bemerkung}
		Assume $x_1, \dots,x_n$ is a basis for $E$. Then every basis for $E$ must contain $n$ different elements. 
		\[
			n = \dim E
		\]
		is well-defined. (System of linear equations, homogeneous with more unknowns than equations. Then there exists a nontrivial solution.)
	\end{beispiele}
\begin{definition*}[norm]
	$E$ vector space. We say that $\norm{.}: E \to [0,\infty)$ is a norm on $E$ if
	\begin{enumerate}[1)]
		\item $\norm{x}=0 \qquad \Rightarrow x =0$
		\item $\norm{\lambda x} = \abs{\lambda} \norm{x} \qquad $ for all $x \in E, \lambda \in \mathbb{R}$
		\item $\norm{x+y} \leq \norm{x} + \norm{y} \qquad $ for all $x,y \in E$
	\end{enumerate}
	
\end{definition*}
\begin{bemerkung}
	\[
		\norm{0} = \norm{0 \cdot 0} = \underset{=0}{\underbrace{\abs{0}}} \norm{0} = 0
	\]
\end{bemerkung}
\begin{beispiele}
	\begin{enumerate}[(1)]
		\item $1 < p < \infty$ and 
	\[
		\norm{X}_{l^p} = \left( \sum_{n=1}^{\infty} \abs{x_n}^p \right)^{\frac{1}{p}}
	\]
	is a norm on $l^p$. Check $1)$,$2)$ and $3)$ above:
	\begin{enumerate}[1)]
		\item \phantom{1} \[
			0 = \norm{X}_{l^p} = \left( \sum_{n=1}^{\infty} \abs{x_n}^p \right)^{\frac{1}{p}} 
		\]
		It follows
		\[
			x_n=0, \qquad n=1,2,\dots
		\]
		\[
			\Rightarrow \qquad X = (x_1,x_2, \dots) = (0,0,\dots) = 0
		\]
		\item \phantom{1}\[
			\norm{\lambda X}_{l^p} = \left( \sum_{n=1}^{\infty} \abs{\lambda x_n}^p \right)^{\frac{1}{p}} 
			= \left( \abs{\lambda}^p \sum_{n=1}^{\infty} \abs{x_n}^p \right)^{\frac{1}{p}} = \abs{\lambda} \norm{X}_{l^p}
		\]
		\item \phantom{1}\[
			\norm{X+Y}_{l^p} \leq \set{\text{Minkowski's inequality}} \leq \norm{X}_{l^p} + \norm{Y}_{l^p}
		\]
	\end{enumerate}
	\item $E = C([0,1])$ and $f \in E$
	\[
		\norm{f} = \max\limits_{t \in [0,1]} \abs{f(t)} \in [0,\infty)
	\]
	Check the axioms above
	\begin{enumerate}[1)]
		\item If $\norm{f} = 0$ it follows
		\[
			\abs{f(t)} = 0 \,\text{ for all }t \in [0,1], \qquad \Rightarrow \qquad f=0
		\]
		\item \[
			\norm{\lambda f} = \max\limits_{t \in [0,1]} \underset{\abs{\lambda}\abs{f(t)}}{\underbrace{\abs{\underset{\lambda f(t)}{\underbrace{(\lambda f)(t)}}}}}
			= \abs{\lambda} \max\limits_{t \in [0,1]} \abs{f(t)} = \abs{\lambda} \norm{f}
		\]
		\item 
		\[
			\norm{f+g} = \max\limits_{t \in [0,1]} \abs{\underset{f(t)+g(t)}{\underbrace{(f+g)(t)}}} = \max\limits_{t \in [0,1]}  \left( \abs{f(t)} + \abs{g(t)} \right)
			\leq \max\limits_{t \in [0,1]} \abs{f(t)} + \max\limits_{t \in [0,1]} \abs{g(t)} = \norm{f} + \norm{g}
		\]
	\end{enumerate}
	\item $E = C([0,1])$ and $f \in E$.
	\[
		\norm{f}_{L^1} = \int_{0}^{1} \abs{f(t)} \,\mathrm{d}t 
	\]
	defines also a norm on $E$.
	\begin{description}
		\item[3)]
		\begin{align*}
			\norm{f+g}_{L^1} &= \int_{0}^{1} \abs{\underset{f(t)+g(t)}{\underbrace{(f+g)(t)}}} \,\mathrm{d}t \\
			&\leq \int_{0}^{1}(\abs{f(t)}+ \abs{g(t)}) \,\mathrm{d}t \\
			&= \int_{0}^{1}\abs{f(t)} \,\mathrm{d}t + \int_{0}^{1}\abs{g(t)} \,\mathrm{d}t \\
			&= \norm{f}_{L^1} + \norm{g}_{L^1}
		\end{align*}
		\item[2)] \[
			\norm{\lambda f} = \int_{0}^{1} \underset{= \abs{\lambda}\abs{f(t)}}{\underbrace{\abs{(\lambda f)(t)}}} \,\mathrm{d}t = \abs{\lambda} \norm{f}_{L^1}
		\]
		\item[1)] \[
			0 = \norm{f}_{L^1} = \int_{0}^{1}\abs{f(t)} \,\mathrm{d}t
		\]
		This implies $f(t)=0$ for $t \in [0,1]$ since f is continuous! i.e. $f=0$
	\end{description}
	\end{enumerate}
\end{beispiele}
\begin{theorem*}[equivalent norm]
	$E$ vector space with norms $\norm{.}$ and $\norm{.}_{*}$. We say that $\norm{.}$ and $\norm{.}_{*}$ are equivalent if there exists $\alpha, \beta >0$ such that
	\[
		\alpha \norm{x}_{*} \leq \norm{x} \leq \beta \norm{x}_{*} \qquad \text{for all }x \in E.
	\]
\end{theorem*}
\begin{beispiel}
		\item $E = C([0,1])$. Choose $y = f(t)$ and $y = \abs{f(t)}$
		\[
			\norm{f} = \max\limits_{t \in [0,1]} \abs{f(t)}, \qquad \norm{f}_{*} = \norm{f}_{L^1} = \text{area}.
		\]
		Question: Are these norms equivalent? \\
		Claim $f \in C([0,1])$ 
		\[
			\norm{f}_{*} = \int_{0}^{1} \underset{\leq \norm{f}}{\underbrace{\abs{f(t)}}} \,\mathrm{d}t \leq \norm{f}
		\]
		Choose $f_n(t)$ such that
		\[
			\norm{f_n} = 1, \qquad \norm{f_n}_{*} = \frac{1}{2n}
		\]
		So 
		\[
			\frac{\norm{f_n}_{*}}{\norm{f_n}} = \frac{1}{2n} \to 0 \qquad n \to \infty
		\]
		The norms are not equivalent! Answer: NO ! 
	\end{beispiel}
\begin{theorem*}
	$E$ vector space with $\dim E < \infty$.  \\
	$\Rightarrow $ All norms on $E$ are equivalent.
\end{theorem*}
\begin{beweis}
	Assume $n = \dim E$ with a positive integer $n$. Let $x_1,x_2, \dots , x_n$ be a basis for $E$. For every $x \in E$
	\[
		x = \alpha_1(x)x_1 + \dots + \alpha_n(x)x_n
	\]
	where $\alpha_1(x), \dots, \alpha_n(x)$ unique. Set 
	\[
		\norm{x}_{*} = \abs{\alpha_1(x)}+ \dots + \abs{\alpha_n(x)}, \qquad x \in E
	\]
	Claim: $\norm{.}_{*}$ defines a norm on $E$ (easy proof) \\
	Fix an arbitrary norm $\norm{.}$ on $E$. \\
	Claim: $\norm{.}_{*}$ and $\norm{.}$ are equivalent. \\
	Note for $x \in E$
	\begin{align*}
		\norm{x} &= \norm{\alpha_1(x)x_1 + \dots + \alpha_n(x)x_n}  \\
		&\leq \abs{\alpha_1(x)}\norm{x_1} + \dots + \abs{\alpha_n(x)} \norm{x_n} \\
		&\leq \max\limits_{k=1,2,\dots,n} \norm{x_k} ( \underset{= \norm{x}_{*}}{\underbrace{\abs{\alpha_1(x)}+ \dots + \abs{\alpha_n(x)}}}) 
	\end{align*}
	Set $\beta = \max\limits_{k=1,2,\dots,n} \norm{x_k}$.
	Then
	\[
		\norm{x} \leq \beta \norm{x}_{*} \qquad \text{for all }x \in E.
	\]
	Remains to prove: There exists $\alpha >0$ such that
	\[
		\alpha \norm{x}_{*} \leq \norm{x} \qquad \text{for all } x \in E \qquad (*)
	\]
	Let $E$ be a vector space with norm $\norm{.}$ and $(v_m)_{m=1}^{\infty}$ a sequence in $E$. We say that $(v_m)_{m=1}^{\infty}$ converges in $(E,\norm{.})$ if there exists $v \in E$ such that $\norm{v_m-v} \to 0$ for $n \to \infty$. \\
	Notation: $v_m \to v$ in $(E, \norm{.})$. \\
	Note: If we have $\norm{.}$ and $\norm{.}_{*}$ are equivalent, then
	\[
		v_n \to v \text{ in }(E,\norm{.}) \qquad  \Leftrightarrow \qquad v_n \to v \text{ in }(E,\norm{.}_{*})
	\] 
	Back to $(*)$: Argue by contradiction. \\
	Assume there is no $\alpha >0$ such that
	\[
		\alpha \norm{x}_{*} \leq \norm{x} \qquad \text{for all } x \in E
	\]
	For $k=1,2,3,\dots$ there are $y_k \in E$ such that
	\[
		\frac{1}{k}\norm{y_k}_{*} > \norm{y_k}. \qquad (**)
	\]
	We have 
	\[
		y_k = \alpha_1^{(k)} x_1 + \dots + \alpha_n^{(k)} x_n
	\]
	where $\alpha_1^{(k)}, \dots, \alpha_n^{(k)}$ are unique scalars and $k = 1,2, \dots$. \\
	$(**)$ implies that
	\[
		k \norm{y_k} < \abs{\alpha_1^{(k)}} + \dots + \abs{\alpha_n^{(k)}}
	\]
	WLOG we can assume $\abs{\alpha_1^{(k)}}+ \dots + \abs{\alpha_n^{(k)}} = 1$. ( If not consider 
	\begin{align*}
		\lambda z &= \lambda ( \alpha_1(z)x_1+ \dots+ \alpha_n(z)x_n)  \\
		&= (\lambda \alpha_1(z))x_1 + \dots + (\lambda \alpha_n (z))x_n \\
		&= \alpha_1(\lambda z)x_1 + \dots + \alpha_n(\lambda z)x_n
	\end{align*}
	We have \[
		\alpha_k(\lambda z) = \lambda \alpha_k(z), \qquad k=1,2,\dots,n)
	\]
	We have 
	\[
		k \norm{y_k} < 1 \qquad k=1,2,\dots
	\]
	which implies $y_k \to 0$ in $(E,\norm{.})$. \\
	\begin{Large}
		\underline{IF:}
	\end{Large} \begin{align*}
		\alpha_1^{(k)} &\to \bar{\alpha_1} \\
		\alpha_2^{(k)} &\to \bar{\alpha_2} \\
		&\vdots \\
		\alpha_n^{(k)} &\to \bar{\alpha_n}
	\end{align*}
	for $k \to \infty$. Then set
	\[
		\bar{y} = \bar{\alpha_1}x_1 + \dots + \bar{\alpha_n}x_n
	\]
	and get
	\begin{align*}
		\norm{y_k-\bar{y}} &= \norm{(\alpha_1^{(k)}-\bar{\alpha_1})x_1 + \dots+ (\alpha_n^{(k)}-\bar{\alpha_n})x_n} \\
		&\leq \underset{\to 0}{\underbrace{\abs{\alpha_1^{(k)}-\bar{\alpha_1}}}}\underset{< \infty}{\underbrace{\norm{x_1}}} 
		+ \dots + \underset{\to 0}{\underbrace{\abs{\alpha_n^{(k)}-\bar{\alpha_n}}}}\underset{< \infty}{\underbrace{\norm{x_n}}} \to 0, \qquad k \to \infty
	\end{align*}
	\[
		\norm{\bar{y}} = \norm{\bar{y}-y_k + y_k} \leq \underset{\to 0}{\underbrace{\bar{y}-y_k}} + \underset{\to 0}{\underbrace{\norm{y_k}}} \to 0, \qquad k \to \infty
	\]
	So $\norm{\bar{y}} = 0$ hence $\bar{y}=0$. But
	\[
		\abs{\bar{\alpha_1}} + \abs{\bar{\alpha_2}} + \dots + \abs{\bar{\alpha_n}} = 1.
	\]
	This contradicts $x_1, \dots,x_n$ is a basis. \\
	We have for $k= 1,2, \dots$ the vector $(\alpha_1^{(k)},\alpha_2^{(k)},\dots,\alpha_n^{(k)})$ where
	\[
		\abs{\alpha_1^{(k)}}+ \dots + \abs{\alpha_n^{(k)}} = 1
	\]
	We focus on the first one and we have
	\[
		\abs{\alpha_1^{(k)}} \leq 1, \qquad k =1,2,\dots
	\]
	By Bolzano-Weierstraß then there exists a converging subsequence $(\alpha_{1,1}^{(k)})_{k=1}^{\infty}$ of $(\alpha_{1}^{(k)})_{k=1}^{\infty}$. Set
	\[
		\bar{\alpha_1} = \lim_{k \to \infty} \alpha_{1,1}^{(k)}
	\]
	consider
	\[
		(\alpha_{1,1}^{(k)},\alpha_{2,1}^{(k)}, \dots ,\alpha_{n,1}^{(k)}), \qquad k=1,2,\dots
	\]
	We have 
	\[
		\abs{\alpha_{2,1}^{(k)}} \leq 1, \qquad k=1,2,\dots
	\]
	Bolzano-Weierstraß implies that there exists a converging subsequenz $(\alpha_{2,2}^{(k)})_{k=1}^{\infty}$ of $(\alpha_{2,1}^{(k)})_{k=1}^{\infty}$. 
	Set 
	\[
		\bar{\alpha_2} = \lim_{k \to \infty} \alpha_{2,2}^{(k)}
	\]
\end{beweis}

\begin{definition*}[normed space]
	Let $E$ be a vector space over $\mathbb{R}$ or $\mathbb{C}$. $\norm{.}:E \to \mathbb{R}$ a norm on $E$ if
	\begin{enumerate}[(i)]
		\item $\norm{.} >0 \qquad $ for any $x \in E \setminus \set{0}$
		\item $\norm{\lambda x} = \abs{\lambda x} \qquad $ for any $\lambda \in \mathbb{C},x \in E$.
		\item $\norm{x+y} \leq \norm{x} + \norm{y} \qquad$ for any $x,y \in E$.
	\end{enumerate}
	Obs. $\norm{x}=0$ if $x =0$. $(E, \norm{.})$ is called a normed space. A norm generates a distance function (metric)
	\[
		L(x,y):= \norm{x-y} \qquad \text{ for any }x,y \in E.
	\]
\end{definition*}
\begin{beispiele}
	\begin{itemize}
		\item $\mathbb{R}^n$ with $\norm{x}_2 = \sqrt{\sum^{n}_{i=1}\abs{x_i}^2}$ is the eucledian norm.
		\item $C([0,1])$ continuous functions in $[0,1]$ with
		\[
			L(f,g)=\norm{f-g}_{\infty}:= \max_{x \in [0,1]}\abs{f(x)-g(x)}
		\]
	\end{itemize}
\end{beispiele}
\begin{definition*}[balls]
	 Let $x \in E$, $r >0$. Define
	\begin{align*}
		B(x,r) &:= \set[y \in E]{\norm{x-y}<r} \qquad \text{open ball} \\
		\bar{B}(x,r) &:= \set[y \in E]{\norm{x-y}\leq r} \qquad \text{closed ball}
	\end{align*}
\end{definition*}
\begin{definition*}[open/closed]
	A subset $A \subset E$ of a normed space $(E,\norm{.})$ is called \underline{open} of any point $x$ of $A$ is inner, i.e 
	\[
		\exists\,r>0 \,:\, B(x,r) \subset A.
	\]
	It is called \underline{closed} if the complement $E \setminus A$ is open.
\end{definition*}
\begin{bemerkung}
	\begin{itemize}
		\item open balls are open sets.
		\item closed balls are closed.
		\item $(C([0,1]),\norm{.}_{\infty})$ with $\norm{f}_{\infty}= \max_{x \in [0,1]}\abs{f(x)}.$ 
		\[
			A := \set[g \in C([0,1])]{f(x) < g(x),\,\forall\, x \in [0,1]}
		\]
		is an open set $C([0,1])$.
		\[
			B := \set[g \in C([0,1])]{f(x) \leq g(x),\,\forall\, x \in [0,1]}
 		\]
		is a closed set.
	\end{itemize}
	\minisec{Properties}
	\begin{itemize}
		\item Any union of open sets is an open set.
		\item Any \underline{finite} intersection of open sets is open.
		\item $\emptyset,E$ are both closed and open.
		\item Normed spaces are topological spaces.
	\end{itemize}
\end{bemerkung}
\begin{definition*}[convergence in normed spaces]
	Let $(E,\norm{.})$ be a normed space $\set{x_n}_n \subset E$. We say that $x_n$ converges to $x \in E$ if 
	\[
		\norm{x_n-x} \to 0, \qquad n \to \infty
	\]
\end{definition*}
One can define open and closed using the definition of convergence:
\begin{satz*} % statement
	$A \subseteq E$ is closed if any convergent sequence in $A$ has a limit in $A$, i.e
	\[
		\substack{x_n \to x \\ \text{for }n \to \infty \\ x_n \in A} \Rightarrow x \in A
	\]
\end{satz*}
\begin{beweis}
	\begin{description}
		\item[$\Rightarrow$:]Assume that $A$ is closed and $x_n \to x$. $x_n \in A$, but $x_n \not \in A$. (try to get a contradiction). \\
	 $A$ is closed $\Rightarrow $ $E \setminus A$ is open and hence $\exists\, r >0$ such that
	 \[
	 	B(x,r) \subset E \setminus A.
	 \]
	 Hence $\norm{x_n -x} \geq r$ for any $n$. This is a contradiction because in that case $x_n \not \to x$
	 \item[$\Leftarrow $:] Assume that for any sequence $\set{x_n} \subset A$ such that $x_n \to x$ we have $x \in A$. We try to get a contradiction and assume that $A$ is not closed. Hence $E \setminus A$ is not open and therefore $\exists\, x \in E \setminus A$ which is not inner.
	 \[
	 	\Rightarrow \qquad  \forall\, B(x,\frac{1}{n}) \text{ containts points outside }E \setminus A 
	 \]
	 i.e.
	 \[
	 	\exists\, x_n \in B(x, \frac{1}{n}), \, x_n \in A.
	 \]
	 We get a sequence $\set{x_n} \subset A$ such that
	 \[
	 	\norm{x_n-x} < \frac{1}{n} \qquad \Rightarrow \qquad x_n \to x
	 \]
	 This is a contradiction
	\end{description}
\end{beweis}
\begin{definition*}[closure]
	$A \subset E$. The closure of $A$ is the minimal closed subset containing $A$. We write $\bar{A}$.
\end{definition*}
\begin{proposition*}
	$\bar{A}$ is the set of all limit points of $A$ which means
	\[
		\bar{A} := \set[x \in E]{\text{there exists $\set{x_n} \subseteq A$ such that $x_n \to x$}}
	\]
\end{proposition*}
\begin{beweis}
	exercise.
\end{beweis}
\begin{definition*}[dense]
	$A \subset E$ is dense in $E$ if 
	\[
		\bar{A} = E.
	\]
\end{definition*}
\begin{bemerkung}
	This definition of dense is equivalent to the following definition:
	\[
		\forall\, x \in E,\,\forall\, \varepsilon>0 \,\exists\,y \in A \text{ such that } \norm{x-y} < \varepsilon.
	\]
\end{bemerkung}
\begin{beispiele}
	\begin{enumerate}[1)]
		\item $\mathbb{Q} \subseteq \mathbb{R}$ with $\abs{.}$ usual absolut value function. $\mathbb{Q}$ is dense in $\mathbb{R}$.
		\item $C([a,b])$. The \underline{Weirestrasstheorem} says that the set of all polynomials are dense in $(C([a,b],\norm{.}_{\infty}))$:
		\[
			\forall\, f \in C([a,b]),\,\forall\, \varepsilon>0 \,\exists\,p-\text{polynomial such that }\max_{x \in [a,b]}\abs{f(x)-p(x)} < \varepsilon.
		\]
	\end{enumerate}
\end{beispiele}
Another example is $(C_0, \norm{.}_{\infty})$ where
		\[
			C_0 = \set[x = (x_1,x_2,\dots)]{x_k \to 0 \text{ as }k \to \infty}
		\]
		\[
			\norm{x}_{\infty}= \sup_{i}\abs{x_i}
		\]
		$(C_0,\norm{.}_{\infty})$ is a normed space. 
		\[
			C_F = \set[x = (x_1,x_2,\dots)]{\text{only a finite number of }x_i \neq 0} \subset C_0
		\]
\begin{satz*}
	$C_F$ is dense in $C_0$
\end{satz*}
\begin{beweis}
	\[
		\forall\,  x \in C_0 \,\forall\, \varepsilon>0 \text{ must find }y \in C_F \text{ such that }\norm{y-x}_{\infty} < \varepsilon.
	\]
	\[
		x \in C_0 \qquad \Rightarrow \qquad x_k \to 0 \text{ for }k \to \infty 
	\]
	\[
		\Rightarrow \qquad \forall\, \varepsilon >0 \,\exists\,K \,\text{ such that } \abs{x_k} < \varepsilon \, \forall\, k \geq K
	\]
	Let now $y = (x_1,x_2, \dots,x_K, 0, \dots) \in C_F$. Then 
	\[
		\norm{x-y}_{\infty} = \norm{(0,0,\dots,0,x_{K+1},x_{K+2},\dots)}_{\infty} = \sup_{k >K}\abs{x_k} < \varepsilon
	\]
\end{beweis}
\begin{definition*}[separable]
	A normed space $(E,\norm{.})$ is called \underline{separable} if it contains a countable dense subset.
\end{definition*}
\begin{beispiele}
	\begin{itemize}
		\item $(\mathbb{R},\abs{.})$ is separable as $\mathbb{Q}$ is countable and dense in $\mathbb{R}$.
		\item $(\mathbb{R}^n,\norm{.}_2)$ is separable, $\mathbb{Q}^n$ is countable and dense in $\mathbb{R}$.
	\end{itemize}
\end{beispiele}
\begin{definition*}[compact set]
	For a normed space $(E,\norm{.})$ is $A \subset E$ a compact set if any sequence $\set{x_n} \subset A$ has a subsequence convergent to an element $x \in A$.
\end{definition*}
\begin{beispiel}
	 Any bounded and closed subset in $\mathbb{R}, \mathbb{R}^n, \mathbb{C}^n$ is compact. A sequence $\set{x_n}$ of a bounded set is bounded. From real Analysis one knows it has a subsequence that is convergent. If the subset is closed then the limit point is inside the set. 
\end{beispiel}
\begin{lemma*}
	$S \subset$ compact in $(E, \norm{.})$ implies that $S$ is closed and bounded.(Bounded means that $S \subset B(0,R)$ for some $R>0$)
\end{lemma*}
\begin{beweis}
	Let $S$ be a compact subset of $E$. Assume that $S$ is not bounded. Hence for any $n >0$ there exists points in $S$ which are outside $B(0,n)$, i.e. 
	\[
		\exists\, x_n \in S \,: \norm{x_n} >n.
	\]
	Then $\set{x_n}$ can not have a convergent subsequence as if $x_{n_k} \to x$ then
	\[
		n_k < \norm{x_{n_k}} = \norm{x_{n_k}-x + x} \leq \norm{x_{n_k}-x} + \norm{x} \to \norm{x}
	\]
	but $n_k \to \infty$. This is a contradiction, hence $S$ must be bounded. \\ $S$ must be closed, because if $x_n \to x$ then any subsequence converges to $x$. From the definition of compactness and uniqueness of the limit we have $x \in S$. \\
\end{beweis}
\begin{bemerkung}
	In general, $S$ bounded and closed doesn't imply that $S$ is compact. \\
For instance let $E= C([0,1])$. Then $S=\set[g \in C([0,1])]{\norm{g}_{\infty}\leq 1}$ is closed and bounded, but not compact. \\
Take $x_n(t):=t^n$. Then $x_n \in S$. $\set{x_n}$ does not have a subsequence convergent to a continuous function.
\end{bemerkung}
\begin{theorem*}
	$(E,\norm{.})$ normed space and $\dim E < \infty$ \\ iff $\set{\forall\, A \subset E,\,A \text{compact} \Leftrightarrow A \text{ is closed and bounded}}$
\end{theorem*}
\begin{beweis}
	\begin{description}
		\item[$\Rightarrow$:]If $\dim E < \infty$ then $A$ is compact iff $A$ is bounded and closed (exsercise)
		\item[$\Leftarrow$:]Enough to prove the following: \\
		If $\dim E = \infty$ then the unit ball $S = \set[x \in E]{\norm{x}\leq 1}$ is not compact.
	\end{description}
\begin{lemma*}[Riesz's lemma]
	If $X$ is a proper closed subspace of a normed space $(E,\norm{.})$ then for every $\varepsilon \in (0,1)$ there exists an $x_{\varepsilon} \in E$ with $\norm{x_\varepsilon}=1$ such that
	\[
		\norm{x_{\varepsilon}-x} \geq \varepsilon \qquad \forall\, x \in X.
	\]
\end{lemma*}
\begin{beweis}
	Let $z \in E \setminus X$ ($X$ proper and hence $E \setminus X \neq \emptyset$). Set 
	\[
		d:= \inf_{x \in X}\norm{z-x}
	\] As $X$ is closed, $d >0$, otherwise $z$ is a limit point in $E \setminus X$. Fix $\varepsilon \in (0,1)$. Then there exists $x_0 \in X$ such that
	\[
		d \leq \norm{z-x_0} < \frac{d}{\varepsilon}.
	\]
	Let $x_\varepsilon := \frac{z-x_0}{\norm{z-x_0}}$; We have $\norm{x_\varepsilon}=1$ and
	\begin{align*}
		\norm{x- x_\varepsilon} &= \norm{x - \frac{z-x_0}{\norm{z-x_0}}} \\
		&= \frac{\norm{x \norm{z-x_0}-z + x_0}}{\norm{z-x_0}} \\
		&= \frac{\norm{\overset{\in X}{\overbrace{x \norm{z-x_0}+ x_0 }}- z}}{\norm{z-x_0}} \\
		&\geq \frac{d}{d}\varepsilon = \varepsilon
	\end{align*}
\end{beweis}
Continue now proof of the theorem above: \\
Let $x_1 \in S$. Consider $X = \text{span} \set{x_1}$ which is a proper closed subspace of $E$. Hence by Riesz's lemma exists $x_2$ with $\norm{x_2}=1$ such that
\[
	\norm{x_2-x_1} \geq \frac{1}{2} 
\]
and
\[
	\norm{x_2-x} \geq \frac{1}{2} \qquad \forall\, x \in X.
\]
Now consider $\text{span} \set{x_1,x_2}$ which is a proper closed subspace of $E$. By Riesz's lemma follows
\[
	\exists\,x_3 \in E,\, \norm{x_3}=1: \, \norm{x_3-x_1}\geq \frac{1}{2}, \norm{x_3-x_2} \geq \frac{1}{2}.
\]
Continuing in the same fashion we get $\set{x_n}$, $\norm{x_n}=1$ such that 
\[
	\norm{x_n-x_m} \geq \frac{1}{2} \qquad \forall\, n,m,\,n \neq m.
\]
Clearly $\set{x_n} \subset S$ has no convergent subsequence. Hence $S$ is not compact.
\end{beweis}
\begin{definition*}[Cauchy sequence]
	$(E, \norm{.})$ normed space. $\set{x_n} \subseteq E$ is called Cauchy if
	\[
		\forall\, \varepsilon >0 \,\exists\,N: \,\norm{x_n-x_m}< \varepsilon \,\text{ for any }n,m \geq N.
	\]
\end{definition*}
\begin{beispiel}
	$(C_F,\norm{.}_{\infty})$, $\norm{x}_{\infty}= \sup_{k \in \mathbb{N}}\abs{x_k}$ where $x = (x_1,x_2,\dots)$. Define
	\[
		x_n = (1, \frac{1}{2}, \frac{1}{3}, \dots, \frac{1}{n}, 0, \dots)
	\]
	Then $\set{x_n}$ is Cauchy, as for $n >m$ 
	\begin{align*}
		\norm{x_n-x_m}_{\infty} &= \norm{(0, \dots,0, \frac{1}{m+1}, \dots, \frac{1}{n},0,\dots)}_{\infty} \\
		&= \frac{1}{m+1}
	\end{align*}
	Observe that $x_n$ is convergent in $(C_0,\norm{.}_{\infty})$
	\[
		\underset{\in C_F}{\underbrace{x_n}} \to (1, \frac{1}{2}, \frac{1}{3}, \dots, \frac{1}{n}, \dots) \in C_0 \setminus C_F
	\]
\end{beispiel}
\begin{satz}
	A convergent sequence is always a Cauchy sequence.
\end{satz}
\begin{definition*}[complete space]
	A normed vector space $(E, \norm{.})$ is called \underline{complete} if any Cauchy sequence in $E$ is convergent in $E$.
\end{definition*}
\begin{definition*}[Banach space]
	A complete normed space is called \underline{Banach space}.
\end{definition*}
\begin{beispiele}
	\begin{itemize}
		\item $(\mathbb{R},\abs{.})$ is a Banach space.
		\item $(\mathbb{C},\abs{.})$ as well.
		\item $(l^2,\norm{.}_2)$ where
		\[
			l^2= \set[(x_1,x_2,\dots)]{\sum^{\infty}_{i=1} \abs{x_i}^2 < \infty, x_i \in \mathbb{C}}
		\]
		and 
		\[
			\norm{(x_1,x_2,\dots)}_2 = \left( \sum_{i=1}^{\infty} \abs{x_i}^2 \right)^{\frac{1}{2}}
		\]
		$(l^2,\norm{.}_2)$ is complete.
		\begin{beweis}
			Let $x_n = (x_1^n,x_2^n,\dots)$ be a Cauchy sequence in $l^2$. We must show that it has a limit in $l^2$. We will do it in a few steps:
			\begin{enumerate}[Step 1:]
				\item Find a candidate for a limit $a$
				\item Show that $a \in l^2$.
				\item $\norm{x_n - a }_2 \to 0$ as $n \to \infty$.
			\end{enumerate}
			\begin{enumerate}[Step 1:]
				\item Let
				\begin{align*}
					x_1 &= (x_1^1,x_2^1, \dots) \\
					x_2 &= (x_1^2,x_2^2, \dots) \\
					\vdots & \qquad \vdots \\
					x_n &= (x_1^n,x_2^n, \dots)
				\end{align*}
				For each $k$ consider sequence $\set{x_k^n} \subset \mathbb{C}$ ($k$-th coordinates in each $x_n$). \\
				Each sequence is Cauchy, as for all $n,m \geq N$
				\[
					\abs{x_k^n-x_k^m} < \left( \sum_{k=1}^{\infty} \abs{x_k^n-x_k^m}^2 \right)^{\frac{1}{2}} = \norm{x_n-x_m}_2 < \varepsilon
				\]
				As $(\mathbb{C}, \abs{.})$ is complete, $\set{x_k^n}_n$ has a limit $a_k \in \mathbb{C}$. Candidate for limit of $x_n$ is 
				\[
					a= (a_1,a_2, \dots, a_k, \dots).
				\]
				\item Write 
				\[
					a = \underset{\in l^2}{\underbrace{x_n}} - (x_n - a)
				\]
				In order to show that $a \in l^2$ it is enough to see that $x_n - a \in l^2$ for some $n$. \\
				$\set{x_n}$ Cauchy implies
				\[
					\forall\, \varepsilon>0 \,\exists\,N: \,\forall\, n,m \geq N: \,\norm{x_n-x_m}_2 < \varepsilon.
				\]
				Consider for some $u>0$
				\begin{align*}
					\sum^{u}_{i=1} \abs{x_i^n-x_i^m}^2 \leq \sum_{i=1}^{\infty}\abs{x_i^n-x_i^m}^2 = \norm{x_n-x_m}^2_2 < \varepsilon^2
				\end{align*}
				Let $m \to \infty$. We get 
				\[
					\sum^{m}_{i=1} \abs{x_i^n-a_i}^2 \leq  \varepsilon^2
				\]
				This holds for any $u \in \mathbb{N}$. Hence for any $n \geq \mathbb{N}$
				\[
					\underset{= \norm{x_n-a}_2^2}{\underbrace{\sum_{i=1}^{\infty}\abs{x_i^n-a_i}^2}} \leq \varepsilon^2.
				\]
				Hence $x_n - a \in l^2$ and moreover $\norm{x_n - a} \to 0$ as $n \to \infty$.
			\end{enumerate}
		\end{beweis}
		\item $(C([a,b]),\norm{.}_{\infty})$ is a Banach space.
		\item $(l^p,\norm{.}_{l^p})$ for $1 \leq p < \infty$ are all Banach spaces.
		\item $(C([a,b]),\norm{.}_2)$ with
		\[
			\norm{f}_2 = \left( \int_{}^{} \abs{f(t)}^2 \,\mathrm{d}t \right)^{\frac{1}{2}}
		\]
		One can prove that $(C([a,b]),\norm{.}_2)$ is not a Banach space.
		\minisec{Exercise:} $[a,b] = [0,1]$ and \[
			f_n(t)= \begin{cases}
				0, &\text{ falls }t < \frac{1}{2} - \frac{1}{n}\\
				1, &\text{ falls }t > \frac{1}{2}\\
				\text{continuous linear function}
			\end{cases}.
		\]
		Show that $\set{f_n}$ is Cauchy in $C([0,1],\norm{.}_2)$ but $f_n \not \to f \in C([0,1])$.
	\end{itemize}
\end{beispiele}
\begin{definition*}[Convergent and absolutely convergent series]
	A series $\sum_{n=1}^{\infty}x_n$ in $E$ is called \underline{convergent} if $\set{\sum_{n=1}^{m}x_n}_m$, a sequence of partial sums, is convergent in $E$. If $\sum_{n=1}^{\infty}\norm{x_n} < \infty$ then we say that $\sum_{n=1}^{\infty}x_n$ converges absolutely.
\end{definition*}
\begin{theorem*}
	A normed space $E$ is complete iff every absolutely convergent series converges in $E$.
\end{theorem*}
\begin{beweis}
	\begin{description}
		\item[$\Rightarrow$:] Suppose $X$ is complete and $\sum_{n=1}^{\infty}\norm{x_n} < \infty$. Let 
		\[
			S_N := \sum_{n=1}^{N}x_n \in E.
		\] 
		For $M >N$:
		\begin{align*}
			\norm{S_N-S_M} &= \norm{\sum_{n=N+1}^{M}x_n} \\
			&\leq \sum_{n=N+1}^{M} \norm{x_n} \\
			&\leq \sum_{n=N+1}^{\infty} \norm{x_n} \to 0 \qquad \text{as }N \to \infty
		\end{align*}
		Hence $\set{S_N}$ is Cauchy. As $E$ is complete, $S_N$ has a limit in $E$ i.e. $\sum_{n=1}^{\infty}x_n$ converges in $E$.
		\item[$\Leftarrow$:] Assume that every absolut convergent series is convergent in $E$. We want to see that $E$ is complete. \\
		Let $\set{x_n}$ be a Cauchy sequence. We want to prove that $\set{x_n}$ has a limit in $E$. We know that
		\[
			\forall\, k \,\exists\,n_k: \, \norm{x_n-x_m}< \frac{1}{2^k} \qquad \forall\, n,m \geq n_k.
		\]
		We can assume that $\set{n_k}$ is an increasing sequence. Write
		\[
			x_{n_k} = (x_{n_k}-x_{n_{k-1}})+ (x_{n_{k-1}}-x_{n_{k-2}}) + \dots +(x_{n_1}-\underset{=0}{\underbrace{x_{n_0}}}) = \sum_{l=1}^{k}(x_{n_l}-x_{n_{l-1}}).
		\]
		\[
			\sum_{l=1}^{\infty}\norm{x_{n_l}-x_{n_{l-1}}} \leq \sum_{l=1}^{\infty}\frac{1}{2^l} < \infty
		\]
		Hence $\sum_{l=1}^{\infty}(x_{n_l}-x_{n_{l-1}})$ is absolutely convergent. By assumption 
		\[
			\sum_{l=1}^{\infty}(x_{n_l}-x_{n_{l-1}}) 
		\]
		is convergent in $E$. Hence the partial sums is convergent. Subsequence is convergent. $\set{x_{n_k}}$ is convergent to some $x \in E$.
		\minisec{Exercise:} Show that the whole $\set{x_n} \to x$.
	\end{description}
\end{beweis}
%%% 8.9.2016
\minisec{Recall:}
converging squences $(x_n)_{n=1}^{\infty}$ in $(E,\norm{.})$. $\norm{x_n-x} \to 0$ for $n \to \infty$ for some $x \in E$. (Notation: $x_n \to x$ in $(E,\norm{.})$)
\begin{bemerkung}
	Assume $x_n \to x$ in $(E,\norm{.})$ Then
	\begin{enumerate}[1)]
		\item $\norm{x_n} \to \norm{x}$ in $(E,\norm{.})$. 
		\item $\sup_{n} \norm{x_n} < \infty$.
	\end{enumerate}
	because
	\begin{enumerate}[1)]
		\item \[
			\norm{x_n} \leq \norm{x_n-x} + \norm{x}
		\]
		so
		\[
			\norm{x_n} - \norm{x} \leq \norm{x_n -x}
		\]
		it follows
		\[
			-(\norm{x_n}-\norm{x}) \leq \norm{x_n -x}
		\]
		So
		\[
			\abs{\norm{x_n}-\norm{x}} \leq \norm{x_n -x} \to 0, \qquad \text{for } n \to \infty
		\]
		Cauchy sequence in $(x_n)_{n=1}^{\infty}$ in $(E,\norm{.})$ if $\norm{x_n-x_m} \to 0$ for $n,m \to \infty$. \\
		We obtain:
	 	$(x_n)_{n=1}^{\infty}$ converges in $(E,\norm{.})$  $\qquad \Rightarrow \qquad$  $(x_n)_{n=1}^{\infty}$ Cauchy sequence in $(E,\norm{.})$. ($\not \Leftarrow $ in general).
		If $\Leftarrow$ then we call $(E,\norm{.})$ a Banach space. 
	\end{enumerate}
	$\sum_{n=1}^{\infty}x_m$ converges in $(E,\norm{.})$ if $\left( \sum_{n=1}^{k}x_n \right)_{k=1}^{\infty}$ converges in $(E,\norm{.})$. \\
	$\sum_{n=1}^{\infty}x_m$ converges absolutely in $(E,\norm{.})$ if $\sum_{n=1}^{\infty}\norm{x_n}$ converges $(\mathbb{R},\norm{.})$. \\
\end{bemerkung}

\subsection{Mappings between normal spaces} 
\label{sub:mappings_between_normal_spaces}
\begin{definition*}
	Let $(E_1,\norm{.}_1)$, $(E_2,\norm{.}_2)$ be normal spaces. $T: E_1 \to E_2$ (not necessarily linear) is called continuous at $x_0 \in E_1$, if 
	\[
		x_n \to x_0 \text{ in } (E_1,\norm{.}_1) \qquad \Rightarrow \qquad T(x_n) \to T(x_0) \text{ in } (E_2,\norm{.}_2)
	\]
	$T$ is called \underline{continuous} if it is continuous at $x_0 \in E_1$ for all $x_0 \in E_1$. We say that $T: E_1 \to E_2$ is \underline{linear} if 
	\[
		T(\lambda_1 x_1 + \lambda_2 x_2) = \lambda_1 T(x_1) + \lambda_2 T(x_2)
	\]
	for all scalars $\lambda_1$, $\lambda_2$ and $x_1,x_2 \in E_1$. \\
	$T: E_1 \to E_2$ linear is called \underline{bounded} if there exists $M>0$ such that
	\[
		\norm{T(x)}_2 \leq M \norm{x}_1 \qquad \text{for all }x \in E_1.
	\]If $T$ is bounded linear $E_1 \to E_2$ define
	\[
		\norm{T} = \norm{T}_{E_1 \to E_2} := \inf \set[M \geq 0]{\norm{T(x)}_2 \leq M \norm{x}_1 \text{ for all }x \in E_1}
	\]
\end{definition*}
\begin{lemma*}
	\[
		\norm{T} = \sup\limits_{\substack{x \in E_1 \\ x \neq 0}} \frac{\norm{T(x)}_2}{\norm{x}_1} = \sup\limits_{\substack{x \in E_1 \\ \norm{x}_1=1}} \norm{T(x)}_2
	\]
\end{lemma*}
\begin{proposition*}
	Assume $T: E_1 \to E_2$ linear. Then all the following statements are equivalent:
	\begin{enumerate}[(1)]
		\item $T$ continuous at $0 \in E_1$.
		\item $T$ continuous at $x_0 \in E_1$ for some $x_0 \in E_1$.
		\item $T$ continuous at $x_0 \in E_1$ for all $x_0 \in E_1$.
		\item $T$ is bounded.
	\end{enumerate}
\end{proposition*}
\begin{beweis}
	\begin{description}
		\item[$(1) \Rightarrow (4)$:] Assume $T$ is continuous at $0 \in E_1$. i.e. 
		\[
			x_n \to 0 \text{ in }(E_1, \norm{.}_1) \qquad \Rightarrow \qquad T(x_n) \to T(\underset{\in E_1}{\underbrace{0}}) = \underset{\in E_2}{\underbrace{0}} \text{ in }(E_2,\norm{.}_2)
		\] 
		We want to prove that $T$ is bounded. We search a $M>0$ such that
		\[
			\norm{T(x)}_2 \leq  M \norm{x}_1
		\]
		We assume that this doesn't hold true. \\
		For $n=1,2,\dots$ there exists $x_n \in E_1$ such that 
		\[
			\norm{T(x_n)}_2 > n \norm{x_n}_1.
		\]
		Set for $n=1,2,\dots$
		\[
			z_n := \frac{1}{n \norm{x_n}_1}x_n
		\]
		(Note that $\norm{x_n}_1 >0$. Otherwise we would get a contradiction.) \\
		Note
		\begin{align*}
		\norm{z_n}_1 &= \norm{\frac{1}{n \norm{x_n}_1}}_1 = \frac{1}{n \norm{x_n}_1} \norm{x_n}_1 = \frac{1}{n} \to 0, \qquad \text{for }n \to \infty
		\end{align*}
		We have $z_n \to 0$ in $(E_1,\norm{.}_1)$. But 
		\[
			\norm{T(z_n)}_2 = \norm{\frac{1}{n \norm{x_n}_1}T(x_n)_2} = \frac{1}{n \norm{x_n}_1} \norm{T(x_n)}_2 > 1 \qquad \text{ for all }n.
		\]
		Hence
		\[
			T(z_n) \not \to 0 \qquad \text{ in }(E_2, \norm{.}_2).
		\]
		This is a contradiction.
		\item[$(1) \Leftarrow (4)$:] Assume $T$ is bounded. For some $M > 0$ 
		\[
			\norm{T(x)}_2 \leq M \norm{x}_1, \qquad \text{ for all }x \in E_1.
		\] 
		We need to show that $T$ is continuous at $0 \in E_1$, i.e.
		\[
			x_n \to 0 \text{ in } (E_1, \norm{.}_1) \qquad \Rightarrow \qquad T(x_n) \to T(0) = 0 \text{ in } (E_2, \norm{.}_2)
		\]
		From \[
			\norm{T(x_n)}_2 \leq  M \norm{x_n}_1 \to 0
		\]
		so
		\[
			T(x_n) \to \underset{=T(0)}{\underbrace{0}} \text{ in }(E_2, \norm{.}_2).
		\]
	\end{description}
\end{beweis}
\begin{beispiele}
	\begin{enumerate}[(A)]
	\item 
	$E_1 = E_2 = C([0,1])$, $\norm{.}_1 = \norm{.}_2 = \norm{.}_{\infty}=: \norm{.}$, i.e.
	\[
		\norm{f} := \max \limits _{x \in [0,1]} \abs{f(x)}.
	\]
	\[
		T(f)(x) = \int_{0}^{1-x} \min(x,y)f(y) \,\mathrm{d}y, \qquad \text{for }f \in C([0,1]), x \in [0,1].
	\]
	\begin{enumerate}[(1)]
		\item $T(f) \in C([0,1])$ for $ f \in C([0,1])$,
		\item $T$ linear,
		\item $T$ bounded,
		\item Calculate $\norm{T}$.
	\end{enumerate}
	\begin{beweis}
		\begin{enumerate}[(1)]
			\item Fix $f \in C([0,1])$ arbitrary and fix $x \in [0,1]$. Show that $T(f)$ is continuous at $x$. Consider a sequence $(x_n)_{n=1}^{\infty}$ in $[0,1]$ such that $x_n \to x$ in $(\mathbb{R},\abs{.})$. \\
			To show $T(f)(x_n) \to T(f)(x)$ in $(\mathbb{R},\abs{.})$
			\begin{align*}
				\abs{T(f)(x_n)- T(f)(x)} &= \set{\text{assume that }x_n \leq x} \\
				&= \abs{\int_{0}^{1-x_n}\min(x_n,y)f(y) \,\mathrm{d}y - \int_{0}^{1-x} \min (x,y)f(y) \,\mathrm{d}y} \\
				&\leq  \abs{\int_{0}^{1-x}(\min (x_n,y) - \min(x,y) )f(y) \,\mathrm{d}y} \\ 
				&\qquad  + \abs{\int_{1-x}^{1-x_n}\min(x_n,y)f(y) \,\mathrm{d}y} \\
				&\leq \underset{\leq \abs{x_n-x} \norm{f}}{\underbrace{\int_{0}^{1-x} \underset{\leq \abs{x_n-x }}{\underbrace{\abs{\min (x_n,y) - \min(x,y)}}}
				 \underset{\leq \norm{f}}{\underbrace{\abs{f(y)}}} \,\mathrm{d}y}} \\ 
				& \qquad + \underset{0 \leq \dots \leq \abs{x_n-x}\cdot \norm{f}}{\underbrace{\int_{1-x}^{1-x_n}\underset{\leq
					 	1}{\underbrace{\min(x_n,y)}}\underset{\leq \norm{f}}{\underbrace{\abs{f(y)}}} \,\mathrm{d}y }} \to 0, \qquad \text{ as }n \to \infty
			\end{align*}
			If $x_n > x$ we get a similar calculation. Conclusion: 
			\[
				T(f)(x_n) \to T(f)(x) \text{ in }(\mathbb{R},\abs{.}) \text{ as } n \to \infty.
			\]
			\item Fix $f_1,f_2 \in C([0,1])$ and $\lambda_1, \lambda_2$ scalars. Then
			\begin{align*}
				T(\lambda_1 f_1 + \lambda_2 f_2)(x) &= \int_{0}^{1-x} \min(x,y)\underset{= \lambda_1 f_1(y)+\lambda_2 f_2(y)}{\underbrace{(\lambda_1 f_1 + \lambda_2 f_2)(y)}} \,\mathrm{d}y \\
				&= \lambda_1 \int_{0}^{1-x}\min(x,y)f_1(y) \,\mathrm{d}y + \lambda_2 \int_{0}^{1-x} \min(x,y)f_2(y) \,\mathrm{d}y \\
				&= \lambda_1 T(f_1)(x) + \lambda_2 T(f_2)(x) \qquad \text{ for }x \in [0,1]
			\end{align*}
			\item Fix $f \in C([0,1])$. For $x \in [0,1]$
			\begin{align*}
				\abs{T(f)(x)} &= \abs{ \int_{0}^{1-x} \underset{\geq 0}{\underbrace{\min(x,y)f(y)}} \,\mathrm{d}y }\\
				&\stackrel{(*_1)}{\leq} \int_{0}^{1-x}\min(x,y)\underset{\leq \norm{f}}{\underbrace{\abs{f(y)}}} \,\mathrm{d}y \\
				&\stackrel{(*_2)}{\leq} \int_{0}^{1-x} \min(x,y) \,\mathrm{d}y \norm{f}
			\end{align*}
			Clearly 
			\[
				\max\limits_{x \in [0,1]}\int_{0}^{1-x} \min(x,y) \,\mathrm{d}y \leq 1
			\]
			This gives:
			\[
				\norm{T(f)} = \max\limits_{x \in [0,1]}\abs{T(f)(x)} \leq 1 \cdot \norm{f}, \qquad \text{for all }f \in C([0,1]).
			\]
			Conclusion: $T$ is bounded with ($M=1$)
			\item Consider the unequality above. $(*_1)$ is an equality if $f$ has a constant sign. $(*_2)$ is an equality if $f$ is a constant function. So we have to calculate 
			\[
				\int_{0}^{1-x} \min(x,y) \,\mathrm{d}y \qquad \text{for }x \in [0,1].
			\]
			\begin{description}
				\item[case 1:]$1-x \leq x$ i.e. $ \frac{1}{2} \leq x$ and we get
				\begin{align*}
					\int_{0}^{1-x} \underset{=y}{\underbrace{\min(x,y)}} \,\mathrm{d}y &= \left[ \frac{1}{2} y^2 \right]_0^{1-x}  \\ &= \frac{1}{2} (1-x)^2
				\end{align*}
				\item[case 2:] $x < 1-x$ i.e. $ x < \frac{1}{2}$ and we get
				\begin{align*}
					\int_{0}^{1-x} \min(x,y) \,\mathrm{d}y &= \int_{0}^{x} y  \,\mathrm{d}y + \int_{x}^{1-x}x \,\mathrm{d}y  \\ &= \frac{1}{2}x^2 + x(1-2x) 
					\\ & = x - \frac{3}{2}x^2
				\end{align*}
				Claim 
				\[
					\norm{T} = \max \left( \max\limits_{x \in [\frac{1}{2},1]} \frac{1}{2}(1-x)^2 , \max\limits_{x \in [0,\frac{1}{2}]}\left( x - \frac{3}{2}x^2
					 \right) \right) = 
					\dots = \frac{1}{6}
				\]
				Note 
				\begin{itemize}
					\item $\norm{T(f)}\leq \norm{T} \cdot \norm{f}$ for all $f \in C([0,1])$,
					\item $\norm{T(1)} = \norm{T} \cdot \norm{1}$ where $1(x)=1$ for $x \in [0,1]$.
				\end{itemize}
			\end{description}
		\end{enumerate}
	\end{beweis}
	\item $E_1 = C([0,1])$ with maximumnorm, $E_2 = \mathbb{R}$ with absolut value. $T: E_1 \to E_2$ with
	\[
		T(f) = \int_{0}^{\frac{1}{2}}f(y) \,\mathrm{d}y - \int_{\frac{1}{2}}^{1} f(y) \,\mathrm{d}y \qquad \text{for }f \in E_1
	\]
	\begin{align*}
		\abs{T(f)} &= \abs{\int_{0}^{\frac{1}{2}}f(y) \,\mathrm{d}y - \int_{\frac{1}{2}}^{1} f(y) \,\mathrm{d}y} \\
		&\leq \abs{\int_{0}^{\frac{1}{2}}f(y) \,\mathrm{d}y} + \abs{\int_{\frac{1}{2}}^{1} f(y) \,\mathrm{d}y} \\
		&\leq \int_{0}^{\frac{1}{2}}\underset{\leq \norm{f}}{\underbrace{\abs{f(y)}}} \,\mathrm{d}y 
		+ \int_{\frac{1}{2}}^{1} \underset{\leq \norm{f}}{\underbrace{\abs{f(y)}}} \,\mathrm{d}y \\
		&\leq 1 \norm{f}
	\end{align*}
	Hence $T$ is bounded and $\norm{T}\leq 1$.
	\[
		T(f) = \int_{0}^{1}k(y)f(y) \,\mathrm{d}y 
	\]
	where 
	\[
		T(f_n)= \begin{cases}
			nachholen, &\text{ falls }case\\
			
		\end{cases}
	\]
	\[
		T(f_n) \leq 1 \left( \frac{1}{2} - \frac{1}{2n} + \frac{1}{2} - \frac{1}{2n} \right) = 1 - \frac{1}{n}, \qquad  n=1,2,\dots
	\]
	note
	\[
		k(y)f_n(y) \geq 0 \qquad \text{ for } y \in [0,1].
	\]
	Hence $\norm{T} \leq 1- \frac{1}{n}$ for $n =1,2,\dots$. Note $\norm{f_n}=1$ for all $n$. Conclusion $\norm{T}=1$. \\
	Here
	\[
		\abs{T(f)} \leq \underset{\leq 1}{\underbrace{\norm{T}}} \norm{f} \text{ for all }f \in C([0,1])
	\]
	but
	\[
		\abs{T(f)} < \norm{T} \norm{f} \qquad \text{ for all }f \in C([0,1]).
	\]
	\end{enumerate}
\end{beispiele}
\begin{satz*}

	$T_1,T_2$ bounded linear mappings $(E_1,\norm{.}_1) \to (E_2,\norm{.}_2)$ and $\lambda$ scalar. Set
	\begin{align*}
		(T_1+T_2)(x) &= T_1(x) + T_2(x) \qquad x \in E_1 \\
		( \lambda T_1)(x) &= \lambda T_1(x) \qquad x \in E_1
	\end{align*}
	Claim:
	\begin{enumerate}[(1)]
		\item $T_1 + T_2$ and $\lambda T_1$ are both linear mappings $(E_1,\norm{.}_1) \to (E_2,\norm{.}_2)$,
		\item $T_1 + T_2$ and $\lambda T_1$ are both bounded mappings $(E_1,\norm{.}_1) \to (E_2,\norm{.}_2)$. \\
		$B(E_1,E_2)$ denote the vector space of all bounded linear mappings $(E_1,\norm{.}_1) \to (E_2,\norm{.}_2)$.
		\item \[
			\norm{T}_{E_1 \to E_2} := \inf \set[M > 0]{\norm{T(x)}_2 \leq M \norm{x}_1 \text{ for all }x \in E_1}
		\]
		defines a norm in $B(E_1,E_2)$.
	\end{enumerate}
\end{satz*}
\begin{beweis}
	\begin{enumerate}[(1)]
		\item $\norm{T}=0$ implies that $\norm{T(x)}_2 = 0$ for all $x \in E_1$ $ \,\, \Rightarrow \,\, $ $T(x) = 0 \in E_2$.
		\[
			T = 0 \in B(E_1,E_2)
		\]
		\item $T \in B(E_1,E_2)$ and $\lambda$ scalar. 
		\begin{align*}
			\norm{\lambda T} &= \inf \set[M >0]{\norm{(\lambda T)(x)}_2 \leq M \norm{x}_1 \text{ for all }x \in E_1} \\
			&= \inf \set[M>0]{\abs{\lambda} \norm{T(x)}_2 \leq M \norm{x}_1 \text{ for all }x \in E_1} \\
			&= \set{\text{if }\lambda \neq 0} \\
			&= \inf \set[\underset{= \abs{\lambda} \tilde M}{\underbrace{M}}>0]{\norm{T(x)}_2 \leq \underset{= \tilde M}{\underbrace{\frac{M}{\abs{\lambda}}}}\norm{x}_1 \text{ for all }x \in E_1} \\
			&= \abs{\lambda} \inf \set[\tilde M >0]{ \norm{T(x)}_2 \leq \tilde M \norm{x}_1 \text{ for all }x \in E_1} \\
			&= \abs{\lambda} \norm{T}
		\end{align*}
		\item Set $T_1,T_2 \in B(E_1,E_2)$.
		\begin{align*}
			\norm{T_1+ T_2} &= \inf \set[M>0]{\norm{(T_1+T_2)(x)}_2 \leq M \norm{x}_1 \text{ for all }x \in E_1} \\
			&\leq \inf \set[M_1 + M_2>0]{\norm{T_1(x)}_2 \leq M_1 \norm{x}_1, \, \norm{T_2(x)}_2 \leq M_2 \norm{x}_1 \text{ for all }x \in E_1} \\
			&= \norm{T_1} + \norm{T_2}
		\end{align*}
	\end{enumerate}
\end{beweis}
Conclusion: $(B(E_1,B_2),\norm{.}_{E_1 \to E_2})$ is a normal space. 
\begin{satz*}
	 $(B(E_1,B_2),\norm{.}_{E_1 \to E_2})$ is a Banach space if $(E_2,\norm{.}_2)$ is a Banach space.
\end{satz*}
\begin{beweis}
	Assume $(T_n)_{n=1}^{\infty}$ is a Cauchy sequence in $(B(E_1,B_2),\norm{.}_{E_1 \to E_2})$ where $(E_2, \norm{.}_2)$ is a Banach space. Fix $x \in E_1$
	\begin{align*}
		\norm{T_n(x)-T_m(x)}_2 &= \norm{(T_n-T_m)(x)}_2  \\
		&\leq \underset{\substack{\to 0 \\ n,m \to \infty}}{\underbrace{\norm{T_n-T_m}_{E_1 \to E_2}}} \cdot \norm{x}_1 \to 0, \qquad n,m \to \infty
	\end{align*}
	Hence $(T_n(x))_{n=1}^{\infty}$ is a Cauchy sequence in $(E_2, \norm{.}_2)$. This is a Banach space which implies that $(T_n(x))_{n=1}^{\infty}$ converges in 
	$(E_2,\norm{.}_2)$. Call the limit $T(x) \in E_2$ for all $x \in E_1$. Show now 
	\begin{enumerate}[(1)]
		\item $T: E_1 \to E_2$ is linear,
		\item $T$ is bounded,
		\item $\norm{T_n - T}_{E_1 \to E_2} \to 0$ for $n \to \infty$.
	\end{enumerate}
	\begin{enumerate}[(1)]
		\item Observe 
		\begin{align*}
		T(\lambda_1 x_1 + \lambda_2 + x_2)\leftarrow T_n(\lambda_1 x_1 + \lambda_2 x_2) = \set{T \text{ linear}} = \underset{\to \lambda_1 T(x_1) + \lambda_2 T(x_2)}{\underbrace{\underset{\to \lambda_1 T(x_1)}{\underbrace{\lambda_1 \underset{\to T(x_1)}{\underbrace{T_n(x_1)}}}} + \underset{\to \lambda_2 T(x_2)}{\underbrace{\lambda_2 \underset{\to T(x_2)}{\underbrace{T_n(x_2)}}}}}}
		\end{align*}
		So for $n \to  \infty$ it is
		\[
			T(\lambda_1 x_1 + \lambda_2 + x_2) = \lambda_1 T(x_1) + \lambda_2 T(x_2) \qquad \text{ in }(E_2, \norm{.}_2).
		\]
		\item Fix $\varepsilon >0$. Then there exists $N$ such that:
		\[
			\norm{T_n- T_m}_{E_1 \to E_2} < \varepsilon \qquad \text{for }n,m \geq N
		\]
		So for $x \in E_1$
		\[
			\norm{T_n(x)-T_m(x)}_2 \leq \norm{T_n - T_m}_{E_1 \to E_2} \norm{x}_1 < \varepsilon \norm{x}_1 \qquad \text{for }n,m \geq N
		\]
		Let $m \to \infty$.
		\[
			\norm{T_n(x)- T(x)}_2 \leq \varepsilon \norm{x}_1 \qquad \text{for }n \geq N
 		\]
		So
		\begin{align*}
			\norm{T(x)}_2 &\leq  \norm{T(x)- T_N(x)}_2 + \norm{T_N(x)}_2 \\
			&\leq \varepsilon \norm{x}_1 + \norm{T_N}_{E_1 \to E_2} \cdot \norm{x}_1 \\
			&= \left( \varepsilon +  \norm{T_N}_{E_1 \to E_2} \right) \norm{x}_1 \qquad \text{for }x \in E_1
		\end{align*}
		\item Look above and get
		\[
			\norm{T_n - T}_{E_1 \to E_2} \to 0, \qquad  n \to \infty.
		\]
	\end{enumerate}
\end{beweis}
\begin{theorem*}[Banach-Steinhaus theorem (uniform boundedness principle)]
	$(E_1,\norm{.}_1)$ Banach space, $(E_2,\norm{.}_2)$ normal space and $\mathcal{F} \subset B(E_1,E_2)$. Assume
	\[
		\sup\limits_{T \in \mathcal{F}}\norm{T(x)}_2 < \infty \qquad \text{for all } x \in E_1
	\]
	then
	\[
		\sup\limits_{T \in \mathcal{F}}\norm{T}_{E_1 \to E_2} < \infty.
	\]
	\end{theorem*}
	\begin{bemerkung}
		The implication $\Leftarrow$ is easy to prove. If $\mathcal{F}$ is a finite set, the theorem is trivial.
	\end{bemerkung}
	\begin{beweis}
		\begin{enumerate}[step 1:]
			\item Assume 
			\[
				\exists\,x_0 \in E_1\, \exists\, r >0 \,\exists\, M>0: \,\forall\, x \in \overline{B(x_0,r)} \, \forall\,  T \in \mathcal{F}: \,\norm{T(x)}_2 \leq M
			\]
			We have to show that 
			\[
				\sup\limits_{T \in \mathcal{F}} \norm{T}_{E_1 \to E_2} < \infty.
			\]
			Fix $T \in \mathcal{F}$. For $\norm{x}_1 \leq r$
			\[
				\norm{T(x_0+x)}_2 \leq M
			\]
			Note that $x_0+x \in \overline{B(x_0,r)}$.
			\begin{align*}
				\norm{T(x)}_2 &= \norm{T(x_0+x-x_0)}_2 \\ &= \set{T \text{ linear}} \\ &= \norm{T(x_0 + x)-T(x_0)}_2 \\ &\leq \norm{T(x_0+x)}_2 +
				\norm{T(x_0)}_2 \\ &\leq 2M
			\end{align*}
			For $0 \neq x \in E_1$ 
			\[
				\norm{T \left( \frac{r}{\norm{x}_1} x \right)}_2 \leq 2M
			\]
			$\frac{r}{\norm{x}_1} $ has the $\norm{.}_1$-norm equal to $r$. This implies , since T linear,
			\[
				\frac{r}{\norm{x}_1} \norm{T(x)}_2 \leq 2M
			\]
			i.e.
			\[
				\norm{T(x)}_2 \leq \frac{2M}{r}\norm{x}_1 \qquad \text{for all }0 \neq x \in E_1.
			\]
			We have
			\[
				\norm{t}_{E_1 \to E_2} \leq \underset{\substack{\text{independant}\\ \text{of }T}}{\underbrace{\frac{2M}{r}}} < \infty
			\]
			\[
				\sup\limits_{T \in \mathcal{F}}\norm{T}_{E_1 \to E_2} \leq \frac{2M}{r} < \infty
			\]
			\item Justify the assumption in step 1. This assumption is equivalent to
			\[
			\exists\,x_0 \in E_1\, \exists\, r >0 \,\exists\, M>0: \,\forall\, x \in B(x_0,r) \, \forall\,  T \in \mathcal{F}: \,\norm{T(x)}_2 \leq M	
			\]
			(Note $\overline{B(x_0,r_1)} \subset B(x_0,r) \subset B(x_0,r_2)$ for $0 < r_1 < r < r_2$). \\
			Argue by contradiction. Assume that the assumption is false. Then it holds
			\[
				\forall\, x_0 \in E_1 \, \forall\, r >0 \,\forall\,  M>0: \,\exists\, x \in B(x_0,r) \,\exists\, T \in \mathcal{F} : \, \norm{T(x)}_2 > M.
			\]
			Idea: Find a converging sequence $x_n \in E_1$, $x_n \to x$ in $(E_1,\norm{.}_1)$ and a sequence $(T_n)_{n=1}^{\infty} \subset \mathcal{F}$ such that
			\[
				\norm{T_n(x_n)}_2 > n \qquad \text{for all }n, \qquad \text{and} \qquad \norm{T_n(x)}_2 > n \qquad \text{ for all }n.
			\]
			We have from above $x_1 \in B(0,1)$ and $T_1 \in  \mathcal{F}$ such that \[
				\norm{T_1(x_1)}_2 > 1.
			\] $T_1$ is bounded linear, hence continuous. This implies that there exists $0<r_1 < \frac{1}{2}$ such that
			\[
				\norm{T_1(x)}_2 >1 \qquad \text{for }x \in B(x_1,r_1)
			\]
			and \[
				\overline{B(x_1,r_1)}\subset B(0,1).
			\]
		\end{enumerate}
	\end{beweis}
\cleardoubleoddemptypage
\pagenumbering{Alph}
\setcounter{page}{1}

\end{document}